{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0GZYrZiHA314tXly6anQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpaj12/LEARNING_GNNs/blob/main/yosys_and_hw2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the yosys install"
      ],
      "metadata": {
        "id": "xHvsJh0lFg4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For GPU = Runtime->\"Change Runtime Type\""
      ],
      "metadata": {
        "id": "bflk6k0X9f4F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRvhEUG-ppJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327e939d-3c59-4114-950d-4de54e2c5e28"
      },
      "source": [
        "!curl -O https://repo.anaconda.com/miniconda/Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
        "!bash Miniconda3-py37_4.10.3-Linux-x86_64.sh -b -f -p miniconda-synth/\n",
        "!miniconda-synth/bin/conda install --yes -c LiteX-Hub yosys\n",
        "!miniconda-synth/bin/conda install --yes -c SymbiFlow verible"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 84.9M  100 84.9M    0     0   117M      0 --:--:-- --:--:-- --:--:--  117M\n",
            "PREFIX=/content/miniconda-synth\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/miniconda-synth\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py37h27cfd23_1003\n",
            "    - ca-certificates==2021.7.5=h06a4308_1\n",
            "    - certifi==2021.5.30=py37h06a4308_0\n",
            "    - cffi==1.14.6=py37h400218f_0\n",
            "    - chardet==4.0.0=py37h06a4308_1003\n",
            "    - conda-package-handling==1.7.3=py37h27cfd23_1\n",
            "    - conda==4.10.3=py37h06a4308_0\n",
            "    - cryptography==3.4.7=py37hd23ed53_0\n",
            "    - idna==2.10=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1k=h27cfd23_0\n",
            "    - pip==21.1.3=py37h06a4308_0\n",
            "    - pycosat==0.6.3=py37h27cfd23_0\n",
            "    - pycparser==2.20=py_2\n",
            "    - pyopenssl==20.0.1=pyhd3eb1b0_1\n",
            "    - pysocks==1.7.1=py37_1\n",
            "    - python==3.7.10=h12debd9_4\n",
            "    - readline==8.1=h27cfd23_0\n",
            "    - requests==2.25.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py37h27cfd23_0\n",
            "    - setuptools==52.0.0=py37h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_0\n",
            "    - sqlite==3.36.0=hc218d9a_0\n",
            "    - tk==8.6.10=hbc83047_0\n",
            "    - tqdm==4.61.2=pyhd3eb1b0_1\n",
            "    - urllib3==1.26.6=pyhd3eb1b0_1\n",
            "    - wheel==0.36.2=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  ca-certificates                      2025.2.25-h06a4308_0 --> 2021.7.5-h06a4308_1\n",
            "  openssl                                 1.1.1w-h7f8727e_0 --> 1.1.1k-h27cfd23_0\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /content/miniconda-synth\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.10.3\n",
            "  latest version: 25.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/miniconda-synth\n",
            "\n",
            "  added / updated specs:\n",
            "    - yosys\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                       2021.7.5-h06a4308_1 --> 2025.2.25-h06a4308_0\n",
            "  openssl                                 1.1.1k-h27cfd23_0 --> 1.1.1w-h7f8727e_0\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\bdone\n",
            "Verifying transaction: / \b\bdone\n",
            "Executing transaction: \\ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.10.3\n",
            "  latest version: 25.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verilog to test"
      ],
      "metadata": {
        "id": "t6_MCVufFmIA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4IAholPqyy7"
      },
      "source": [
        "%%bash -c 'source miniconda-synth/bin/activate; cat > adder.v; verible-verilog-lint adder.v'\n",
        "\n",
        "module adder(\n",
        "  input wire a,\n",
        "  input wire b,\n",
        "  output wire [1:0] out\n",
        ");\n",
        "  assign out = a + b;\n",
        "endmodule"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0bGPxH3nvXR",
        "outputId": "06c9ed4e-05ff-4c04-a165-9a80b395583c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 88272\n",
            "-rw-r--r--  1 root root     1921 May 27 21:08 '=1.4'\n",
            "-rw-r--r--  1 root root      106 May 27 21:35  adder.v\n",
            "drwxrwxr-x  2 root root     4096 Nov  5  2021  cmos\n",
            "-rw-r--r--  1 root root  1061608 May 27 21:25  dfg_tj_rtl.pkl\n",
            "drwx------  6 root root     4096 May 27 21:07  drive\n",
            "drwxr-xr-x  6 root root     4096 May 27 16:54  hw2vec\n",
            "drwxr-xr-x  2 root root     4096 May 27 21:24  hw2vec_logs\n",
            "-rw-r--r--  1 root root      226 May 27 21:25  metadata.tsv\n",
            "-rw-r--r--  1 root root 89026327 May 27 21:34  Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
            "drwxr-xr-x 16 root root     4096 May 27 21:34  miniconda-synth\n",
            "-rw-r--r--  1 root root      211 May 27 21:25  model.cfg\n",
            "-rw-r--r--  1 root root   198620 May 27 21:25  model.pth\n",
            "drwxr-xr-x  1 root root     4096 May 23 13:39  sample_data\n",
            "-rw-r--r--  1 root root     1757 May 27 21:06  synth_cmos.dot\n",
            "-rw-r--r--  1 root root      489 May 27 21:06  synth_design.dot\n",
            "-rw-r--r--  1 root root      973 May 27 21:06  synth_gate.dot\n",
            "-rw-r--r--  1 root root    39006 May 27 21:25  vectors.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yosys reads and executes with .dot visualization\n"
      ],
      "metadata": {
        "id": "XoZEWtm1FqYo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItAxi-2Vqky7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6fca6813-3da5-4776-aa3e-3ecd3e0e4848"
      },
      "source": [
        "%%script miniconda-synth/bin/yosys -Q -T\n",
        "\n",
        "read -sv adder.v\n",
        "hierarchy -top adder\n",
        "\n",
        "proc; opt\n",
        "\n",
        "opt_clean\n",
        "show -format dot -prefix synth_design\n",
        "stat"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "yosys> \n",
            "yosys> \n",
            "\n",
            "1. Executing Verilog-2005 frontend: adder.v\n",
            "Parsing SystemVerilog input from `adder.v' to AST representation.\n",
            "Storing AST representation for module `$abstract\\adder'.\n",
            "Successfully finished Verilog frontend.\n",
            "\n",
            "yosys> \n",
            "2. Executing HIERARCHY pass (managing design hierarchy).\n",
            "\n",
            "3. Executing AST frontend in derive mode using pre-parsed AST for module `\\adder'.\n",
            "Generating RTLIL representation for module `\\adder'.\n",
            "\n",
            "3.1. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "\n",
            "3.2. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "Removing unused module `$abstract\\adder'.\n",
            "Removed 1 unused modules.\n",
            "\n",
            "yosys> \n",
            "yosys> \n",
            "4. Executing PROC pass (convert processes to netlists).\n",
            "\n",
            "4.1. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
            "Cleaned up 0 empty switches.\n",
            "\n",
            "4.2. Executing PROC_RMDEAD pass (remove dead branches from decision trees).\n",
            "Removed a total of 0 dead cases.\n",
            "\n",
            "4.3. Executing PROC_PRUNE pass (remove redundant assignments in processes).\n",
            "Removed 0 redundant assignments.\n",
            "Promoted 0 assignments to connections.\n",
            "\n",
            "4.4. Executing PROC_INIT pass (extract init attributes).\n",
            "\n",
            "4.5. Executing PROC_ARST pass (detect async resets in processes).\n",
            "\n",
            "4.6. Executing PROC_MUX pass (convert decision trees to multiplexers).\n",
            "\n",
            "4.7. Executing PROC_DLATCH pass (convert process syncs to latches).\n",
            "\n",
            "4.8. Executing PROC_DFF pass (convert process syncs to FFs).\n",
            "\n",
            "4.9. Executing PROC_MEMWR pass (convert process memory writes to cells).\n",
            "\n",
            "4.10. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
            "Cleaned up 0 empty switches.\n",
            "\n",
            "4.11. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.5. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "Removed 0 unused cells and 1 unused wires.\n",
            "\n",
            "5.8. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.9. Rerunning OPT passes. (Maybe there is more to do..)\n",
            "\n",
            "5.10. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.11. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.12. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.13. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.14. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.15. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.16. Finished OPT passes. (There is nothing left to do.)\n",
            "\n",
            "yosys> \n",
            "yosys> \n",
            "6. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "yosys> \n",
            "7. Generating Graphviz representation of design.\n",
            "Writing dot description to `synth_design.dot'.\n",
            "Dumping module adder to page 1.\n",
            "\n",
            "yosys> \n",
            "8. Printing statistics.\n",
            "\n",
            "=== adder ===\n",
            "\n",
            "   Number of wires:                  3\n",
            "   Number of wire bits:              4\n",
            "   Number of public wires:           3\n",
            "   Number of public wire bits:       4\n",
            "   Number of memories:               0\n",
            "   Number of memory bits:            0\n",
            "   Number of processes:              0\n",
            "   Number of cells:                  1\n",
            "     $add                            1\n",
            "\n",
            "\n",
            "yosys> exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "vHZ3rQJ6tHXM",
        "outputId": "faa66a22-59b8-4d53-c543-0a18039a3cc6"
      },
      "source": [
        "import graphviz\n",
        "graphviz.Source.from_file('synth_design.dot')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: adder Pages: 1 -->\n<svg width=\"283pt\" height=\"121pt\"\n viewBox=\"0.00 0.00 283.00 121.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 117)\">\n<title>adder</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-117 279,-117 279,4 -4,4\"/>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">adder</text>\n<!-- n1 -->\n<g id=\"node1\" class=\"node\">\n<title>n1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"54,-87.54 54,-102.46 38.18,-113 15.82,-113 0,-102.46 0,-87.54 15.82,-77 38.18,-77 54,-87.54\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n</g>\n<!-- c7 -->\n<g id=\"node4\" class=\"node\">\n<title>c7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"90,-45 90,-91 185,-91 185,-45 90,-45\"/>\n<text text-anchor=\"middle\" x=\"103\" y=\"-75.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"90,-68 116,-68 \"/>\n<text text-anchor=\"middle\" x=\"103\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"116,-45 116,-91 \"/>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-71.8\" font-family=\"Times,serif\" font-size=\"14.00\">$1</text>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\">$add</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"159,-45 159,-91 \"/>\n<text text-anchor=\"middle\" x=\"172\" y=\"-64.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- n1&#45;&gt;c7 -->\n<g id=\"edge1\" class=\"edge\">\n<title>n1:e&#45;&gt;c7:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-95C67.27,-95 71.16,-86.21 80.04,-82.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"80.93,-85.47 90,-80 79.49,-78.62 80.93,-85.47\"/>\n</g>\n<!-- n2 -->\n<g id=\"node2\" class=\"node\">\n<title>n2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"54,-33.54 54,-48.46 38.18,-59 15.82,-59 0,-48.46 0,-33.54 15.82,-23 38.18,-23 54,-33.54\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n</g>\n<!-- n2&#45;&gt;c7 -->\n<g id=\"edge2\" class=\"edge\">\n<title>n2:e&#45;&gt;c7:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-41C67.27,-41 71.16,-49.79 80.04,-53.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.49,-57.38 90,-56 80.93,-50.53 79.49,-57.38\"/>\n</g>\n<!-- n3 -->\n<g id=\"node3\" class=\"node\">\n<title>n3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"275,-60.54 275,-75.46 259.18,-86 236.82,-86 221,-75.46 221,-60.54 236.82,-50 259.18,-50 275,-60.54\"/>\n<text text-anchor=\"middle\" x=\"248\" y=\"-64.3\" font-family=\"Times,serif\" font-size=\"14.00\">out</text>\n</g>\n<!-- c7&#45;&gt;n3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>c7:e&#45;&gt;n3:w</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"3\" d=\"M185,-68C197,-68 202.25,-68 210.88,-68\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"3\" points=\"211,-71.5 221,-68 211,-64.5 211,-71.5\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7b1d51c12d90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJHob_xTup5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "81b080a7-2bce-4fe5-c6e7-3213b1f44072"
      },
      "source": [
        "%%script miniconda-synth/bin/yosys -Q -T\n",
        "\n",
        "read -sv adder.v\n",
        "hierarchy -top adder\n",
        "\n",
        "proc; opt\n",
        "techmap; opt\n",
        "\n",
        "opt_clean\n",
        "show -format dot -prefix synth_gate\n",
        "stat"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "yosys> \n",
            "yosys> \n",
            "\n",
            "1. Executing Verilog-2005 frontend: adder.v\n",
            "Parsing SystemVerilog input from `adder.v' to AST representation.\n",
            "Storing AST representation for module `$abstract\\adder'.\n",
            "Successfully finished Verilog frontend.\n",
            "\n",
            "yosys> \n",
            "2. Executing HIERARCHY pass (managing design hierarchy).\n",
            "\n",
            "3. Executing AST frontend in derive mode using pre-parsed AST for module `\\adder'.\n",
            "Generating RTLIL representation for module `\\adder'.\n",
            "\n",
            "3.1. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "\n",
            "3.2. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "Removing unused module `$abstract\\adder'.\n",
            "Removed 1 unused modules.\n",
            "\n",
            "yosys> \n",
            "yosys> \n",
            "4. Executing PROC pass (convert processes to netlists).\n",
            "\n",
            "4.1. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
            "Cleaned up 0 empty switches.\n",
            "\n",
            "4.2. Executing PROC_RMDEAD pass (remove dead branches from decision trees).\n",
            "Removed a total of 0 dead cases.\n",
            "\n",
            "4.3. Executing PROC_PRUNE pass (remove redundant assignments in processes).\n",
            "Removed 0 redundant assignments.\n",
            "Promoted 0 assignments to connections.\n",
            "\n",
            "4.4. Executing PROC_INIT pass (extract init attributes).\n",
            "\n",
            "4.5. Executing PROC_ARST pass (detect async resets in processes).\n",
            "\n",
            "4.6. Executing PROC_MUX pass (convert decision trees to multiplexers).\n",
            "\n",
            "4.7. Executing PROC_DLATCH pass (convert process syncs to latches).\n",
            "\n",
            "4.8. Executing PROC_DFF pass (convert process syncs to FFs).\n",
            "\n",
            "4.9. Executing PROC_MEMWR pass (convert process memory writes to cells).\n",
            "\n",
            "4.10. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
            "Cleaned up 0 empty switches.\n",
            "\n",
            "4.11. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.5. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "Removed 0 unused cells and 1 unused wires.\n",
            "\n",
            "5.8. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.9. Rerunning OPT passes. (Maybe there is more to do..)\n",
            "\n",
            "5.10. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.11. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.12. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.13. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.14. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.15. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.16. Finished OPT passes. (There is nothing left to do.)\n",
            "\n",
            "yosys> \n",
            "6. Executing TECHMAP pass (map to technology primitives).\n",
            "\n",
            "6.1. Executing Verilog-2005 frontend: /content/miniconda-synth/bin/../share/yosys/techmap.v\n",
            "Parsing Verilog input from `/content/miniconda-synth/bin/../share/yosys/techmap.v' to AST representation.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_bool_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_reduce_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_logic_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_compare_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_various'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_registers'.\n",
            "Generating RTLIL representation for module `\\_90_shift_ops_shr_shl_sshl_sshr'.\n",
            "Generating RTLIL representation for module `\\_90_shift_shiftx'.\n",
            "Generating RTLIL representation for module `\\_90_fa'.\n",
            "Generating RTLIL representation for module `\\_90_lcu'.\n",
            "Generating RTLIL representation for module `\\_90_alu'.\n",
            "Generating RTLIL representation for module `\\_90_macc'.\n",
            "Generating RTLIL representation for module `\\_90_alumacc'.\n",
            "Generating RTLIL representation for module `\\$__div_mod_u'.\n",
            "Generating RTLIL representation for module `\\$__div_mod_trunc'.\n",
            "Generating RTLIL representation for module `\\_90_div'.\n",
            "Generating RTLIL representation for module `\\_90_mod'.\n",
            "Generating RTLIL representation for module `\\$__div_mod_floor'.\n",
            "Generating RTLIL representation for module `\\_90_divfloor'.\n",
            "Generating RTLIL representation for module `\\_90_modfloor'.\n",
            "Generating RTLIL representation for module `\\_90_pow'.\n",
            "Generating RTLIL representation for module `\\_90_pmux'.\n",
            "Generating RTLIL representation for module `\\_90_demux'.\n",
            "Generating RTLIL representation for module `\\_90_lut'.\n",
            "Successfully finished Verilog frontend.\n",
            "\n",
            "6.2. Continuing TECHMAP pass.\n",
            "Running \"alumacc\" on wrapper $extern:wrap:$add:A_SIGNED=0:A_WIDTH=1:B_SIGNED=0:B_WIDTH=1:Y_WIDTH=2:394426c56d1a028ba8fdd5469b163e04011def47.\n",
            "Using template $extern:wrap:$add:A_SIGNED=0:A_WIDTH=1:B_SIGNED=0:B_WIDTH=1:Y_WIDTH=2:394426c56d1a028ba8fdd5469b163e04011def47 for cells of type $extern:wrap:$add:A_SIGNED=0:A_WIDTH=1:B_SIGNED=0:B_WIDTH=1:Y_WIDTH=2:394426c56d1a028ba8fdd5469b163e04011def47.\n",
            "Using template $paramod$1d1e68f77481583066c6d429218f48ea9d5739b3\\_90_alu for cells of type $alu.\n",
            "Using extmapper simplemap for cells of type $xor.\n",
            "Using extmapper simplemap for cells of type $and.\n",
            "Using template $paramod\\_90_lcu\\WIDTH=32'00000000000000000000000000000010 for cells of type $lcu.\n",
            "Using extmapper simplemap for cells of type $pos.\n",
            "Using extmapper simplemap for cells of type $mux.\n",
            "Using extmapper simplemap for cells of type $not.\n",
            "Using extmapper simplemap for cells of type $or.\n",
            "No more expansions possible.\n",
            "\n",
            "7. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "7.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "7.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "7.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "7.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "7.5. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "7.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "7.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "Removed 1 unused cells and 32 unused wires.\n",
            "\n",
            "7.8. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "7.9. Rerunning OPT passes. (Maybe there is more to do..)\n",
            "\n",
            "7.10. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "7.11. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "7.12. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "7.13. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "7.14. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "7.15. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "7.16. Finished OPT passes. (There is nothing left to do.)\n",
            "\n",
            "yosys> \n",
            "yosys> \n",
            "8. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "yosys> \n",
            "9. Generating Graphviz representation of design.\n",
            "Writing dot description to `synth_gate.dot'.\n",
            "Dumping module adder to page 1.\n",
            "\n",
            "yosys> \n",
            "10. Printing statistics.\n",
            "\n",
            "=== adder ===\n",
            "\n",
            "   Number of wires:                  3\n",
            "   Number of wire bits:              4\n",
            "   Number of public wires:           3\n",
            "   Number of public wire bits:       4\n",
            "   Number of memories:               0\n",
            "   Number of memory bits:            0\n",
            "   Number of processes:              0\n",
            "   Number of cells:                  2\n",
            "     $_AND_                          1\n",
            "     $_XOR_                          1\n",
            "\n",
            "\n",
            "yosys> exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "O0OKruObup5W",
        "outputId": "5951f9fa-fd9b-4488-a2c4-e50a29658602"
      },
      "source": [
        "import graphviz\n",
        "graphviz.Source.from_file('synth_gate.dot')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: adder Pages: 1 -->\n<svg width=\"405pt\" height=\"143pt\"\n viewBox=\"0.00 0.00 405.00 143.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 139)\">\n<title>adder</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-139 401,-139 401,4 -4,4\"/>\n<text text-anchor=\"middle\" x=\"198.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">adder</text>\n<!-- n1 -->\n<g id=\"node1\" class=\"node\">\n<title>n1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"54,-107.04 54,-121.96 38.18,-132.5 15.82,-132.5 0,-121.96 0,-107.04 15.82,-96.5 38.18,-96.5 54,-107.04\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-110.8\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n</g>\n<!-- c7 -->\n<g id=\"node4\" class=\"node\">\n<title>c7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"90.5,-88.5 90.5,-134.5 207.5,-134.5 207.5,-88.5 90.5,-88.5\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"90.5,-111.5 116.5,-111.5 \"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"116.5,-88.5 116.5,-134.5 \"/>\n<text text-anchor=\"middle\" x=\"149\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">$90</text>\n<text text-anchor=\"middle\" x=\"149\" y=\"-100.3\" font-family=\"Times,serif\" font-size=\"14.00\">$_XOR_</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"181.5,-88.5 181.5,-134.5 \"/>\n<text text-anchor=\"middle\" x=\"194.5\" y=\"-107.8\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- n1&#45;&gt;c7 -->\n<g id=\"edge3\" class=\"edge\">\n<title>n1:e&#45;&gt;c7:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-114.5C66.5,-114.5 71.26,-119.67 80.01,-122.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.63,-125.65 90,-123.5 80.55,-118.71 79.63,-125.65\"/>\n</g>\n<!-- c8 -->\n<g id=\"node6\" class=\"node\">\n<title>c8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"90,-23.5 90,-69.5 208,-69.5 208,-23.5 90,-23.5\"/>\n<text text-anchor=\"middle\" x=\"103\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"90,-46.5 116,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"103\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"116,-23.5 116,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"149\" y=\"-50.3\" font-family=\"Times,serif\" font-size=\"14.00\">$92</text>\n<text text-anchor=\"middle\" x=\"149\" y=\"-35.3\" font-family=\"Times,serif\" font-size=\"14.00\">$_AND_</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"182,-23.5 182,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"195\" y=\"-42.8\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n</g>\n<!-- n1&#45;&gt;c8 -->\n<g id=\"edge4\" class=\"edge\">\n<title>n1:e&#45;&gt;c8:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-114.5C79.43,-114.5 65.89,-73.14 80.35,-61.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"81.5,-64.82 90,-58.5 79.41,-58.14 81.5,-64.82\"/>\n</g>\n<!-- n2 -->\n<g id=\"node2\" class=\"node\">\n<title>n2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"54,-36.04 54,-50.96 38.18,-61.5 15.82,-61.5 0,-50.96 0,-36.04 15.82,-25.5 38.18,-25.5 54,-36.04\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-39.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n</g>\n<!-- n2&#45;&gt;c7 -->\n<g id=\"edge5\" class=\"edge\">\n<title>n2:e&#45;&gt;c7:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-43.5C79.43,-43.5 65.89,-84.86 80.35,-96.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"79.41,-99.86 90,-99.5 81.5,-93.18 79.41,-99.86\"/>\n</g>\n<!-- n2&#45;&gt;c8 -->\n<g id=\"edge6\" class=\"edge\">\n<title>n2:e&#45;&gt;c8:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-43.5C66.5,-43.5 71.26,-38.33 80.01,-35.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"80.55,-39.29 90,-34.5 79.63,-32.35 80.55,-39.29\"/>\n</g>\n<!-- n3 -->\n<g id=\"node3\" class=\"node\">\n<title>n3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"397,-71.04 397,-85.96 381.18,-96.5 358.82,-96.5 343,-85.96 343,-71.04 358.82,-60.5 381.18,-60.5 397,-71.04\"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">out</text>\n</g>\n<!-- x0 -->\n<g id=\"node5\" class=\"node\">\n<title>x0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M256,-90.5C256,-90.5 295,-90.5 295,-90.5 301,-90.5 307,-96.5 307,-102.5 307,-102.5 307,-114.5 307,-114.5 307,-120.5 301,-126.5 295,-126.5 295,-126.5 256,-126.5 256,-126.5 250,-126.5 244,-120.5 244,-114.5 244,-114.5 244,-102.5 244,-102.5 244,-96.5 250,-90.5 256,-90.5\"/>\n<text text-anchor=\"middle\" x=\"275.5\" y=\"-104.8\" font-family=\"Times,serif\" font-size=\"14.00\">0:0 &#45; 0:0</text>\n</g>\n<!-- c7&#45;&gt;x0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>c7:e&#45;&gt;x0:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M220.23,-110.8C224.3,-110.32 227.73,-109.68 231.8,-109.19\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"219.98,-110.82 214.22,-115.15 208,-111.5 213.76,-107.17 219.98,-110.82\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"232.02,-109.18 237.78,-104.85 244,-108.5 238.24,-112.83 232.02,-109.18\"/>\n</g>\n<!-- x0&#45;&gt;n3 -->\n<g id=\"edge7\" class=\"edge\">\n<title>x0:e&#45;&gt;n3:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M307,-108.5C323.76,-108.5 323.37,-89.07 333.43,-81.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"334.5,-84.82 343,-78.5 332.41,-78.14 334.5,-84.82\"/>\n</g>\n<!-- x1 -->\n<g id=\"node7\" class=\"node\">\n<title>x1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M256,-33.5C256,-33.5 295,-33.5 295,-33.5 301,-33.5 307,-39.5 307,-45.5 307,-45.5 307,-57.5 307,-57.5 307,-63.5 301,-69.5 295,-69.5 295,-69.5 256,-69.5 256,-69.5 250,-69.5 244,-63.5 244,-57.5 244,-57.5 244,-45.5 244,-45.5 244,-39.5 250,-33.5 256,-33.5\"/>\n<text text-anchor=\"middle\" x=\"275.5\" y=\"-47.8\" font-family=\"Times,serif\" font-size=\"14.00\">0:0 &#45; 1:1</text>\n</g>\n<!-- c8&#45;&gt;x1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>c8:e&#45;&gt;x1:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M220,-47.61C224.25,-48.44 227.76,-49.57 232.02,-50.39\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"219.95,-47.61 213.61,-51.04 208,-46.5 214.34,-43.07 219.95,-47.61\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"232.05,-50.4 238.39,-46.97 244,-51.5 237.66,-54.93 232.05,-50.4\"/>\n</g>\n<!-- x1&#45;&gt;n3 -->\n<g id=\"edge8\" class=\"edge\">\n<title>x1:e&#45;&gt;n3:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M307,-51.5C322.94,-51.5 323.63,-68.65 333.38,-75.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"332.42,-78.98 343,-78.5 334.43,-72.27 332.42,-78.98\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7b1d5198f850>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90512ce-74c1-40f1-dd88-951316fe87d1",
        "id": "jdaUbtpMoSB8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 88272\n",
            "-rw-r--r--  1 root root     1921 May 27 21:08 '=1.4'\n",
            "-rw-r--r--  1 root root      106 May 27 21:35  adder.v\n",
            "drwxrwxr-x  2 root root     4096 Nov  5  2021  cmos\n",
            "-rw-r--r--  1 root root  1061608 May 27 21:25  dfg_tj_rtl.pkl\n",
            "drwx------  6 root root     4096 May 27 21:07  drive\n",
            "drwxr-xr-x  6 root root     4096 May 27 16:54  hw2vec\n",
            "drwxr-xr-x  2 root root     4096 May 27 21:24  hw2vec_logs\n",
            "-rw-r--r--  1 root root      226 May 27 21:25  metadata.tsv\n",
            "-rw-r--r--  1 root root 89026327 May 27 21:34  Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
            "drwxr-xr-x 16 root root     4096 May 27 21:34  miniconda-synth\n",
            "-rw-r--r--  1 root root      211 May 27 21:25  model.cfg\n",
            "-rw-r--r--  1 root root   198620 May 27 21:25  model.pth\n",
            "drwxr-xr-x  1 root root     4096 May 23 13:39  sample_data\n",
            "-rw-r--r--  1 root root     1757 May 27 21:06  synth_cmos.dot\n",
            "-rw-r--r--  1 root root      489 May 27 21:35  synth_design.dot\n",
            "-rw-r--r--  1 root root      973 May 27 21:35  synth_gate.dot\n",
            "-rw-r--r--  1 root root    39006 May 27 21:25  vectors.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I34dkQ01xSOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a31f92-fe84-4dc8-8cc3-a0bca3982a04"
      },
      "source": [
        "!curl --silent -L https://github.com/YosysHQ/yosys/archive/refs/tags/yosys-0.11.tar.gz | tar xvzf - yosys-yosys-0.11/examples/cmos --strip-components=2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yosys-yosys-0.11/examples/cmos/\n",
            "yosys-yosys-0.11/examples/cmos/.gitignore\n",
            "yosys-yosys-0.11/examples/cmos/README\n",
            "yosys-yosys-0.11/examples/cmos/cmos_cells.lib\n",
            "yosys-yosys-0.11/examples/cmos/cmos_cells.sp\n",
            "yosys-yosys-0.11/examples/cmos/cmos_cells.v\n",
            "yosys-yosys-0.11/examples/cmos/cmos_cells_digital.sp\n",
            "yosys-yosys-0.11/examples/cmos/counter.v\n",
            "yosys-yosys-0.11/examples/cmos/counter.ys\n",
            "yosys-yosys-0.11/examples/cmos/counter_digital.ys\n",
            "yosys-yosys-0.11/examples/cmos/counter_tb.gtkw\n",
            "yosys-yosys-0.11/examples/cmos/counter_tb.v\n",
            "yosys-yosys-0.11/examples/cmos/testbench.sh\n",
            "yosys-yosys-0.11/examples/cmos/testbench.sp\n",
            "yosys-yosys-0.11/examples/cmos/testbench_digital.sh\n",
            "yosys-yosys-0.11/examples/cmos/testbench_digital.sp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2cny9dXwLE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3ee0ce56-d28c-4474-bf98-cb6be5d249a0"
      },
      "source": [
        "%%script miniconda-synth/bin/yosys -Q -T\n",
        "\n",
        "read -sv adder.v\n",
        "hierarchy -top adder\n",
        "\n",
        "read -sv -lib cmos/cmos_cells.v\n",
        "synth\n",
        "dfflibmap -liberty cmos/cmos_cells.lib\n",
        "abc -liberty cmos/cmos_cells.lib\n",
        "\n",
        "opt_clean\n",
        "show -format dot -prefix synth_cmos\n",
        "stat -liberty cmos/cmos_cells.lib"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "yosys> \n",
            "yosys> \n",
            "\n",
            "1. Executing Verilog-2005 frontend: adder.v\n",
            "Parsing SystemVerilog input from `adder.v' to AST representation.\n",
            "Storing AST representation for module `$abstract\\adder'.\n",
            "Successfully finished Verilog frontend.\n",
            "\n",
            "yosys> \n",
            "2. Executing HIERARCHY pass (managing design hierarchy).\n",
            "\n",
            "3. Executing AST frontend in derive mode using pre-parsed AST for module `\\adder'.\n",
            "Generating RTLIL representation for module `\\adder'.\n",
            "\n",
            "3.1. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "\n",
            "3.2. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "Removing unused module `$abstract\\adder'.\n",
            "Removed 1 unused modules.\n",
            "\n",
            "yosys> \n",
            "yosys> \n",
            "4. Executing Verilog-2005 frontend: cmos/cmos_cells.v\n",
            "Parsing SystemVerilog input from `cmos/cmos_cells.v' to AST representation.\n",
            "Storing AST representation for module `$abstract\\BUF'.\n",
            "Storing AST representation for module `$abstract\\NOT'.\n",
            "Storing AST representation for module `$abstract\\NAND'.\n",
            "Storing AST representation for module `$abstract\\NOR'.\n",
            "Storing AST representation for module `$abstract\\DFF'.\n",
            "Storing AST representation for module `$abstract\\DFFSR'.\n",
            "Successfully finished Verilog frontend.\n",
            "\n",
            "yosys> \n",
            "5. Executing SYNTH pass.\n",
            "\n",
            "5.1. Executing HIERARCHY pass (managing design hierarchy).\n",
            "\n",
            "5.1.1. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "\n",
            "5.1.2. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "Removing unused module `$abstract\\DFFSR'.\n",
            "Removing unused module `$abstract\\DFF'.\n",
            "Removing unused module `$abstract\\NOR'.\n",
            "Removing unused module `$abstract\\NAND'.\n",
            "Removing unused module `$abstract\\NOT'.\n",
            "Removing unused module `$abstract\\BUF'.\n",
            "Removed 6 unused modules.\n",
            "\n",
            "5.2. Executing PROC pass (convert processes to netlists).\n",
            "\n",
            "5.2.1. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
            "Cleaned up 0 empty switches.\n",
            "\n",
            "5.2.2. Executing PROC_RMDEAD pass (remove dead branches from decision trees).\n",
            "Removed a total of 0 dead cases.\n",
            "\n",
            "5.2.3. Executing PROC_PRUNE pass (remove redundant assignments in processes).\n",
            "Removed 0 redundant assignments.\n",
            "Promoted 0 assignments to connections.\n",
            "\n",
            "5.2.4. Executing PROC_INIT pass (extract init attributes).\n",
            "\n",
            "5.2.5. Executing PROC_ARST pass (detect async resets in processes).\n",
            "\n",
            "5.2.6. Executing PROC_MUX pass (convert decision trees to multiplexers).\n",
            "\n",
            "5.2.7. Executing PROC_DLATCH pass (convert process syncs to latches).\n",
            "\n",
            "5.2.8. Executing PROC_DFF pass (convert process syncs to FFs).\n",
            "\n",
            "5.2.9. Executing PROC_MEMWR pass (convert process memory writes to cells).\n",
            "\n",
            "5.2.10. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
            "Cleaned up 0 empty switches.\n",
            "\n",
            "5.2.11. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.3. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "Removed 0 unused cells and 1 unused wires.\n",
            "\n",
            "5.5. Executing CHECK pass (checking for obvious problems).\n",
            "Checking module adder...\n",
            "Found and reported 0 problems.\n",
            "\n",
            "5.6. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.6.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.6.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.6.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.6.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.6.5. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.6.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.6.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.6.8. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.6.9. Finished OPT passes. (There is nothing left to do.)\n",
            "\n",
            "5.7. Executing FSM pass (extract and optimize FSM).\n",
            "\n",
            "5.7.1. Executing FSM_DETECT pass (finding FSMs in design).\n",
            "\n",
            "5.7.2. Executing FSM_EXTRACT pass (extracting FSM from design).\n",
            "\n",
            "5.7.3. Executing FSM_OPT pass (simple optimizations of FSMs).\n",
            "\n",
            "5.7.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.7.5. Executing FSM_OPT pass (simple optimizations of FSMs).\n",
            "\n",
            "5.7.6. Executing FSM_RECODE pass (re-assigning FSM state encoding).\n",
            "\n",
            "5.7.7. Executing FSM_INFO pass (dumping all available information on FSM cells).\n",
            "\n",
            "5.7.8. Executing FSM_MAP pass (mapping FSMs to basic logic).\n",
            "\n",
            "5.8. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.8.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.8.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.8.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.8.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.8.5. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.8.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.8.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.8.8. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.8.9. Finished OPT passes. (There is nothing left to do.)\n",
            "\n",
            "5.9. Executing WREDUCE pass (reducing word size of cells).\n",
            "\n",
            "5.10. Executing PEEPOPT pass (run peephole optimizers).\n",
            "\n",
            "5.11. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.12. Executing ALUMACC pass (create $alu and $macc cells).\n",
            "Extracting $alu and $macc cells in module adder:\n",
            "  creating $macc model for $add$adder.v:7$1 ($add).\n",
            "  creating $alu model for $macc $add$adder.v:7$1.\n",
            "  creating $alu cell for $add$adder.v:7$1: $auto$alumacc.cc:485:replace_alu$2\n",
            "  created 1 $alu and 0 $macc cells.\n",
            "\n",
            "5.13. Executing SHARE pass (SAT-based resource sharing).\n",
            "\n",
            "5.14. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.14.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.14.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.14.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.14.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.14.5. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.14.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.14.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.14.8. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.14.9. Finished OPT passes. (There is nothing left to do.)\n",
            "\n",
            "5.15. Executing MEMORY pass.\n",
            "\n",
            "5.15.1. Executing OPT_MEM pass (optimize memories).\n",
            "Performed a total of 0 transformations.\n",
            "\n",
            "5.15.2. Executing OPT_MEM_PRIORITY pass (removing unnecessary memory write priority relations).\n",
            "Performed a total of 0 transformations.\n",
            "\n",
            "5.15.3. Executing OPT_MEM_FEEDBACK pass (finding memory read-to-write feedback paths).\n",
            "\n",
            "5.15.4. Executing MEMORY_DFF pass (merging $dff cells to $memrd).\n",
            "\n",
            "5.15.5. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.15.6. Executing MEMORY_SHARE pass (consolidating $memrd/$memwr cells).\n",
            "\n",
            "5.15.7. Executing OPT_MEM_WIDEN pass (optimize memories where all ports are wide).\n",
            "Performed a total of 0 transformations.\n",
            "\n",
            "5.15.8. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.15.9. Executing MEMORY_COLLECT pass (generating $mem cells).\n",
            "\n",
            "5.16. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.17. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.17.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.17.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.17.3. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.17.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.17.5. Finished fast OPT passes.\n",
            "\n",
            "5.18. Executing MEMORY_MAP pass (converting memories to logic and flip-flops).\n",
            "\n",
            "5.19. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.19.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.19.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.19.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
            "Running muxtree optimizer on module \\adder..\n",
            "  Creating internal representation of mux trees.\n",
            "  No muxes found in this module.\n",
            "Removed 0 multiplexer ports.\n",
            "\n",
            "5.19.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
            "  Optimizing cells in module \\adder.\n",
            "Performed a total of 0 changes.\n",
            "\n",
            "5.19.5. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.19.6. Executing OPT_SHARE pass.\n",
            "\n",
            "5.19.7. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.19.8. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "\n",
            "5.19.9. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.19.10. Finished OPT passes. (There is nothing left to do.)\n",
            "\n",
            "5.20. Executing TECHMAP pass (map to technology primitives).\n",
            "\n",
            "5.20.1. Executing Verilog-2005 frontend: /content/miniconda-synth/bin/../share/yosys/techmap.v\n",
            "Parsing Verilog input from `/content/miniconda-synth/bin/../share/yosys/techmap.v' to AST representation.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_bool_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_reduce_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_logic_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_compare_ops'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_various'.\n",
            "Generating RTLIL representation for module `\\_90_simplemap_registers'.\n",
            "Generating RTLIL representation for module `\\_90_shift_ops_shr_shl_sshl_sshr'.\n",
            "Generating RTLIL representation for module `\\_90_shift_shiftx'.\n",
            "Generating RTLIL representation for module `\\_90_fa'.\n",
            "Generating RTLIL representation for module `\\_90_lcu'.\n",
            "Generating RTLIL representation for module `\\_90_alu'.\n",
            "Generating RTLIL representation for module `\\_90_macc'.\n",
            "Generating RTLIL representation for module `\\_90_alumacc'.\n",
            "Generating RTLIL representation for module `\\$__div_mod_u'.\n",
            "Generating RTLIL representation for module `\\$__div_mod_trunc'.\n",
            "Generating RTLIL representation for module `\\_90_div'.\n",
            "Generating RTLIL representation for module `\\_90_mod'.\n",
            "Generating RTLIL representation for module `\\$__div_mod_floor'.\n",
            "Generating RTLIL representation for module `\\_90_divfloor'.\n",
            "Generating RTLIL representation for module `\\_90_modfloor'.\n",
            "Generating RTLIL representation for module `\\_90_pow'.\n",
            "Generating RTLIL representation for module `\\_90_pmux'.\n",
            "Generating RTLIL representation for module `\\_90_demux'.\n",
            "Generating RTLIL representation for module `\\_90_lut'.\n",
            "Successfully finished Verilog frontend.\n",
            "\n",
            "5.20.2. Continuing TECHMAP pass.\n",
            "Using template $paramod$1d1e68f77481583066c6d429218f48ea9d5739b3\\_90_alu for cells of type $alu.\n",
            "Using extmapper simplemap for cells of type $xor.\n",
            "Using extmapper simplemap for cells of type $and.\n",
            "Using template $paramod\\_90_lcu\\WIDTH=32'00000000000000000000000000000010 for cells of type $lcu.\n",
            "Using extmapper simplemap for cells of type $pos.\n",
            "Using extmapper simplemap for cells of type $mux.\n",
            "Using extmapper simplemap for cells of type $not.\n",
            "Using extmapper simplemap for cells of type $or.\n",
            "No more expansions possible.\n",
            "\n",
            "5.21. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.21.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.21.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.21.3. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.21.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "Removed 1 unused cells and 29 unused wires.\n",
            "\n",
            "5.21.5. Finished fast OPT passes.\n",
            "\n",
            "5.22. Executing ABC pass (technology mapping using ABC).\n",
            "\n",
            "5.22.1. Extracting gate netlist of module `\\adder' to `<abc-temp-dir>/input.blif'..\n",
            "Extracted 2 gates and 4 wires to a netlist network with 2 inputs and 2 outputs.\n",
            "\n",
            "5.22.1.1. Executing ABC.\n",
            "Running ABC command: <yosys-exe-dir>/yosys-abc -s -f <abc-temp-dir>/abc.script 2>&1\n",
            "ABC: ABC command line: \"source <abc-temp-dir>/abc.script\".\n",
            "ABC: \n",
            "ABC: + read_blif <abc-temp-dir>/input.blif \n",
            "ABC: + read_library <abc-temp-dir>/stdcells.genlib \n",
            "ABC: Entered genlib library with 13 gates from file \"<abc-temp-dir>/stdcells.genlib\".\n",
            "ABC: + strash \n",
            "ABC: + dretime \n",
            "ABC: + map \n",
            "ABC: + write_blif <abc-temp-dir>/output.blif \n",
            "\n",
            "5.22.1.2. Re-integrating ABC results.\n",
            "ABC RESULTS:               AND cells:        1\n",
            "ABC RESULTS:               XOR cells:        1\n",
            "ABC RESULTS:        internal signals:        0\n",
            "ABC RESULTS:           input signals:        2\n",
            "ABC RESULTS:          output signals:        2\n",
            "Removing temp directory.\n",
            "\n",
            "5.23. Executing OPT pass (performing simple optimizations).\n",
            "\n",
            "5.23.1. Executing OPT_EXPR pass (perform const folding).\n",
            "Optimizing module adder.\n",
            "\n",
            "5.23.2. Executing OPT_MERGE pass (detect identical cells).\n",
            "Finding identical cells in module `\\adder'.\n",
            "Removed a total of 0 cells.\n",
            "\n",
            "5.23.3. Executing OPT_DFF pass (perform DFF optimizations).\n",
            "\n",
            "5.23.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "Removed 0 unused cells and 4 unused wires.\n",
            "\n",
            "5.23.5. Finished fast OPT passes.\n",
            "\n",
            "5.24. Executing HIERARCHY pass (managing design hierarchy).\n",
            "\n",
            "5.24.1. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "\n",
            "5.24.2. Analyzing design hierarchy..\n",
            "Top module:  \\adder\n",
            "Removed 0 unused modules.\n",
            "\n",
            "5.25. Printing statistics.\n",
            "\n",
            "=== adder ===\n",
            "\n",
            "   Number of wires:                  3\n",
            "   Number of wire bits:              4\n",
            "   Number of public wires:           3\n",
            "   Number of public wire bits:       4\n",
            "   Number of memories:               0\n",
            "   Number of memory bits:            0\n",
            "   Number of processes:              0\n",
            "   Number of cells:                  2\n",
            "     $_AND_                          1\n",
            "     $_XOR_                          1\n",
            "\n",
            "5.26. Executing CHECK pass (checking for obvious problems).\n",
            "Checking module adder...\n",
            "Found and reported 0 problems.\n",
            "\n",
            "yosys> \n",
            "6. Executing DFFLIBMAP pass (mapping DFF cells to sequential cells from liberty file).\n",
            "  cell DFF (noninv, pins=3, area=18.00) is a direct match for cell type $_DFF_P_.\n",
            "  cell DFFSR (noninv, pins=5, area=18.00) is a direct match for cell type $_DFFSR_PPP_.\n",
            "  final dff cell mappings:\n",
            "    unmapped dff cell: $_DFF_N_\n",
            "    \\DFF _DFF_P_ (.C( C), .D( D), .Q( Q));\n",
            "    unmapped dff cell: $_DFF_NN0_\n",
            "    unmapped dff cell: $_DFF_NN1_\n",
            "    unmapped dff cell: $_DFF_NP0_\n",
            "    unmapped dff cell: $_DFF_NP1_\n",
            "    unmapped dff cell: $_DFF_PN0_\n",
            "    unmapped dff cell: $_DFF_PN1_\n",
            "    unmapped dff cell: $_DFF_PP0_\n",
            "    unmapped dff cell: $_DFF_PP1_\n",
            "    unmapped dff cell: $_DFFSR_NNN_\n",
            "    unmapped dff cell: $_DFFSR_NNP_\n",
            "    unmapped dff cell: $_DFFSR_NPN_\n",
            "    unmapped dff cell: $_DFFSR_NPP_\n",
            "    unmapped dff cell: $_DFFSR_PNN_\n",
            "    unmapped dff cell: $_DFFSR_PNP_\n",
            "    unmapped dff cell: $_DFFSR_PPN_\n",
            "    \\DFFSR _DFFSR_PPP_ (.C( C), .D( D), .Q( Q), .R( R), .S( S));\n",
            "\n",
            "6.1. Executing DFFLEGALIZE pass (convert FFs to types supported by the target).\n",
            "Mapping DFF cells in module `\\adder':\n",
            "\n",
            "yosys> \n",
            "7. Executing ABC pass (technology mapping using ABC).\n",
            "\n",
            "7.1. Extracting gate netlist of module `\\adder' to `<abc-temp-dir>/input.blif'..\n",
            "Extracted 2 gates and 4 wires to a netlist network with 2 inputs and 2 outputs.\n",
            "\n",
            "7.1.1. Executing ABC.\n",
            "Running ABC command: <yosys-exe-dir>/yosys-abc -s -f <abc-temp-dir>/abc.script 2>&1\n",
            "ABC: ABC command line: \"source <abc-temp-dir>/abc.script\".\n",
            "ABC: \n",
            "ABC: + read_blif <abc-temp-dir>/input.blif \n",
            "ABC: + read_lib -w /content/cmos/cmos_cells.lib \n",
            "ABC: Parsing finished successfully.  Parsing time =     0.00 sec\n",
            "ABC: Warning: Templates are not defined.\n",
            "ABC: Libery parser cannot read \"time_unit\".  Assuming   time_unit : \"1ns\".\n",
            "ABC: Libery parser cannot read \"capacitive_load_unit\". Assuming   capacitive_load_unit(1, pf).\n",
            "ABC: Scl_LibertyReadGenlib() skipped sequential cell \"DFF\".\n",
            "ABC: Scl_LibertyReadGenlib() skipped sequential cell \"DFFSR\".\n",
            "ABC: Library \"demo\" from \"/content/cmos/cmos_cells.lib\" has 4 cells (2 skipped: 2 seq; 0 tri-state; 0 no func; 0 dont_use).  Time =     0.00 sec\n",
            "ABC: Memory =    0.00 MB. Time =     0.00 sec\n",
            "ABC: + strash \n",
            "ABC: + ifraig \n",
            "ABC: + scorr \n",
            "ABC: Warning: The network is combinational (run \"fraig\" or \"fraig_sweep\").\n",
            "ABC: + dc2 \n",
            "ABC: + dretime \n",
            "ABC: + strash \n",
            "ABC: + &get -n \n",
            "ABC: + &dch -f \n",
            "ABC: + &nf \n",
            "ABC: + &put \n",
            "ABC: + write_blif <abc-temp-dir>/output.blif \n",
            "\n",
            "7.1.2. Re-integrating ABC results.\n",
            "ABC RESULTS:               NOR cells:        3\n",
            "ABC RESULTS:               NOT cells:        2\n",
            "ABC RESULTS:        internal signals:        0\n",
            "ABC RESULTS:           input signals:        2\n",
            "ABC RESULTS:          output signals:        2\n",
            "Removing temp directory.\n",
            "\n",
            "yosys> \n",
            "yosys> \n",
            "8. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
            "Finding unused cells or wires in module \\adder..\n",
            "Removed 0 unused cells and 4 unused wires.\n",
            "\n",
            "yosys> \n",
            "9. Generating Graphviz representation of design.\n",
            "Writing dot description to `synth_cmos.dot'.\n",
            "Dumping module adder to page 1.\n",
            "\n",
            "yosys> \n",
            "10. Printing statistics.\n",
            "\n",
            "=== adder ===\n",
            "\n",
            "   Number of wires:                  6\n",
            "   Number of wire bits:              7\n",
            "   Number of public wires:           3\n",
            "   Number of public wire bits:       4\n",
            "   Number of memories:               0\n",
            "   Number of memory bits:            0\n",
            "   Number of processes:              0\n",
            "   Number of cells:                  5\n",
            "     NOR                             3\n",
            "     NOT                             2\n",
            "\n",
            "   Chip area for module '\\adder': 18.000000\n",
            "\n",
            "\n",
            "yosys> exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "8FhBL03awLE2",
        "outputId": "36a9c46b-cfa5-44b7-fb4e-8756e4aed35b"
      },
      "source": [
        "import graphviz\n",
        "graphviz.Source.from_file('synth_cmos.dot')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: adder Pages: 1 -->\n<svg width=\"359pt\" height=\"450pt\"\n viewBox=\"0.00 0.00 359.20 450.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 446)\">\n<title>adder</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-446 355.2,-446 355.2,4 -4,4\"/>\n<text text-anchor=\"middle\" x=\"175.6\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">adder</text>\n<!-- n4 -->\n<g id=\"node1\" class=\"node\">\n<title>n4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"184.1,-251.04 184.1,-265.96 168.28,-276.5 145.91,-276.5 130.1,-265.96 130.1,-251.04 145.91,-240.5 168.28,-240.5 184.1,-251.04\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-254.8\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n</g>\n<!-- c9 -->\n<g id=\"node4\" class=\"node\">\n<title>c9</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"260.7,-182.5 260.7,-228.5 350.7,-228.5 350.7,-182.5 260.7,-182.5\"/>\n<text text-anchor=\"middle\" x=\"273.7\" y=\"-213.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.7,-205.5 286.7,-205.5 \"/>\n<text text-anchor=\"middle\" x=\"273.7\" y=\"-190.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"286.7,-182.5 286.7,-228.5 \"/>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-209.3\" font-family=\"Times,serif\" font-size=\"14.00\">$112</text>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-194.3\" font-family=\"Times,serif\" font-size=\"14.00\">NOT</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"330.7,-182.5 330.7,-228.5 \"/>\n<text text-anchor=\"middle\" x=\"340.7\" y=\"-201.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n</g>\n<!-- n4&#45;&gt;c9 -->\n<g id=\"edge11\" class=\"edge\">\n<title>n4:e&#45;&gt;c9:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.1,-258.5C219.41,-258.5 221.98,-225.12 250.1,-218.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"250.63,-222.06 260.2,-217.5 249.88,-215.1 250.63,-222.06\"/>\n</g>\n<!-- c13 -->\n<g id=\"node8\" class=\"node\">\n<title>c13</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"260.2,-248 260.2,-317 351.2,-317 351.2,-248 260.2,-248\"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.2,-294 286.2,-294 \"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-278.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.2,-271 286.2,-271 \"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-255.8\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"286.2,-248 286.2,-317 \"/>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-286.3\" font-family=\"Times,serif\" font-size=\"14.00\">$115</text>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-271.3\" font-family=\"Times,serif\" font-size=\"14.00\">NOR</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"331.2,-248 331.2,-317 \"/>\n<text text-anchor=\"middle\" x=\"341.2\" y=\"-278.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n</g>\n<!-- n4&#45;&gt;c13 -->\n<g id=\"edge10\" class=\"edge\">\n<title>n4:e&#45;&gt;c13:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.1,-258.5C220.78,-258.5 221.13,-297.1 250.19,-304.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"249.86,-307.82 260.2,-305.5 250.67,-300.87 249.86,-307.82\"/>\n</g>\n<!-- n5 -->\n<g id=\"node2\" class=\"node\">\n<title>n5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"184.1,-197.04 184.1,-211.96 168.28,-222.5 145.91,-222.5 130.1,-211.96 130.1,-197.04 145.91,-186.5 168.28,-186.5 184.1,-197.04\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n</g>\n<!-- c10 -->\n<g id=\"node5\" class=\"node\">\n<title>c10</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"260.7,-117.5 260.7,-163.5 350.7,-163.5 350.7,-117.5 260.7,-117.5\"/>\n<text text-anchor=\"middle\" x=\"273.7\" y=\"-148.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.7,-140.5 286.7,-140.5 \"/>\n<text text-anchor=\"middle\" x=\"273.7\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"286.7,-117.5 286.7,-163.5 \"/>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-144.3\" font-family=\"Times,serif\" font-size=\"14.00\">$113</text>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-129.3\" font-family=\"Times,serif\" font-size=\"14.00\">NOT</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"330.7,-117.5 330.7,-163.5 \"/>\n<text text-anchor=\"middle\" x=\"340.7\" y=\"-136.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n</g>\n<!-- n5&#45;&gt;c10 -->\n<g id=\"edge12\" class=\"edge\">\n<title>n5:e&#45;&gt;c10:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.1,-204.5C206.22,-204.5 206.84,-189.52 224.2,-177.5 236.83,-168.75 239.81,-158.24 250.08,-154.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"250.92,-157.61 260.2,-152.5 249.76,-150.71 250.92,-157.61\"/>\n</g>\n<!-- n5&#45;&gt;c13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>n5:e&#45;&gt;c13:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.1,-204.5C206.22,-204.5 209.19,-216.64 224.2,-231.5 240.99,-248.12 235.17,-273.42 250.2,-280.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"249.71,-284.03 260.2,-282.5 251.05,-277.16 249.71,-284.03\"/>\n</g>\n<!-- n6 -->\n<g id=\"node3\" class=\"node\">\n<title>n6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"54,-306.04 54,-320.96 38.18,-331.5 15.82,-331.5 0,-320.96 0,-306.04 15.82,-295.5 38.18,-295.5 54,-306.04\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-309.8\" font-family=\"Times,serif\" font-size=\"14.00\">out</text>\n</g>\n<!-- x0 -->\n<g id=\"node7\" class=\"node\">\n<title>x0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.6,-23.5C137.6,-23.5 176.6,-23.5 176.6,-23.5 182.6,-23.5 188.6,-29.5 188.6,-35.5 188.6,-35.5 188.6,-47.5 188.6,-47.5 188.6,-53.5 182.6,-59.5 176.6,-59.5 176.6,-59.5 137.6,-59.5 137.6,-59.5 131.6,-59.5 125.6,-53.5 125.6,-47.5 125.6,-47.5 125.6,-35.5 125.6,-35.5 125.6,-29.5 131.6,-23.5 137.6,-23.5\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">1:1 &#45; 0:0</text>\n</g>\n<!-- n6&#45;&gt;x0 -->\n<g id=\"edge14\" class=\"edge\">\n<title>n6:e&#45;&gt;x0:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-313.5C108.81,-313.5 63.01,-117.2 90,-69.5 97.77,-55.77 102.42,-46 114.15,-42.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"114.6,-46.19 124.1,-41.5 113.75,-39.24 114.6,-46.19\"/>\n</g>\n<!-- x1 -->\n<g id=\"node10\" class=\"node\">\n<title>x1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.6,-405.5C137.6,-405.5 176.6,-405.5 176.6,-405.5 182.6,-405.5 188.6,-411.5 188.6,-417.5 188.6,-417.5 188.6,-429.5 188.6,-429.5 188.6,-435.5 182.6,-441.5 176.6,-441.5 176.6,-441.5 137.6,-441.5 137.6,-441.5 131.6,-441.5 125.6,-435.5 125.6,-429.5 125.6,-429.5 125.6,-417.5 125.6,-417.5 125.6,-411.5 131.6,-405.5 137.6,-405.5\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-419.8\" font-family=\"Times,serif\" font-size=\"14.00\">1:1 &#45; 0:0</text>\n</g>\n<!-- n6&#45;&gt;x1 -->\n<g id=\"edge15\" class=\"edge\">\n<title>n6:e&#45;&gt;x1:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-313.5C93.8,-313.5 65.96,-363.78 90,-395.5 99.44,-407.95 103.03,-418.34 114.03,-422.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"113.7,-425.53 124.1,-423.5 114.7,-418.61 113.7,-425.53\"/>\n</g>\n<!-- x2 -->\n<g id=\"node11\" class=\"node\">\n<title>x2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.6,-295.5C137.6,-295.5 176.6,-295.5 176.6,-295.5 182.6,-295.5 188.6,-301.5 188.6,-307.5 188.6,-307.5 188.6,-319.5 188.6,-319.5 188.6,-325.5 182.6,-331.5 176.6,-331.5 176.6,-331.5 137.6,-331.5 137.6,-331.5 131.6,-331.5 125.6,-325.5 125.6,-319.5 125.6,-319.5 125.6,-307.5 125.6,-307.5 125.6,-301.5 131.6,-295.5 137.6,-295.5\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-309.8\" font-family=\"Times,serif\" font-size=\"14.00\">0:0 &#45; 0:0</text>\n</g>\n<!-- n6&#45;&gt;x2 -->\n<g id=\"edge16\" class=\"edge\">\n<title>n6:e&#45;&gt;x2:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M54,-313.5C81.5,-313.5 90.8,-313.5 114.03,-313.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"114.1,-317 124.1,-313.5 114.1,-310 114.1,-317\"/>\n</g>\n<!-- c12 -->\n<g id=\"node6\" class=\"node\">\n<title>c12</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"260.2,-30 260.2,-99 351.2,-99 351.2,-30 260.2,-30\"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.2,-76 286.2,-76 \"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-60.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.2,-53 286.2,-53 \"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"286.2,-30 286.2,-99 \"/>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">$114</text>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">NOR</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"331.2,-30 331.2,-99 \"/>\n<text text-anchor=\"middle\" x=\"341.2\" y=\"-60.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n</g>\n<!-- x0&#45;&gt;c12 -->\n<g id=\"edge1\" class=\"edge\">\n<title>x0:e&#45;&gt;c12:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M202.28,-41.5C220.35,-41.5 229.99,-41.5 248.08,-41.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"202.1,-41.5 196.1,-45.5 190.1,-41.5 196.1,-37.5 202.1,-41.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"248.2,-41.5 254.2,-37.5 260.2,-41.5 254.2,-45.5 248.2,-41.5\"/>\n</g>\n<!-- c14 -->\n<g id=\"node9\" class=\"node\">\n<title>c14</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"260.2,-336 260.2,-405 351.2,-405 351.2,-336 260.2,-336\"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-389.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.2,-382 286.2,-382 \"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-366.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260.2,-359 286.2,-359 \"/>\n<text text-anchor=\"middle\" x=\"273.2\" y=\"-343.8\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"286.2,-336 286.2,-405 \"/>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">$116</text>\n<text text-anchor=\"middle\" x=\"308.7\" y=\"-359.3\" font-family=\"Times,serif\" font-size=\"14.00\">NOR</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"331.2,-336 331.2,-405 \"/>\n<text text-anchor=\"middle\" x=\"341.2\" y=\"-366.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n</g>\n<!-- x1&#45;&gt;c14 -->\n<g id=\"edge2\" class=\"edge\">\n<title>x1:e&#45;&gt;c14:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M202.08,-422.05C221.64,-416.97 228.68,-399.99 248.27,-394.93\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"202.01,-422.06 196.53,-426.75 190.1,-423.5 195.58,-418.81 202.01,-422.06\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"248.28,-394.93 253.76,-390.24 260.2,-393.5 254.72,-398.19 248.28,-394.93\"/>\n</g>\n<!-- x2&#45;&gt;c14 -->\n<g id=\"edge3\" class=\"edge\">\n<title>x2:e&#45;&gt;c14:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M202.27,-315.14C222,-320.9 228.33,-340.15 248.09,-345.88\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"201.99,-315.1 195.51,-318.27 190.1,-313.5 196.58,-310.34 201.99,-315.1\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"248.3,-345.91 254.78,-342.74 260.2,-347.5 253.72,-350.67 248.3,-345.91\"/>\n</g>\n<!-- n1 -->\n<g id=\"node12\" class=\"node\">\n<title>n1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"157.1,-168.5 89.9,-150.5 157.1,-132.5 224.3,-150.5 157.1,-168.5\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-146.8\" font-family=\"Times,serif\" font-size=\"14.00\">$new_n5_</text>\n</g>\n<!-- n1&#45;&gt;c9 -->\n<g id=\"edge5\" class=\"edge\">\n<title>n1:e&#45;&gt;c9:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.2,-150.5C244.84,-150.5 238.89,-179.99 250.39,-190.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"249.6,-193.56 260.2,-193.5 251.88,-186.94 249.6,-193.56\"/>\n</g>\n<!-- n1&#45;&gt;c12 -->\n<g id=\"edge4\" class=\"edge\">\n<title>n1:e&#45;&gt;c12:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.2,-150.5C252.16,-150.5 234.45,-103.12 250.28,-90.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"251.66,-93.78 260.2,-87.5 249.61,-87.08 251.66,-93.78\"/>\n</g>\n<!-- n2 -->\n<g id=\"node13\" class=\"node\">\n<title>n2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"157.1,-114.5 89.9,-96.5 157.1,-78.5 224.3,-96.5 157.1,-114.5\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">$new_n6_</text>\n</g>\n<!-- n2&#45;&gt;c10 -->\n<g id=\"edge6\" class=\"edge\">\n<title>n2:e&#45;&gt;c10:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.2,-96.5C241.42,-96.5 240.38,-117.22 250.46,-125.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"249.6,-128.72 260.2,-128.5 251.78,-122.06 249.6,-128.72\"/>\n</g>\n<!-- n2&#45;&gt;c12 -->\n<g id=\"edge7\" class=\"edge\">\n<title>n2:e&#45;&gt;c12:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.2,-96.5C241.42,-96.5 240.38,-75.78 250.46,-67.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"251.78,-70.94 260.2,-64.5 249.6,-64.28 251.78,-70.94\"/>\n</g>\n<!-- n3 -->\n<g id=\"node14\" class=\"node\">\n<title>n3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"157.1,-386.5 89.9,-368.5 157.1,-350.5 224.3,-368.5 157.1,-386.5\"/>\n<text text-anchor=\"middle\" x=\"157.1\" y=\"-364.8\" font-family=\"Times,serif\" font-size=\"14.00\">$new_n8_</text>\n</g>\n<!-- n3&#45;&gt;c13 -->\n<g id=\"edge8\" class=\"edge\">\n<title>n3:e&#45;&gt;c13:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.2,-368.5C271.23,-368.5 218.78,-275.87 250.27,-261.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"251.03,-264.81 260.2,-259.5 249.72,-257.93 251.03,-264.81\"/>\n</g>\n<!-- n3&#45;&gt;c14 -->\n<g id=\"edge9\" class=\"edge\">\n<title>n3:e&#45;&gt;c14:w</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.2,-368.5C236.22,-368.5 241.44,-369.62 250.07,-370.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"250.09,-373.69 260.2,-370.5 250.31,-366.69 250.09,-373.69\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7b1d510ed510>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ./synth_cmos.dot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkmOoZZyCKfE",
        "outputId": "f319e6a3-7a6e-40cb-90a6-2b13e9fe1941"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digraph \"adder\" {\n",
            "label=\"adder\";\n",
            "rankdir=\"LR\";\n",
            "remincross=true;\n",
            "n4 [ shape=octagon, label=\"a\", color=\"black\", fontcolor=\"black\" ];\n",
            "n5 [ shape=octagon, label=\"b\", color=\"black\", fontcolor=\"black\" ];\n",
            "n6 [ shape=octagon, label=\"out\", color=\"black\", fontcolor=\"black\" ];\n",
            "c9 [ shape=record, label=\"{{<p7> A|<p8> Y}|$112\\nNOT|{}}\" ];\n",
            "c10 [ shape=record, label=\"{{<p7> A|<p8> Y}|$113\\nNOT|{}}\" ];\n",
            "c12 [ shape=record, label=\"{{<p7> A|<p11> B|<p8> Y}|$114\\nNOR|{}}\" ];\n",
            "x0 [ shape=record, style=rounded, label=\"<s0> 1:1 - 0:0 \" ];\n",
            "x0:e -> c12:p8:w [arrowhead=odiamond, arrowtail=odiamond, dir=both, color=\"black\", label=\"\"];\n",
            "c13 [ shape=record, label=\"{{<p7> A|<p11> B|<p8> Y}|$115\\nNOR|{}}\" ];\n",
            "c14 [ shape=record, label=\"{{<p7> A|<p11> B|<p8> Y}|$116\\nNOR|{}}\" ];\n",
            "x1 [ shape=record, style=rounded, label=\"<s0> 1:1 - 0:0 \" ];\n",
            "x1:e -> c14:p7:w [arrowhead=odiamond, arrowtail=odiamond, dir=both, color=\"black\", label=\"\"];\n",
            "x2 [ shape=record, style=rounded, label=\"<s0> 0:0 - 0:0 \" ];\n",
            "x2:e -> c14:p8:w [arrowhead=odiamond, arrowtail=odiamond, dir=both, color=\"black\", label=\"\"];\n",
            "n1 [ shape=diamond, label=\"$new_n5_\" ];\n",
            "n1:e -> c12:p7:w [color=\"black\", label=\"\"];\n",
            "n1:e -> c9:p8:w [color=\"black\", label=\"\"];\n",
            "n2 [ shape=diamond, label=\"$new_n6_\" ];\n",
            "n2:e -> c10:p8:w [color=\"black\", label=\"\"];\n",
            "n2:e -> c12:p11:w [color=\"black\", label=\"\"];\n",
            "n3 [ shape=diamond, label=\"$new_n8_\" ];\n",
            "n3:e -> c13:p8:w [color=\"black\", label=\"\"];\n",
            "n3:e -> c14:p11:w [color=\"black\", label=\"\"];\n",
            "n4:e -> c13:p7:w [color=\"black\", label=\"\"];\n",
            "n4:e -> c9:p7:w [color=\"black\", label=\"\"];\n",
            "n5:e -> c10:p7:w [color=\"black\", label=\"\"];\n",
            "n5:e -> c13:p11:w [color=\"black\", label=\"\"];\n",
            "n6:e -> x0:s0:w [color=\"black\", label=\"\"];\n",
            "n6:e -> x1:s0:w [color=\"black\", label=\"\"];\n",
            "n6:e -> x2:s0:w [color=\"black\", label=\"\"];\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l\n",
        "!apt-get update && apt-get install -y graphviz libgraphviz-dev\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e95b15a-be5f-4736-9d03-a49385aabc52",
        "collapsed": true,
        "id": "hgLjEmfQ-jwx"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 88272\n",
            "-rw-r--r--  1 root root     1921 May 27 21:08 '=1.4'\n",
            "-rw-r--r--  1 root root      106 May 27 21:35  adder.v\n",
            "drwxrwxr-x  2 root root     4096 Nov  5  2021  cmos\n",
            "-rw-r--r--  1 root root  1061608 May 27 21:25  dfg_tj_rtl.pkl\n",
            "drwx------  6 root root     4096 May 27 21:07  drive\n",
            "drwxr-xr-x  6 root root     4096 May 27 16:54  hw2vec\n",
            "drwxr-xr-x  2 root root     4096 May 27 21:24  hw2vec_logs\n",
            "-rw-r--r--  1 root root      226 May 27 21:25  metadata.tsv\n",
            "-rw-r--r--  1 root root 89026327 May 27 21:34  Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
            "drwxr-xr-x 16 root root     4096 May 27 21:34  miniconda-synth\n",
            "-rw-r--r--  1 root root      211 May 27 21:25  model.cfg\n",
            "-rw-r--r--  1 root root   198620 May 27 21:25  model.pth\n",
            "drwxr-xr-x  1 root root     4096 May 23 13:39  sample_data\n",
            "-rw-r--r--  1 root root     1757 May 27 21:35  synth_cmos.dot\n",
            "-rw-r--r--  1 root root      489 May 27 21:35  synth_design.dot\n",
            "-rw-r--r--  1 root root      973 May 27 21:35  synth_gate.dot\n",
            "-rw-r--r--  1 root root    39006 May 27 21:25  vectors.tsv\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "libgraphviz-dev is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
            "Requirement already satisfied: pygraphviz in /usr/local/lib/python3.11/dist-packages (1.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading in .dot file from the yosys output ... okay"
      ],
      "metadata": {
        "id": "K7iolKnoFYEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "# Read the graph from the .dot file\n",
        "graph = nx.drawing.nx_agraph.read_dot(\"./synth_cmos.dot\")\n",
        "\n",
        "print(\"> graph:\")\n",
        "print(graph)\n",
        "print(\"> nodes:\")\n",
        "print(graph.nodes())\n",
        "print(\"> edges:\")\n",
        "print(graph.edges())\n",
        "\n",
        "print(\"> Showing graph!\")\n",
        "nx.draw(graph)\n",
        "\n",
        "\n",
        "\n",
        "# The 'graph' variable now contains a NetworkX graph object\n",
        "# You can perform operations on it, such as:\n",
        "# - Accessing nodes: graph.nodes()\n",
        "# - Accessing edges: graph.edges()\n",
        "# - Drawing the graph: nx.draw(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "vC6EnLGR-o9q",
        "outputId": "f239d6aa-2ead-4cb4-9348-f0a915f0ddab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> graph:\n",
            "MultiDiGraph named 'adder' with 14 nodes and 16 edges\n",
            "> nodes:\n",
            "['n4', 'n5', 'n6', 'c9', 'c10', 'c12', 'x0', 'c13', 'c14', 'x1', 'x2', 'n1', 'n2', 'n3']\n",
            "> edges:\n",
            "[('n4', 'c9'), ('n4', 'c13'), ('n5', 'c10'), ('n5', 'c13'), ('n6', 'x0'), ('n6', 'x1'), ('n6', 'x2'), ('x0', 'c12'), ('x1', 'c14'), ('x2', 'c14'), ('n1', 'c9'), ('n1', 'c12'), ('n2', 'c10'), ('n2', 'c12'), ('n3', 'c13'), ('n3', 'c14')]\n",
            "> Showing graph!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"> Fancier graph!\")\n",
        "options = {\n",
        "    'node_color': 'blue',\n",
        "    'node_size': 100,\n",
        "    'width': 1,\n",
        "    'arrowstyle': '-|>',\n",
        "    'arrowsize': 12,\n",
        "    'node_size':1500\n",
        "}\n",
        "nx.draw_networkx(graph, arrows=True, **options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GVT4q6awBkLe",
        "outputId": "0040b599-c621-4990-a83d-0612a81b53b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Fancier graph!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing out pyverilog - This is what HW2VEC used"
      ],
      "metadata": {
        "id": "M_kJ1crAFQKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install iverilog\n",
        "!pip3 install jinja2 ply\n",
        "!pip3 install pytest pytest-pythonpath\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yikXZoq-FBQ5",
        "outputId": "669ca0dd-5609-4f02-c43b-5e68c0c161e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "iverilog is already the newest version (11.0-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (3.1.6)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.11/dist-packages (3.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2) (3.0.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (6.2.5)\n",
            "Requirement already satisfied: pytest-pythonpath in /usr/local/lib/python3.11/dist-packages (0.7.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from pytest) (25.3.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest) (24.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest) (1.6.0)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from pytest) (1.11.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from pytest) (0.10.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install pyverilog\n",
        "#!python3 setup.py install\n",
        "!pip install 'git+https://github.com/PyHDI/Pyverilog.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LUHlGoPGQC4",
        "outputId": "6b941793-7b77-4c09-dcb9-5eb10d03b0e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PyHDI/Pyverilog.git\n",
            "  Cloning https://github.com/PyHDI/Pyverilog.git to /tmp/pip-req-build-6y9ek09q\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PyHDI/Pyverilog.git /tmp/pip-req-build-6y9ek09q\n",
            "  Resolved https://github.com/PyHDI/Pyverilog.git to commit 81838bc463d17148ef6872af34eb27585ee349ba\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.11/dist-packages (from pyverilog==1.3.0) (3.1.6)\n",
            "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.11/dist-packages (from pyverilog==1.3.0) (3.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.10->pyverilog==1.3.0) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l ./\n",
        "#!ls -l /usr/bin/\n",
        "#!ls -l /usr/local/lib/\n",
        "#!ls -l /usr/local/lib/python3.11/dist-packages/\n",
        "#!ls -l /usr/local/lib/python3.11/dist-packages/pyverilog/\n",
        "#!ls -l /usr/local/bin/\n",
        "\n",
        "#!ls -l /Library/\n",
        "#!ls -l /Library/\n",
        "\n",
        "!which parser.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CGNx5vYJG0Ly",
        "outputId": "07d91765-80ba-4cfc-bcad-a6ccd5b50b3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 88272\n",
            "-rw-r--r--  1 root root     1921 May 27 21:08 '=1.4'\n",
            "-rw-r--r--  1 root root      106 May 27 21:35  adder.v\n",
            "drwxrwxr-x  2 root root     4096 Nov  5  2021  cmos\n",
            "-rw-r--r--  1 root root  1061608 May 27 21:25  dfg_tj_rtl.pkl\n",
            "drwx------  6 root root     4096 May 27 21:07  drive\n",
            "drwxr-xr-x  6 root root     4096 May 27 16:54  hw2vec\n",
            "drwxr-xr-x  2 root root     4096 May 27 21:24  hw2vec_logs\n",
            "-rw-r--r--  1 root root      226 May 27 21:25  metadata.tsv\n",
            "-rw-r--r--  1 root root 89026327 May 27 21:34  Miniconda3-py37_4.10.3-Linux-x86_64.sh\n",
            "drwxr-xr-x 16 root root     4096 May 27 21:34  miniconda-synth\n",
            "-rw-r--r--  1 root root      211 May 27 21:25  model.cfg\n",
            "-rw-r--r--  1 root root   198620 May 27 21:25  model.pth\n",
            "drwxr-xr-x  1 root root     4096 May 23 13:39  sample_data\n",
            "-rw-r--r--  1 root root     1757 May 27 21:35  synth_cmos.dot\n",
            "-rw-r--r--  1 root root      489 May 27 21:35  synth_design.dot\n",
            "-rw-r--r--  1 root root      973 May 27 21:35  synth_gate.dot\n",
            "-rw-r--r--  1 root root    39006 May 27 21:25  vectors.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import sys\n",
        "import os\n",
        "from optparse import OptionParser\n",
        "\n",
        "# the next line can be removed after installation\n",
        "#sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
        "\n",
        "import pyverilog\n",
        "from pyverilog.vparser.parser import parse\n",
        "\n",
        "\n",
        "def main():\n",
        "    INFO = \"Verilog code parser\"\n",
        "    VERSION = pyverilog.__version__\n",
        "    USAGE = \"Usage: python example_parser.py file ...\"\n",
        "\n",
        "    #def showVersion():\n",
        "    #    print(INFO)\n",
        "    #    print(VERSION)\n",
        "    #    print(USAGE)\n",
        "    #    sys.exit()\n",
        "\n",
        "    #optparser = OptionParser()\n",
        "    #optparser.add_option(\"-v\", \"--version\", action=\"store_true\", dest=\"showversion\",\n",
        "    #                     default=False, help=\"Show the version\")\n",
        "    #optparser.add_option(\"-I\", \"--include\", dest=\"include\", action=\"append\",\n",
        "    #                     default=[], help=\"Include path\")\n",
        "    #optparser.add_option(\"-D\", dest=\"define\", action=\"append\",\n",
        "    #                     default=[], help=\"Macro Definition\")\n",
        "    #(options, args) = optparser.parse_args()\n",
        "\n",
        "    #filelist = args\n",
        "    filelist = [\"adder.v\"]\n",
        "\n",
        "    #if options.showversion:\n",
        "    #    showVersion()\n",
        "    print(\"here\")\n",
        "    for f in filelist:\n",
        "        if not os.path.exists(f):\n",
        "            raise IOError(\"file not found: \" + f)\n",
        "\n",
        "    #if len(filelist) == 0:\n",
        "    #    showVersion()\n",
        "\n",
        "    ast, directives = parse(filelist)\n",
        "\n",
        "    ast.show()\n",
        "    for lineno, directive in directives:\n",
        "        print('Line %d : %s' % (lineno, directive))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq1a-UYpLiSD",
        "outputId": "40f77d43-b9af-45c3-c818-05f42280a91a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating LALR tables\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source:  (at 2)\n",
            "  Description:  (at 2)\n",
            "    ModuleDef: adder (from 2 to 8)\n",
            "      Paramlist:  (at 0)\n",
            "      Portlist:  (at 2)\n",
            "        Ioport:  (at 3)\n",
            "          Input: a, False (at 3)\n",
            "          Wire: a, False (at 3)\n",
            "        Ioport:  (at 4)\n",
            "          Input: b, False (at 4)\n",
            "          Wire: b, False (at 4)\n",
            "        Ioport:  (at 5)\n",
            "          Output: out, False (at 5)\n",
            "            Width:  (at 5)\n",
            "              IntConst: 1 (at 5)\n",
            "              IntConst: 0 (at 5)\n",
            "          Wire: out, False (at 5)\n",
            "            Width:  (at 5)\n",
            "              IntConst: 1 (at 5)\n",
            "              IntConst: 0 (at 5)\n",
            "      Assign:  (from 7 to 7)\n",
            "        Lvalue:  (at 7)\n",
            "          Identifier: out (at 7)\n",
            "        Rvalue:  (at 7)\n",
            "          Plus:  (at 7)\n",
            "            Identifier: a (at 7)\n",
            "            Identifier: b (at 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: 183 shift/reduce conflicts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the github of hw2vec\n",
        "CHANGED to use the zip file of hw2vec with modifications"
      ],
      "metadata": {
        "id": "8JoFq1gDV1eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original version, but there are folder directories and some errors that I fixed\n",
        "#!git clone https://github.com/AICPS/hw2vec.git\n",
        "#!unzip /content/hw2vec/assets/datasets.zip -d /content/hw2vec/assets/"
      ],
      "metadata": {
        "id": "AxvLa8dEULDr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls -l /content/drive/MyDrive/Colab\\ Notebooks/\n",
        "\n",
        "# unzip the hw2vec I've updated to work in Colab\n",
        "!unzip -o /content/drive/MyDrive/Colab\\ Notebooks/hw2vec.zip -d /content/\n",
        "!unzip -o /content/drive/MyDrive/Colab\\ Notebooks/hw2vec_deb.zip -d /content/\n",
        "#!mv /content/hw2vec_deb /content/hw2vec/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4e1OuKBj9R8",
        "outputId": "bd0d44aa-9b8b-4d1b-e9ae-5853890f43e1",
        "collapsed": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "total 6619\n",
            "-rw------- 1 root root   55932 Jul 30  2024 background_remover.ipynb\n",
            "-rw------- 1 root root    2773 May 21 21:06 GNN_sources_and_notes.ipynb\n",
            "-rw------- 1 root root   33968 May 21 20:52 GNN_tutorial.ipynb\n",
            "-rw------- 1 root root   92108 May 22 19:02 hw2vec2.ipynb\n",
            "-rw------- 1 root root 3155079 May 27 21:34 hw2vec_deb.zip\n",
            "-rw------- 1 root root   39098 May 22 18:39 hw2vec.ipynb\n",
            "-rw------- 1 root root 3126990 May 27 17:53 hw2vec.zip\n",
            "-rw------- 1 root root   21245 May 22 18:11 norm_and_mes_work.ipynb\n",
            "-rw------- 1 root root   27182 May 22 19:36 Untitled0.ipynb\n",
            "-rw------- 1 root root   15135 May 23 14:42 Untitled1.ipynb\n",
            "-rw------- 1 root root  204942 May 27 15:01 yosys.ipynb\n",
            "Archive:  /content/drive/MyDrive/Colab Notebooks/hw2vec_deb.zip\n",
            "   creating: /content/hw2vec_deb/\n",
            "  inflating: /content/hw2vec_deb/.gitignore  \n",
            "  inflating: /content/hw2vec_deb/.travis.yml  \n",
            "   creating: /content/hw2vec_deb/assets/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets.zip  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-BE280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-BE280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CS1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CS1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CS320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CS320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CS640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CS640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY1020/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY1020/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY2000/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY2000/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY290/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY290/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY530/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-CY530/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NC1400/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NC1400/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NC1720/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NC1720/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NC2360/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NC2360/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NR1400/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NR1400/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NR1720/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NR1720/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NR2360/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NR2360/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NS1400/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NS1400/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NS1720/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NS1720/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NS2360/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-NS2360/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-RN1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-RN1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-RN320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-RN320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-RN640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-RN640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-SL1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-SL1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-SL320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-SL320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-SL640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C432/c432-SL640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CS1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CS1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CS320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CS320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CS640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CS640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY1040/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY1040/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY2060/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY2060/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY270/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY270/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY520/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-CY520/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NC1550/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NC1550/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NC1870/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NC1870/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NC2510/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NC2510/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NR1550/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NR1550/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NR1870/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NR1870/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NR2510/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NR2510/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NS1550/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NS1550/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NS1870/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NS1870/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NS2510/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-NS2510/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-RN1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-RN1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-RN320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-RN320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-RN640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-RN640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-SL1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-SL1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-SL320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-SL320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-SL640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C499/c499-SL640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS2560/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS2560/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CS640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY1070/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY1070/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY2030/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY2030/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY310/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY310/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY3880/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY3880/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY590/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-CY590/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC2120/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC2120/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC2440/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC2440/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC3080/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC3080/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC4360/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NC4360/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR2120/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR2120/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR2440/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR2440/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR3080/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR3080/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR4360/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NR4360/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS2120/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS2120/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS2440/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS2440/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS3080/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS3080/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS4360/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-NS4360/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN2560/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN2560/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-RN640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL1280/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL1280/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL2560/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL2560/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL320/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL320/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL640/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-Netlist-toy/C880/c880-SL640/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_1/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_1/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_2/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_2/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_3/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_3/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_4/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_4/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_5/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_5/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_6/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_6/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_7/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/adder4bit/adder4bit_7/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_1/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_1/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_2/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_2/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_3/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_3/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_4/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_4/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_5/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_5/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_6/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_6/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_7/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_7/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_8/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/bcdToseg/bcdToseg_8/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_1/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_1/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_2/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_2/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_3/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_3/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_4/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_4/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_5/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_5/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_6/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/IP-RTL-toy/encoder8to3/encoder8to3_6/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/det_1011/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/det_1011/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/PIC16F84/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/PIC16F84/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/RC5/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/RC5/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/RC6/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/RC6/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/RS232/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/RS232/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/spi_master/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/spi_master/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/syncRAM/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/syncRAM/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/vga/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/vga/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/xtea/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjFree/xtea/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/\n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T100/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T100/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T200/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T200/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T300/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T300/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T400/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/PIC16F84-T400/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T100/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T100/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T100/RS232-T100.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T100/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T100/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T200/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T200/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T200/RS232-T200.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T200/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T200/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T300/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T300/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T300/RS232-T300.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T300/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T300/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T400/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T400/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T400/RS232-T400.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T400/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T400/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T500/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T500/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T500/RS232-T500.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T500/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T500/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T600/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T600/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T600/RS232-T600.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T600/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T600/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T700/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T700/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T700/RS232-T700.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T700/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T700/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T800/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T800/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T800/RS232-T800.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T800/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T800/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T900/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T900/Read me.txt  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T900/RS232-T900.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T900/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T900/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T901/\n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T901/RS232-T901.pdf  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T901/Spec.doc  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T901/specification.md  \n",
            "  inflating: /content/hw2vec_deb/assets/datasets/TJ-RTL-toy/TjIn/RS232-T901/topModule.v  \n",
            "   creating: /content/hw2vec_deb/assets/pretrained_AST_IP_RTL/\n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_AST_IP_RTL/model.cfg  \n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_AST_IP_RTL/model.pth  \n",
            "   creating: /content/hw2vec_deb/assets/pretrained_AST_TJ_RTL/\n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_AST_TJ_RTL/model.cfg  \n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_AST_TJ_RTL/model.pth  \n",
            "   creating: /content/hw2vec_deb/assets/pretrained_DFG_IP_RTL/\n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_DFG_IP_RTL/model.cfg  \n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_DFG_IP_RTL/model.pth  \n",
            "   creating: /content/hw2vec_deb/assets/pretrained_DFG_TJ_RTL/\n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_DFG_TJ_RTL/model.cfg  \n",
            "  inflating: /content/hw2vec_deb/assets/pretrained_DFG_TJ_RTL/model.pth  \n",
            "   creating: /content/hw2vec_deb/examples/\n",
            "  inflating: /content/hw2vec_deb/examples/example_gnn4ip.yaml  \n",
            "  inflating: /content/hw2vec_deb/examples/example_gnn4tj.yaml  \n",
            "  inflating: /content/hw2vec_deb/examples/use_case_1.py  \n",
            "  inflating: /content/hw2vec_deb/examples/use_case_2.py  \n",
            "  inflating: /content/hw2vec_deb/examples/use_case_3.py  \n",
            "   creating: /content/hw2vec_deb/figures/\n",
            "  inflating: /content/hw2vec_deb/figures/archi.png  \n",
            "   creating: /content/hw2vec_deb/hw2vec/\n",
            "  inflating: /content/hw2vec_deb/hw2vec/config.py  \n",
            "   creating: /content/hw2vec_deb/hw2vec/configs/\n",
            "  inflating: /content/hw2vec_deb/hw2vec/configs/DFG-IP-NetList.yaml  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/configs/IP-RTL.yaml  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/configs/TJ-RTL.yaml  \n",
            "   creating: /content/hw2vec_deb/hw2vec/graph2vec/\n",
            "  inflating: /content/hw2vec_deb/hw2vec/graph2vec/models.py  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/graph2vec/trainers.py  \n",
            " extracting: /content/hw2vec_deb/hw2vec/graph2vec/__init__.py  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/hw2graph.py  \n",
            "   creating: /content/hw2vec_deb/hw2vec/scripts/\n",
            "  inflating: /content/hw2vec_deb/hw2vec/scripts/exp1.sh  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/scripts/graph_processer.py  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/utilities.py  \n",
            " extracting: /content/hw2vec_deb/hw2vec/_version.py  \n",
            " extracting: /content/hw2vec_deb/hw2vec/__init__.py  \n",
            "   creating: /content/hw2vec_deb/hw2vec/__pycache__/\n",
            "  inflating: /content/hw2vec_deb/hw2vec/__pycache__/config.cpython-313.pyc  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/__pycache__/hw2graph.cpython-313.pyc  \n",
            "  inflating: /content/hw2vec_deb/hw2vec/__pycache__/__init__.cpython-313.pyc  \n",
            "  inflating: /content/hw2vec_deb/LICENSE  \n",
            "  inflating: /content/hw2vec_deb/README.md  \n",
            "  inflating: /content/hw2vec_deb/requirements.txt  \n",
            "  inflating: /content/hw2vec_deb/requirements_dev.txt  \n",
            "  inflating: /content/hw2vec_deb/setup.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup pytorch geometric"
      ],
      "metadata": {
        "id": "_7qljrFkVwZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"../data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaipk3oMY36U",
        "outputId": "93834043-fbad-40a1-e0d1-e0b114e27326"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-ebf0b716a7e6>:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch geometric\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version.\n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-geometric\n",
        "    import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data"
      ],
      "metadata": {
        "id": "2lFvgij8YrKF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l\n",
        "!ls -l /content/hw2vec/assets/TJ-RTL-toy/TjFree/det_1011/\n",
        "!pwd\n",
        "#%env PYTHONPATH=/content/:$PYTHONPATH\n",
        "#!python /content/hw2vec/examples/use_case_1.py\n",
        "#!python /content/hw2vec/examples/use_case_2.py --yaml_path ./hw2vec/examples/example_gnn4tj.yaml --raw_dataset_path ./hw2vec/assets/datasets/TJ-RTL-toy --data_pkl_path dfg_tj_rtl.pkl --graph_type DFG --device cuda\n",
        "!python /content/hw2vec_deb/examples/use_case_2.py --yaml_path ./hw2vec_deb/examples/example_gnn4tj.yaml --raw_dataset_path ./hw2vec_deb/assets/datasets/TJ-RTL-toy --data_pkl_path dfg_tj_rtl.pkl --graph_type DFG --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-5tbNtCUSSL",
        "outputId": "43c3f586-bcb8-485d-9fcd-7d0cd0c6f96d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2025-05-27 21:36:26,488 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([883, 200]), Edge index shape: torch.Size([2, 1057])\n",
            "2025-05-27 21:36:26,488 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([883, 200])\n",
            "2025-05-27 21:36:26,489 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([883, 200]) -> torch.Size([883, 200])\n",
            "2025-05-27 21:36:26,489 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([883, 200]), Batch size: 2\n",
            "2025-05-27 21:36:26,490 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([708, 200]), Nodes kept: 708/883 (80.2%)\n",
            "2025-05-27 21:36:26,491 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([883, 200]) -> torch.Size([708, 200])\n",
            "2025-05-27 21:36:26,491 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([708, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:26,491 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,491 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([708, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,491 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,491 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,491 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:26,492 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0417\n",
            "Epoch: 0161, loss_train: 0.0500, time: 0.1s:  80% 161/200 [00:15<00:04,  9.48it/s]2025-05-27 21:36:26,494 - trainers.GraphTrainer - INFO - train:427 - Epoch 161 completed - Avg loss: 0.0500, Time: 0.1s\n",
            "2025-05-27 21:36:26,494 - trainers.GraphTrainer - INFO - train:427 - Epoch 161 completed - Avg loss: 0.0500, Time: 0.1s\n",
            "2025-05-27 21:36:26,496 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 7945 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,497 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 7945, Edges: 11126, Graphs: 4\n",
            "2025-05-27 21:36:26,497 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([7945]) -> torch.Size([7945, 37])\n",
            "2025-05-27 21:36:26,497 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7945, 37]), Edge index shape: torch.Size([2, 11126])\n",
            "2025-05-27 21:36:26,498 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7945, 200])\n",
            "2025-05-27 21:36:26,498 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([7945, 37]) -> torch.Size([7945, 200])\n",
            "2025-05-27 21:36:26,498 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7945, 200]), Edge index shape: torch.Size([2, 11126])\n",
            "2025-05-27 21:36:26,499 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7945, 200])\n",
            "2025-05-27 21:36:26,499 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([7945, 200]) -> torch.Size([7945, 200])\n",
            "2025-05-27 21:36:26,500 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([7945, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,502 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6357, 200]), Nodes kept: 6357/7945 (80.0%)\n",
            "2025-05-27 21:36:26,502 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([7945, 200]) -> torch.Size([6357, 200])\n",
            "2025-05-27 21:36:26,502 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6357, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,502 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,502 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6357, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,502 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,502 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,503 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,503 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:26,507 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 162, Batch 0/5, Loss: 0.0000\n",
            "2025-05-27 21:36:26,509 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6163 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,509 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6163, Edges: 7075, Graphs: 4\n",
            "2025-05-27 21:36:26,509 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6163]) -> torch.Size([6163, 37])\n",
            "2025-05-27 21:36:26,509 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6163, 37]), Edge index shape: torch.Size([2, 7075])\n",
            "2025-05-27 21:36:26,510 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6163, 200])\n",
            "2025-05-27 21:36:26,510 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6163, 37]) -> torch.Size([6163, 200])\n",
            "2025-05-27 21:36:26,510 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6163, 200]), Edge index shape: torch.Size([2, 7075])\n",
            "2025-05-27 21:36:26,511 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6163, 200])\n",
            "2025-05-27 21:36:26,511 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6163, 200]) -> torch.Size([6163, 200])\n",
            "2025-05-27 21:36:26,512 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6163, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,514 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4932, 200]), Nodes kept: 4932/6163 (80.0%)\n",
            "2025-05-27 21:36:26,514 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6163, 200]) -> torch.Size([4932, 200])\n",
            "2025-05-27 21:36:26,514 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4932, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,514 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,514 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4932, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,514 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,514 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,514 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,515 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0157\n",
            "2025-05-27 21:36:26,520 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2448 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,520 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2448, Edges: 2904, Graphs: 4\n",
            "2025-05-27 21:36:26,520 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2448]) -> torch.Size([2448, 37])\n",
            "2025-05-27 21:36:26,520 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2448, 37]), Edge index shape: torch.Size([2, 2904])\n",
            "2025-05-27 21:36:26,521 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2448, 200])\n",
            "2025-05-27 21:36:26,521 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2448, 37]) -> torch.Size([2448, 200])\n",
            "2025-05-27 21:36:26,521 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2448, 200]), Edge index shape: torch.Size([2, 2904])\n",
            "2025-05-27 21:36:26,522 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2448, 200])\n",
            "2025-05-27 21:36:26,522 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2448, 200]) -> torch.Size([2448, 200])\n",
            "2025-05-27 21:36:26,522 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2448, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,524 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1959, 200]), Nodes kept: 1959/2448 (80.0%)\n",
            "2025-05-27 21:36:26,524 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2448, 200]) -> torch.Size([1959, 200])\n",
            "2025-05-27 21:36:26,524 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1959, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,524 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,524 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1959, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,524 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,524 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,525 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,525 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0242\n",
            "2025-05-27 21:36:26,528 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1853 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,529 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1853, Edges: 2255, Graphs: 4\n",
            "2025-05-27 21:36:26,529 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1853]) -> torch.Size([1853, 37])\n",
            "2025-05-27 21:36:26,529 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1853, 37]), Edge index shape: torch.Size([2, 2255])\n",
            "2025-05-27 21:36:26,530 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1853, 200])\n",
            "2025-05-27 21:36:26,530 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1853, 37]) -> torch.Size([1853, 200])\n",
            "2025-05-27 21:36:26,530 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1853, 200]), Edge index shape: torch.Size([2, 2255])\n",
            "2025-05-27 21:36:26,531 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1853, 200])\n",
            "2025-05-27 21:36:26,531 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1853, 200]) -> torch.Size([1853, 200])\n",
            "2025-05-27 21:36:26,531 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1853, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,533 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1484, 200]), Nodes kept: 1484/1853 (80.1%)\n",
            "2025-05-27 21:36:26,533 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1853, 200]) -> torch.Size([1484, 200])\n",
            "2025-05-27 21:36:26,533 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1484, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,533 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,533 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1484, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,533 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,533 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,534 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,534 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0016\n",
            "2025-05-27 21:36:26,539 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3304 nodes, 2 graphs\n",
            "2025-05-27 21:36:26,539 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3304, Edges: 4477, Graphs: 2\n",
            "2025-05-27 21:36:26,539 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3304]) -> torch.Size([3304, 37])\n",
            "2025-05-27 21:36:26,539 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3304, 37]), Edge index shape: torch.Size([2, 4477])\n",
            "2025-05-27 21:36:26,540 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3304, 200])\n",
            "2025-05-27 21:36:26,540 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3304, 37]) -> torch.Size([3304, 200])\n",
            "2025-05-27 21:36:26,540 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3304, 200]), Edge index shape: torch.Size([2, 4477])\n",
            "2025-05-27 21:36:26,541 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3304, 200])\n",
            "2025-05-27 21:36:26,542 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3304, 200]) -> torch.Size([3304, 200])\n",
            "2025-05-27 21:36:26,542 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3304, 200]), Batch size: 2\n",
            "2025-05-27 21:36:26,543 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2644, 200]), Nodes kept: 2644/3304 (80.0%)\n",
            "2025-05-27 21:36:26,543 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3304, 200]) -> torch.Size([2644, 200])\n",
            "2025-05-27 21:36:26,544 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2644, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:26,544 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,544 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2644, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,544 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,544 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,544 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:26,545 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2263\n",
            "Epoch: 0162, loss_train: 0.0536, time: 0.1s:  80% 161/200 [00:15<00:04,  9.48it/s]2025-05-27 21:36:26,548 - trainers.GraphTrainer - INFO - train:427 - Epoch 162 completed - Avg loss: 0.0536, Time: 0.1s\n",
            "2025-05-27 21:36:26,548 - trainers.GraphTrainer - INFO - train:427 - Epoch 162 completed - Avg loss: 0.0536, Time: 0.1s\n",
            "Epoch: 0162, loss_train: 0.0536, time: 0.1s:  82% 163/200 [00:15<00:03, 10.72it/s]2025-05-27 21:36:26,549 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4604 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,550 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4604, Edges: 5366, Graphs: 4\n",
            "2025-05-27 21:36:26,579 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4604]) -> torch.Size([4604, 37])\n",
            "2025-05-27 21:36:26,579 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4604, 37]), Edge index shape: torch.Size([2, 5366])\n",
            "2025-05-27 21:36:26,580 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4604, 200])\n",
            "2025-05-27 21:36:26,581 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4604, 37]) -> torch.Size([4604, 200])\n",
            "2025-05-27 21:36:26,581 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4604, 200]), Edge index shape: torch.Size([2, 5366])\n",
            "2025-05-27 21:36:26,582 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4604, 200])\n",
            "2025-05-27 21:36:26,584 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4604, 200]) -> torch.Size([4604, 200])\n",
            "2025-05-27 21:36:26,585 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4604, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,593 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3684, 200]), Nodes kept: 3684/4604 (80.0%)\n",
            "2025-05-27 21:36:26,593 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4604, 200]) -> torch.Size([3684, 200])\n",
            "2025-05-27 21:36:26,593 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3684, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,594 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,594 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3684, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,594 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,594 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,595 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,596 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0321\n",
            "2025-05-27 21:36:26,601 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 163, Batch 0/5, Loss: 0.0321\n",
            "2025-05-27 21:36:26,603 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5988 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,603 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5988, Edges: 7548, Graphs: 4\n",
            "2025-05-27 21:36:26,604 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5988]) -> torch.Size([5988, 37])\n",
            "2025-05-27 21:36:26,604 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5988, 37]), Edge index shape: torch.Size([2, 7548])\n",
            "2025-05-27 21:36:26,605 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5988, 200])\n",
            "2025-05-27 21:36:26,605 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5988, 37]) -> torch.Size([5988, 200])\n",
            "2025-05-27 21:36:26,606 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5988, 200]), Edge index shape: torch.Size([2, 7548])\n",
            "2025-05-27 21:36:26,607 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5988, 200])\n",
            "2025-05-27 21:36:26,607 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5988, 200]) -> torch.Size([5988, 200])\n",
            "2025-05-27 21:36:26,607 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5988, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,609 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4791, 200]), Nodes kept: 4791/5988 (80.0%)\n",
            "2025-05-27 21:36:26,610 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5988, 200]) -> torch.Size([4791, 200])\n",
            "2025-05-27 21:36:26,610 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4791, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,610 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,610 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4791, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,610 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,610 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,611 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,611 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0021\n",
            "2025-05-27 21:36:26,621 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2302 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,621 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2302, Edges: 2754, Graphs: 4\n",
            "2025-05-27 21:36:26,621 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2302]) -> torch.Size([2302, 37])\n",
            "2025-05-27 21:36:26,621 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2302, 37]), Edge index shape: torch.Size([2, 2754])\n",
            "2025-05-27 21:36:26,624 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2302, 200])\n",
            "2025-05-27 21:36:26,625 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2302, 37]) -> torch.Size([2302, 200])\n",
            "2025-05-27 21:36:26,625 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2302, 200]), Edge index shape: torch.Size([2, 2754])\n",
            "2025-05-27 21:36:26,626 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2302, 200])\n",
            "2025-05-27 21:36:26,626 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2302, 200]) -> torch.Size([2302, 200])\n",
            "2025-05-27 21:36:26,626 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2302, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,628 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1843, 200]), Nodes kept: 1843/2302 (80.1%)\n",
            "2025-05-27 21:36:26,631 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2302, 200]) -> torch.Size([1843, 200])\n",
            "2025-05-27 21:36:26,631 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1843, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,632 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,632 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1843, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,632 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,632 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,632 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,633 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1136\n",
            "2025-05-27 21:36:26,638 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6039 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,641 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6039, Edges: 8280, Graphs: 4\n",
            "2025-05-27 21:36:26,641 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6039]) -> torch.Size([6039, 37])\n",
            "2025-05-27 21:36:26,642 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6039, 37]), Edge index shape: torch.Size([2, 8280])\n",
            "2025-05-27 21:36:26,642 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6039, 200])\n",
            "2025-05-27 21:36:26,643 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6039, 37]) -> torch.Size([6039, 200])\n",
            "2025-05-27 21:36:26,643 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6039, 200]), Edge index shape: torch.Size([2, 8280])\n",
            "2025-05-27 21:36:26,644 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6039, 200])\n",
            "2025-05-27 21:36:26,644 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6039, 200]) -> torch.Size([6039, 200])\n",
            "2025-05-27 21:36:26,644 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6039, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,647 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4833, 200]), Nodes kept: 4833/6039 (80.0%)\n",
            "2025-05-27 21:36:26,647 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6039, 200]) -> torch.Size([4833, 200])\n",
            "2025-05-27 21:36:26,649 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4833, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,649 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,650 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4833, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,650 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,650 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,650 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,650 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0707\n",
            "2025-05-27 21:36:26,656 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2780 nodes, 2 graphs\n",
            "2025-05-27 21:36:26,656 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2780, Edges: 3889, Graphs: 2\n",
            "2025-05-27 21:36:26,656 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2780]) -> torch.Size([2780, 37])\n",
            "2025-05-27 21:36:26,656 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2780, 37]), Edge index shape: torch.Size([2, 3889])\n",
            "2025-05-27 21:36:26,657 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,657 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2780, 37]) -> torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,658 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2780, 200]), Edge index shape: torch.Size([2, 3889])\n",
            "2025-05-27 21:36:26,659 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,659 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2780, 200]) -> torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,659 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2780, 200]), Batch size: 2\n",
            "2025-05-27 21:36:26,661 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2225, 200]), Nodes kept: 2225/2780 (80.0%)\n",
            "2025-05-27 21:36:26,661 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2780, 200]) -> torch.Size([2225, 200])\n",
            "2025-05-27 21:36:26,661 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2225, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:26,662 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,662 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2225, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,662 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,662 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,662 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:26,662 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0019\n",
            "Epoch: 0163, loss_train: 0.0441, time: 0.1s:  82% 163/200 [00:15<00:03, 10.72it/s]2025-05-27 21:36:26,665 - trainers.GraphTrainer - INFO - train:427 - Epoch 163 completed - Avg loss: 0.0441, Time: 0.1s\n",
            "2025-05-27 21:36:26,665 - trainers.GraphTrainer - INFO - train:427 - Epoch 163 completed - Avg loss: 0.0441, Time: 0.1s\n",
            "2025-05-27 21:36:26,667 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1776 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,667 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1776, Edges: 2187, Graphs: 4\n",
            "2025-05-27 21:36:26,668 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1776]) -> torch.Size([1776, 37])\n",
            "2025-05-27 21:36:26,668 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1776, 37]), Edge index shape: torch.Size([2, 2187])\n",
            "2025-05-27 21:36:26,669 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1776, 200])\n",
            "2025-05-27 21:36:26,669 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1776, 37]) -> torch.Size([1776, 200])\n",
            "2025-05-27 21:36:26,669 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1776, 200]), Edge index shape: torch.Size([2, 2187])\n",
            "2025-05-27 21:36:26,670 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1776, 200])\n",
            "2025-05-27 21:36:26,671 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1776, 200]) -> torch.Size([1776, 200])\n",
            "2025-05-27 21:36:26,671 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1776, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,673 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1422, 200]), Nodes kept: 1422/1776 (80.1%)\n",
            "2025-05-27 21:36:26,673 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1776, 200]) -> torch.Size([1422, 200])\n",
            "2025-05-27 21:36:26,674 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1422, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,674 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,674 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1422, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,674 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,674 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,675 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,675 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0003\n",
            "2025-05-27 21:36:26,679 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 164, Batch 0/5, Loss: 0.0003\n",
            "2025-05-27 21:36:26,681 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1765 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,681 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1765, Edges: 2143, Graphs: 4\n",
            "2025-05-27 21:36:26,681 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1765]) -> torch.Size([1765, 37])\n",
            "2025-05-27 21:36:26,681 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1765, 37]), Edge index shape: torch.Size([2, 2143])\n",
            "2025-05-27 21:36:26,682 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1765, 200])\n",
            "2025-05-27 21:36:26,682 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1765, 37]) -> torch.Size([1765, 200])\n",
            "2025-05-27 21:36:26,683 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1765, 200]), Edge index shape: torch.Size([2, 2143])\n",
            "2025-05-27 21:36:26,684 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1765, 200])\n",
            "2025-05-27 21:36:26,684 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1765, 200]) -> torch.Size([1765, 200])\n",
            "2025-05-27 21:36:26,684 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1765, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,686 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1414, 200]), Nodes kept: 1414/1765 (80.1%)\n",
            "2025-05-27 21:36:26,686 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1765, 200]) -> torch.Size([1414, 200])\n",
            "2025-05-27 21:36:26,687 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1414, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,687 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,687 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1414, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,687 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,687 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,687 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,688 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0460\n",
            "2025-05-27 21:36:26,692 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6529 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,692 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6529, Edges: 8145, Graphs: 4\n",
            "2025-05-27 21:36:26,692 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6529]) -> torch.Size([6529, 37])\n",
            "2025-05-27 21:36:26,692 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6529, 37]), Edge index shape: torch.Size([2, 8145])\n",
            "2025-05-27 21:36:26,693 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6529, 200])\n",
            "2025-05-27 21:36:26,693 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6529, 37]) -> torch.Size([6529, 200])\n",
            "2025-05-27 21:36:26,693 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6529, 200]), Edge index shape: torch.Size([2, 8145])\n",
            "2025-05-27 21:36:26,694 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6529, 200])\n",
            "2025-05-27 21:36:26,695 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6529, 200]) -> torch.Size([6529, 200])\n",
            "2025-05-27 21:36:26,695 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6529, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,697 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5225, 200]), Nodes kept: 5225/6529 (80.0%)\n",
            "2025-05-27 21:36:26,697 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6529, 200]) -> torch.Size([5225, 200])\n",
            "2025-05-27 21:36:26,697 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5225, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,697 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,698 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5225, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,698 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,698 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,698 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,698 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2489\n",
            "2025-05-27 21:36:26,703 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8212 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,704 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8212, Edges: 10742, Graphs: 4\n",
            "2025-05-27 21:36:26,704 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8212]) -> torch.Size([8212, 37])\n",
            "2025-05-27 21:36:26,704 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8212, 37]), Edge index shape: torch.Size([2, 10742])\n",
            "2025-05-27 21:36:26,705 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8212, 200])\n",
            "2025-05-27 21:36:26,705 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8212, 37]) -> torch.Size([8212, 200])\n",
            "2025-05-27 21:36:26,705 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8212, 200]), Edge index shape: torch.Size([2, 10742])\n",
            "2025-05-27 21:36:26,706 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8212, 200])\n",
            "2025-05-27 21:36:26,706 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8212, 200]) -> torch.Size([8212, 200])\n",
            "2025-05-27 21:36:26,707 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8212, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,709 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6570, 200]), Nodes kept: 6570/8212 (80.0%)\n",
            "2025-05-27 21:36:26,709 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8212, 200]) -> torch.Size([6570, 200])\n",
            "2025-05-27 21:36:26,709 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6570, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,709 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,709 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6570, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,710 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,710 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,710 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,710 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0009\n",
            "2025-05-27 21:36:26,716 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3431 nodes, 2 graphs\n",
            "2025-05-27 21:36:26,716 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3431, Edges: 4620, Graphs: 2\n",
            "2025-05-27 21:36:26,716 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3431]) -> torch.Size([3431, 37])\n",
            "2025-05-27 21:36:26,716 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3431, 37]), Edge index shape: torch.Size([2, 4620])\n",
            "2025-05-27 21:36:26,717 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3431, 200])\n",
            "2025-05-27 21:36:26,717 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3431, 37]) -> torch.Size([3431, 200])\n",
            "2025-05-27 21:36:26,717 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3431, 200]), Edge index shape: torch.Size([2, 4620])\n",
            "2025-05-27 21:36:26,718 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3431, 200])\n",
            "2025-05-27 21:36:26,718 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3431, 200]) -> torch.Size([3431, 200])\n",
            "2025-05-27 21:36:26,719 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3431, 200]), Batch size: 2\n",
            "2025-05-27 21:36:26,720 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2745, 200]), Nodes kept: 2745/3431 (80.0%)\n",
            "2025-05-27 21:36:26,720 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3431, 200]) -> torch.Size([2745, 200])\n",
            "2025-05-27 21:36:26,720 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2745, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:26,721 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,721 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2745, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,721 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,721 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,721 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:26,721 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0054\n",
            "Epoch: 0164, loss_train: 0.0603, time: 0.1s:  82% 163/200 [00:15<00:03, 10.72it/s]2025-05-27 21:36:26,724 - trainers.GraphTrainer - INFO - train:427 - Epoch 164 completed - Avg loss: 0.0603, Time: 0.1s\n",
            "2025-05-27 21:36:26,724 - trainers.GraphTrainer - INFO - train:427 - Epoch 164 completed - Avg loss: 0.0603, Time: 0.1s\n",
            "Epoch: 0164, loss_train: 0.0603, time: 0.1s:  82% 165/200 [00:15<00:03, 10.89it/s]2025-05-27 21:36:26,726 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5007 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,727 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5007, Edges: 6586, Graphs: 4\n",
            "2025-05-27 21:36:26,727 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5007]) -> torch.Size([5007, 37])\n",
            "2025-05-27 21:36:26,727 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5007, 37]), Edge index shape: torch.Size([2, 6586])\n",
            "2025-05-27 21:36:26,728 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5007, 200])\n",
            "2025-05-27 21:36:26,728 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5007, 37]) -> torch.Size([5007, 200])\n",
            "2025-05-27 21:36:26,728 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5007, 200]), Edge index shape: torch.Size([2, 6586])\n",
            "2025-05-27 21:36:26,729 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5007, 200])\n",
            "2025-05-27 21:36:26,729 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5007, 200]) -> torch.Size([5007, 200])\n",
            "2025-05-27 21:36:26,729 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5007, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,731 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4007, 200]), Nodes kept: 4007/5007 (80.0%)\n",
            "2025-05-27 21:36:26,731 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5007, 200]) -> torch.Size([4007, 200])\n",
            "2025-05-27 21:36:26,731 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4007, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,732 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,732 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4007, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,732 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,732 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,732 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,732 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0510\n",
            "2025-05-27 21:36:26,736 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 165, Batch 0/5, Loss: 0.0510\n",
            "2025-05-27 21:36:26,737 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4289 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,737 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4289, Edges: 5690, Graphs: 4\n",
            "2025-05-27 21:36:26,738 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4289]) -> torch.Size([4289, 37])\n",
            "2025-05-27 21:36:26,738 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4289, 37]), Edge index shape: torch.Size([2, 5690])\n",
            "2025-05-27 21:36:26,739 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4289, 200])\n",
            "2025-05-27 21:36:26,739 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4289, 37]) -> torch.Size([4289, 200])\n",
            "2025-05-27 21:36:26,739 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4289, 200]), Edge index shape: torch.Size([2, 5690])\n",
            "2025-05-27 21:36:26,740 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4289, 200])\n",
            "2025-05-27 21:36:26,740 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4289, 200]) -> torch.Size([4289, 200])\n",
            "2025-05-27 21:36:26,740 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4289, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,743 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3433, 200]), Nodes kept: 3433/4289 (80.0%)\n",
            "2025-05-27 21:36:26,743 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4289, 200]) -> torch.Size([3433, 200])\n",
            "2025-05-27 21:36:26,743 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3433, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,743 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,743 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3433, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,744 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,744 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,744 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,744 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0683\n",
            "2025-05-27 21:36:26,749 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5909 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,749 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5909, Edges: 7397, Graphs: 4\n",
            "2025-05-27 21:36:26,749 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5909]) -> torch.Size([5909, 37])\n",
            "2025-05-27 21:36:26,749 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5909, 37]), Edge index shape: torch.Size([2, 7397])\n",
            "2025-05-27 21:36:26,750 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5909, 200])\n",
            "2025-05-27 21:36:26,750 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5909, 37]) -> torch.Size([5909, 200])\n",
            "2025-05-27 21:36:26,750 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5909, 200]), Edge index shape: torch.Size([2, 7397])\n",
            "2025-05-27 21:36:26,751 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5909, 200])\n",
            "2025-05-27 21:36:26,751 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5909, 200]) -> torch.Size([5909, 200])\n",
            "2025-05-27 21:36:26,752 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5909, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,753 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4728, 200]), Nodes kept: 4728/5909 (80.0%)\n",
            "2025-05-27 21:36:26,779 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5909, 200]) -> torch.Size([4728, 200])\n",
            "2025-05-27 21:36:26,780 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4728, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,780 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,781 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4728, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,783 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,783 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,783 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,783 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0033\n",
            "2025-05-27 21:36:26,789 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3728 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,789 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3728, Edges: 4275, Graphs: 4\n",
            "2025-05-27 21:36:26,790 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3728]) -> torch.Size([3728, 37])\n",
            "2025-05-27 21:36:26,790 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3728, 37]), Edge index shape: torch.Size([2, 4275])\n",
            "2025-05-27 21:36:26,791 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3728, 200])\n",
            "2025-05-27 21:36:26,792 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3728, 37]) -> torch.Size([3728, 200])\n",
            "2025-05-27 21:36:26,792 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3728, 200]), Edge index shape: torch.Size([2, 4275])\n",
            "2025-05-27 21:36:26,793 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3728, 200])\n",
            "2025-05-27 21:36:26,793 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3728, 200]) -> torch.Size([3728, 200])\n",
            "2025-05-27 21:36:26,793 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3728, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,796 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2983, 200]), Nodes kept: 2983/3728 (80.0%)\n",
            "2025-05-27 21:36:26,796 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3728, 200]) -> torch.Size([2983, 200])\n",
            "2025-05-27 21:36:26,796 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2983, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,796 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,797 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2983, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,797 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,797 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,797 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,797 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0319\n",
            "2025-05-27 21:36:26,802 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2780 nodes, 2 graphs\n",
            "2025-05-27 21:36:26,803 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2780, Edges: 3889, Graphs: 2\n",
            "2025-05-27 21:36:26,803 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2780]) -> torch.Size([2780, 37])\n",
            "2025-05-27 21:36:26,803 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2780, 37]), Edge index shape: torch.Size([2, 3889])\n",
            "2025-05-27 21:36:26,804 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,804 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2780, 37]) -> torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,804 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2780, 200]), Edge index shape: torch.Size([2, 3889])\n",
            "2025-05-27 21:36:26,805 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,805 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2780, 200]) -> torch.Size([2780, 200])\n",
            "2025-05-27 21:36:26,806 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2780, 200]), Batch size: 2\n",
            "2025-05-27 21:36:26,808 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2225, 200]), Nodes kept: 2225/2780 (80.0%)\n",
            "2025-05-27 21:36:26,808 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2780, 200]) -> torch.Size([2225, 200])\n",
            "2025-05-27 21:36:26,808 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2225, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:26,808 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,808 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2225, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,808 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,809 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,809 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:26,809 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0019\n",
            "Epoch: 0165, loss_train: 0.0313, time: 0.1s:  82% 165/200 [00:16<00:03, 10.89it/s]2025-05-27 21:36:26,812 - trainers.GraphTrainer - INFO - train:427 - Epoch 165 completed - Avg loss: 0.0313, Time: 0.1s\n",
            "2025-05-27 21:36:26,812 - trainers.GraphTrainer - INFO - train:427 - Epoch 165 completed - Avg loss: 0.0313, Time: 0.1s\n",
            "2025-05-27 21:36:26,814 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2360 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,814 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2360, Edges: 2810, Graphs: 4\n",
            "2025-05-27 21:36:26,814 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2360]) -> torch.Size([2360, 37])\n",
            "2025-05-27 21:36:26,815 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2360, 37]), Edge index shape: torch.Size([2, 2810])\n",
            "2025-05-27 21:36:26,816 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2360, 200])\n",
            "2025-05-27 21:36:26,816 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2360, 37]) -> torch.Size([2360, 200])\n",
            "2025-05-27 21:36:26,816 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2360, 200]), Edge index shape: torch.Size([2, 2810])\n",
            "2025-05-27 21:36:26,817 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2360, 200])\n",
            "2025-05-27 21:36:26,817 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2360, 200]) -> torch.Size([2360, 200])\n",
            "2025-05-27 21:36:26,817 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2360, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,819 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1890, 200]), Nodes kept: 1890/2360 (80.1%)\n",
            "2025-05-27 21:36:26,819 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2360, 200]) -> torch.Size([1890, 200])\n",
            "2025-05-27 21:36:26,819 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1890, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,820 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,820 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1890, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,820 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,820 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,820 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,820 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0987\n",
            "2025-05-27 21:36:26,823 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 166, Batch 0/5, Loss: 0.0987\n",
            "2025-05-27 21:36:26,825 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5024 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,825 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5024, Edges: 6545, Graphs: 4\n",
            "2025-05-27 21:36:26,826 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5024]) -> torch.Size([5024, 37])\n",
            "2025-05-27 21:36:26,826 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5024, 37]), Edge index shape: torch.Size([2, 6545])\n",
            "2025-05-27 21:36:26,827 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5024, 200])\n",
            "2025-05-27 21:36:26,827 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5024, 37]) -> torch.Size([5024, 200])\n",
            "2025-05-27 21:36:26,827 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5024, 200]), Edge index shape: torch.Size([2, 6545])\n",
            "2025-05-27 21:36:26,828 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5024, 200])\n",
            "2025-05-27 21:36:26,828 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5024, 200]) -> torch.Size([5024, 200])\n",
            "2025-05-27 21:36:26,828 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5024, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,831 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4020, 200]), Nodes kept: 4020/5024 (80.0%)\n",
            "2025-05-27 21:36:26,831 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5024, 200]) -> torch.Size([4020, 200])\n",
            "2025-05-27 21:36:26,831 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4020, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,831 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,831 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4020, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,831 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,831 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,832 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,832 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0013\n",
            "2025-05-27 21:36:26,837 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3838 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,837 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3838, Edges: 4459, Graphs: 4\n",
            "2025-05-27 21:36:26,838 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3838]) -> torch.Size([3838, 37])\n",
            "2025-05-27 21:36:26,838 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3838, 37]), Edge index shape: torch.Size([2, 4459])\n",
            "2025-05-27 21:36:26,839 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3838, 200])\n",
            "2025-05-27 21:36:26,839 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3838, 37]) -> torch.Size([3838, 200])\n",
            "2025-05-27 21:36:26,839 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3838, 200]), Edge index shape: torch.Size([2, 4459])\n",
            "2025-05-27 21:36:26,840 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3838, 200])\n",
            "2025-05-27 21:36:26,840 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3838, 200]) -> torch.Size([3838, 200])\n",
            "2025-05-27 21:36:26,840 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3838, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,842 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3071, 200]), Nodes kept: 3071/3838 (80.0%)\n",
            "2025-05-27 21:36:26,843 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3838, 200]) -> torch.Size([3071, 200])\n",
            "2025-05-27 21:36:26,843 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3071, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,843 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,843 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3071, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,843 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,843 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,843 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,844 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0477\n",
            "2025-05-27 21:36:26,849 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8048 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,849 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8048, Edges: 11275, Graphs: 4\n",
            "2025-05-27 21:36:26,849 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8048]) -> torch.Size([8048, 37])\n",
            "2025-05-27 21:36:26,849 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8048, 37]), Edge index shape: torch.Size([2, 11275])\n",
            "2025-05-27 21:36:26,850 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8048, 200])\n",
            "2025-05-27 21:36:26,850 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8048, 37]) -> torch.Size([8048, 200])\n",
            "2025-05-27 21:36:26,851 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8048, 200]), Edge index shape: torch.Size([2, 11275])\n",
            "2025-05-27 21:36:26,852 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8048, 200])\n",
            "2025-05-27 21:36:26,852 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8048, 200]) -> torch.Size([8048, 200])\n",
            "2025-05-27 21:36:26,853 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8048, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,855 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6440, 200]), Nodes kept: 6440/8048 (80.0%)\n",
            "2025-05-27 21:36:26,855 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8048, 200]) -> torch.Size([6440, 200])\n",
            "2025-05-27 21:36:26,855 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6440, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,855 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,856 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6440, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,856 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,856 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,856 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,856 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0009\n",
            "2025-05-27 21:36:26,863 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2443 nodes, 2 graphs\n",
            "2025-05-27 21:36:26,863 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2443, Edges: 2748, Graphs: 2\n",
            "2025-05-27 21:36:26,863 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2443]) -> torch.Size([2443, 37])\n",
            "2025-05-27 21:36:26,863 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2443, 37]), Edge index shape: torch.Size([2, 2748])\n",
            "2025-05-27 21:36:26,865 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2443, 200])\n",
            "2025-05-27 21:36:26,865 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2443, 37]) -> torch.Size([2443, 200])\n",
            "2025-05-27 21:36:26,865 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2443, 200]), Edge index shape: torch.Size([2, 2748])\n",
            "2025-05-27 21:36:26,866 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2443, 200])\n",
            "2025-05-27 21:36:26,881 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2443, 200]) -> torch.Size([2443, 200])\n",
            "2025-05-27 21:36:26,881 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2443, 200]), Batch size: 2\n",
            "2025-05-27 21:36:26,883 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1955, 200]), Nodes kept: 1955/2443 (80.0%)\n",
            "2025-05-27 21:36:26,883 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2443, 200]) -> torch.Size([1955, 200])\n",
            "2025-05-27 21:36:26,883 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1955, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:26,883 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,883 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1955, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,883 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,883 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,884 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:26,884 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0010\n",
            "Epoch: 0166, loss_train: 0.0299, time: 0.1s:  82% 165/200 [00:16<00:03, 10.89it/s]2025-05-27 21:36:26,886 - trainers.GraphTrainer - INFO - train:427 - Epoch 166 completed - Avg loss: 0.0299, Time: 0.1s\n",
            "2025-05-27 21:36:26,886 - trainers.GraphTrainer - INFO - train:427 - Epoch 166 completed - Avg loss: 0.0299, Time: 0.1s\n",
            "Epoch: 0166, loss_train: 0.0299, time: 0.1s:  84% 167/200 [00:16<00:02, 11.29it/s]2025-05-27 21:36:26,888 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4088 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,888 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4088, Edges: 5396, Graphs: 4\n",
            "2025-05-27 21:36:26,889 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4088]) -> torch.Size([4088, 37])\n",
            "2025-05-27 21:36:26,889 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4088, 37]), Edge index shape: torch.Size([2, 5396])\n",
            "2025-05-27 21:36:26,890 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4088, 200])\n",
            "2025-05-27 21:36:26,890 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4088, 37]) -> torch.Size([4088, 200])\n",
            "2025-05-27 21:36:26,890 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4088, 200]), Edge index shape: torch.Size([2, 5396])\n",
            "2025-05-27 21:36:26,891 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4088, 200])\n",
            "2025-05-27 21:36:26,891 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4088, 200]) -> torch.Size([4088, 200])\n",
            "2025-05-27 21:36:26,891 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4088, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,893 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3272, 200]), Nodes kept: 3272/4088 (80.0%)\n",
            "2025-05-27 21:36:26,893 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4088, 200]) -> torch.Size([3272, 200])\n",
            "2025-05-27 21:36:26,893 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3272, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,894 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,894 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3272, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,894 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,894 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,894 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,894 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2064\n",
            "2025-05-27 21:36:26,897 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 167, Batch 0/5, Loss: 0.2064\n",
            "2025-05-27 21:36:26,899 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5448 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,899 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5448, Edges: 7615, Graphs: 4\n",
            "2025-05-27 21:36:26,899 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5448]) -> torch.Size([5448, 37])\n",
            "2025-05-27 21:36:26,899 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5448, 37]), Edge index shape: torch.Size([2, 7615])\n",
            "2025-05-27 21:36:26,900 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5448, 200])\n",
            "2025-05-27 21:36:26,900 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5448, 37]) -> torch.Size([5448, 200])\n",
            "2025-05-27 21:36:26,901 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5448, 200]), Edge index shape: torch.Size([2, 7615])\n",
            "2025-05-27 21:36:26,901 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5448, 200])\n",
            "2025-05-27 21:36:26,902 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5448, 200]) -> torch.Size([5448, 200])\n",
            "2025-05-27 21:36:26,902 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5448, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,904 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4360, 200]), Nodes kept: 4360/5448 (80.0%)\n",
            "2025-05-27 21:36:26,904 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5448, 200]) -> torch.Size([4360, 200])\n",
            "2025-05-27 21:36:26,904 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4360, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,904 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,904 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4360, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,905 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,905 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,905 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,905 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0015\n",
            "2025-05-27 21:36:26,910 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3916 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,910 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3916, Edges: 4527, Graphs: 4\n",
            "2025-05-27 21:36:26,910 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3916]) -> torch.Size([3916, 37])\n",
            "2025-05-27 21:36:26,910 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3916, 37]), Edge index shape: torch.Size([2, 4527])\n",
            "2025-05-27 21:36:26,911 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3916, 200])\n",
            "2025-05-27 21:36:26,912 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3916, 37]) -> torch.Size([3916, 200])\n",
            "2025-05-27 21:36:26,912 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3916, 200]), Edge index shape: torch.Size([2, 4527])\n",
            "2025-05-27 21:36:26,912 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3916, 200])\n",
            "2025-05-27 21:36:26,913 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3916, 200]) -> torch.Size([3916, 200])\n",
            "2025-05-27 21:36:26,913 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3916, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,915 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3133, 200]), Nodes kept: 3133/3916 (80.0%)\n",
            "2025-05-27 21:36:26,915 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3916, 200]) -> torch.Size([3133, 200])\n",
            "2025-05-27 21:36:26,915 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3133, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,915 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,915 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3133, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,915 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,915 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,916 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,916 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0013\n",
            "2025-05-27 21:36:26,920 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6619 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,920 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6619, Edges: 8306, Graphs: 4\n",
            "2025-05-27 21:36:26,921 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6619]) -> torch.Size([6619, 37])\n",
            "2025-05-27 21:36:26,921 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6619, 37]), Edge index shape: torch.Size([2, 8306])\n",
            "2025-05-27 21:36:26,921 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6619, 200])\n",
            "2025-05-27 21:36:26,922 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6619, 37]) -> torch.Size([6619, 200])\n",
            "2025-05-27 21:36:26,922 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6619, 200]), Edge index shape: torch.Size([2, 8306])\n",
            "2025-05-27 21:36:26,923 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6619, 200])\n",
            "2025-05-27 21:36:26,923 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6619, 200]) -> torch.Size([6619, 200])\n",
            "2025-05-27 21:36:26,923 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6619, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,925 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5297, 200]), Nodes kept: 5297/6619 (80.0%)\n",
            "2025-05-27 21:36:26,925 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6619, 200]) -> torch.Size([5297, 200])\n",
            "2025-05-27 21:36:26,925 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5297, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,926 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,926 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5297, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,926 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,926 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,926 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,926 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0382\n",
            "2025-05-27 21:36:26,932 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1642 nodes, 2 graphs\n",
            "2025-05-27 21:36:26,932 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1642, Edges: 1993, Graphs: 2\n",
            "2025-05-27 21:36:26,932 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1642]) -> torch.Size([1642, 37])\n",
            "2025-05-27 21:36:26,932 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1642, 37]), Edge index shape: torch.Size([2, 1993])\n",
            "2025-05-27 21:36:26,933 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1642, 200])\n",
            "2025-05-27 21:36:26,933 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1642, 37]) -> torch.Size([1642, 200])\n",
            "2025-05-27 21:36:26,933 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1642, 200]), Edge index shape: torch.Size([2, 1993])\n",
            "2025-05-27 21:36:26,934 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1642, 200])\n",
            "2025-05-27 21:36:26,934 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1642, 200]) -> torch.Size([1642, 200])\n",
            "2025-05-27 21:36:26,934 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1642, 200]), Batch size: 2\n",
            "2025-05-27 21:36:26,936 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1314, 200]), Nodes kept: 1314/1642 (80.0%)\n",
            "2025-05-27 21:36:26,936 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1642, 200]) -> torch.Size([1314, 200])\n",
            "2025-05-27 21:36:26,936 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1314, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:26,937 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,937 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1314, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,937 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,937 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:26,937 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:26,937 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0010\n",
            "Epoch: 0167, loss_train: 0.0497, time: 0.1s:  84% 167/200 [00:16<00:02, 11.29it/s]2025-05-27 21:36:26,940 - trainers.GraphTrainer - INFO - train:427 - Epoch 167 completed - Avg loss: 0.0497, Time: 0.1s\n",
            "2025-05-27 21:36:26,940 - trainers.GraphTrainer - INFO - train:427 - Epoch 167 completed - Avg loss: 0.0497, Time: 0.1s\n",
            "2025-05-27 21:36:26,941 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2368 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,942 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2368, Edges: 2823, Graphs: 4\n",
            "2025-05-27 21:36:26,942 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2368]) -> torch.Size([2368, 37])\n",
            "2025-05-27 21:36:26,942 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2368, 37]), Edge index shape: torch.Size([2, 2823])\n",
            "2025-05-27 21:36:26,943 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2368, 200])\n",
            "2025-05-27 21:36:26,943 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2368, 37]) -> torch.Size([2368, 200])\n",
            "2025-05-27 21:36:26,943 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2368, 200]), Edge index shape: torch.Size([2, 2823])\n",
            "2025-05-27 21:36:26,944 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2368, 200])\n",
            "2025-05-27 21:36:26,944 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2368, 200]) -> torch.Size([2368, 200])\n",
            "2025-05-27 21:36:26,944 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2368, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,946 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1896, 200]), Nodes kept: 1896/2368 (80.1%)\n",
            "2025-05-27 21:36:26,946 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2368, 200]) -> torch.Size([1896, 200])\n",
            "2025-05-27 21:36:26,946 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1896, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,947 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,947 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1896, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,947 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,947 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,947 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,947 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2618\n",
            "2025-05-27 21:36:26,984 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 168, Batch 0/5, Loss: 0.2618\n",
            "2025-05-27 21:36:26,989 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4275 nodes, 4 graphs\n",
            "2025-05-27 21:36:26,989 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4275, Edges: 5640, Graphs: 4\n",
            "2025-05-27 21:36:26,989 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4275]) -> torch.Size([4275, 37])\n",
            "2025-05-27 21:36:26,989 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4275, 37]), Edge index shape: torch.Size([2, 5640])\n",
            "2025-05-27 21:36:26,990 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4275, 200])\n",
            "2025-05-27 21:36:26,991 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4275, 37]) -> torch.Size([4275, 200])\n",
            "2025-05-27 21:36:26,991 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4275, 200]), Edge index shape: torch.Size([2, 5640])\n",
            "2025-05-27 21:36:26,992 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4275, 200])\n",
            "2025-05-27 21:36:26,993 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4275, 200]) -> torch.Size([4275, 200])\n",
            "2025-05-27 21:36:26,993 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4275, 200]), Batch size: 4\n",
            "2025-05-27 21:36:26,995 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3422, 200]), Nodes kept: 3422/4275 (80.0%)\n",
            "2025-05-27 21:36:26,995 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4275, 200]) -> torch.Size([3422, 200])\n",
            "2025-05-27 21:36:26,996 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3422, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:26,996 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,996 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3422, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,996 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,996 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:26,996 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:26,997 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0511\n",
            "2025-05-27 21:36:27,002 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5718 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,002 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5718, Edges: 7264, Graphs: 4\n",
            "2025-05-27 21:36:27,003 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5718]) -> torch.Size([5718, 37])\n",
            "2025-05-27 21:36:27,003 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5718, 37]), Edge index shape: torch.Size([2, 7264])\n",
            "2025-05-27 21:36:27,004 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5718, 200])\n",
            "2025-05-27 21:36:27,004 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5718, 37]) -> torch.Size([5718, 200])\n",
            "2025-05-27 21:36:27,004 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5718, 200]), Edge index shape: torch.Size([2, 7264])\n",
            "2025-05-27 21:36:27,005 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5718, 200])\n",
            "2025-05-27 21:36:27,005 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5718, 200]) -> torch.Size([5718, 200])\n",
            "2025-05-27 21:36:27,006 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5718, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,008 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4575, 200]), Nodes kept: 4575/5718 (80.0%)\n",
            "2025-05-27 21:36:27,008 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5718, 200]) -> torch.Size([4575, 200])\n",
            "2025-05-27 21:36:27,008 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4575, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,008 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,008 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4575, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,009 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,009 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,009 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,009 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0003\n",
            "2025-05-27 21:36:27,015 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6900 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,015 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6900, Edges: 9348, Graphs: 4\n",
            "2025-05-27 21:36:27,015 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6900]) -> torch.Size([6900, 37])\n",
            "2025-05-27 21:36:27,015 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6900, 37]), Edge index shape: torch.Size([2, 9348])\n",
            "2025-05-27 21:36:27,016 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6900, 200])\n",
            "2025-05-27 21:36:27,017 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6900, 37]) -> torch.Size([6900, 200])\n",
            "2025-05-27 21:36:27,017 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6900, 200]), Edge index shape: torch.Size([2, 9348])\n",
            "2025-05-27 21:36:27,018 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6900, 200])\n",
            "2025-05-27 21:36:27,018 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6900, 200]) -> torch.Size([6900, 200])\n",
            "2025-05-27 21:36:27,018 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6900, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,020 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5521, 200]), Nodes kept: 5521/6900 (80.0%)\n",
            "2025-05-27 21:36:27,021 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6900, 200]) -> torch.Size([5521, 200])\n",
            "2025-05-27 21:36:27,021 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5521, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,021 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,021 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5521, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,021 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,021 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,021 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,022 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:27,027 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2452 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,028 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2452, Edges: 2762, Graphs: 2\n",
            "2025-05-27 21:36:27,028 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2452]) -> torch.Size([2452, 37])\n",
            "2025-05-27 21:36:27,028 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2452, 37]), Edge index shape: torch.Size([2, 2762])\n",
            "2025-05-27 21:36:27,029 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2452, 200])\n",
            "2025-05-27 21:36:27,029 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2452, 37]) -> torch.Size([2452, 200])\n",
            "2025-05-27 21:36:27,029 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2452, 200]), Edge index shape: torch.Size([2, 2762])\n",
            "2025-05-27 21:36:27,030 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2452, 200])\n",
            "2025-05-27 21:36:27,031 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2452, 200]) -> torch.Size([2452, 200])\n",
            "2025-05-27 21:36:27,031 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2452, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,033 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1962, 200]), Nodes kept: 1962/2452 (80.0%)\n",
            "2025-05-27 21:36:27,033 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2452, 200]) -> torch.Size([1962, 200])\n",
            "2025-05-27 21:36:27,033 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1962, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,033 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,033 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1962, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,033 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,033 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,034 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,034 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0168, loss_train: 0.0627, time: 0.1s:  84% 167/200 [00:16<00:02, 11.29it/s]2025-05-27 21:36:27,037 - trainers.GraphTrainer - INFO - train:427 - Epoch 168 completed - Avg loss: 0.0627, Time: 0.1s\n",
            "2025-05-27 21:36:27,037 - trainers.GraphTrainer - INFO - train:427 - Epoch 168 completed - Avg loss: 0.0627, Time: 0.1s\n",
            "Epoch: 0168, loss_train: 0.0627, time: 0.1s:  84% 169/200 [00:16<00:02, 11.82it/s]2025-05-27 21:36:27,039 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6425 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,040 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6425, Edges: 8094, Graphs: 4\n",
            "2025-05-27 21:36:27,040 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6425]) -> torch.Size([6425, 37])\n",
            "2025-05-27 21:36:27,040 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6425, 37]), Edge index shape: torch.Size([2, 8094])\n",
            "2025-05-27 21:36:27,041 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6425, 200])\n",
            "2025-05-27 21:36:27,041 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6425, 37]) -> torch.Size([6425, 200])\n",
            "2025-05-27 21:36:27,041 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6425, 200]), Edge index shape: torch.Size([2, 8094])\n",
            "2025-05-27 21:36:27,042 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6425, 200])\n",
            "2025-05-27 21:36:27,043 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6425, 200]) -> torch.Size([6425, 200])\n",
            "2025-05-27 21:36:27,043 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6425, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,045 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5141, 200]), Nodes kept: 5141/6425 (80.0%)\n",
            "2025-05-27 21:36:27,045 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6425, 200]) -> torch.Size([5141, 200])\n",
            "2025-05-27 21:36:27,045 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5141, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,045 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,046 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5141, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,046 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,046 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,046 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,046 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0437\n",
            "2025-05-27 21:36:27,050 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 169, Batch 0/5, Loss: 0.0437\n",
            "2025-05-27 21:36:27,052 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2970 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,052 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2970, Edges: 3475, Graphs: 4\n",
            "2025-05-27 21:36:27,052 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2970]) -> torch.Size([2970, 37])\n",
            "2025-05-27 21:36:27,052 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2970, 37]), Edge index shape: torch.Size([2, 3475])\n",
            "2025-05-27 21:36:27,053 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2970, 200])\n",
            "2025-05-27 21:36:27,054 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2970, 37]) -> torch.Size([2970, 200])\n",
            "2025-05-27 21:36:27,054 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2970, 200]), Edge index shape: torch.Size([2, 3475])\n",
            "2025-05-27 21:36:27,055 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2970, 200])\n",
            "2025-05-27 21:36:27,055 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2970, 200]) -> torch.Size([2970, 200])\n",
            "2025-05-27 21:36:27,055 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2970, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,057 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2377, 200]), Nodes kept: 2377/2970 (80.0%)\n",
            "2025-05-27 21:36:27,057 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2970, 200]) -> torch.Size([2377, 200])\n",
            "2025-05-27 21:36:27,057 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2377, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,058 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,058 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2377, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,058 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,058 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,058 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,058 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1741\n",
            "2025-05-27 21:36:27,064 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5908 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,064 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5908, Edges: 7474, Graphs: 4\n",
            "2025-05-27 21:36:27,065 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5908]) -> torch.Size([5908, 37])\n",
            "2025-05-27 21:36:27,065 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5908, 37]), Edge index shape: torch.Size([2, 7474])\n",
            "2025-05-27 21:36:27,066 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5908, 200])\n",
            "2025-05-27 21:36:27,066 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5908, 37]) -> torch.Size([5908, 200])\n",
            "2025-05-27 21:36:27,066 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5908, 200]), Edge index shape: torch.Size([2, 7474])\n",
            "2025-05-27 21:36:27,067 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5908, 200])\n",
            "2025-05-27 21:36:27,067 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5908, 200]) -> torch.Size([5908, 200])\n",
            "2025-05-27 21:36:27,068 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5908, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,070 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4728, 200]), Nodes kept: 4728/5908 (80.0%)\n",
            "2025-05-27 21:36:27,081 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5908, 200]) -> torch.Size([4728, 200])\n",
            "2025-05-27 21:36:27,082 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4728, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,082 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,082 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4728, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,082 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,082 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,083 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,083 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0003\n",
            "2025-05-27 21:36:27,089 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3703 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,089 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3703, Edges: 5037, Graphs: 4\n",
            "2025-05-27 21:36:27,089 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3703]) -> torch.Size([3703, 37])\n",
            "2025-05-27 21:36:27,089 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3703, 37]), Edge index shape: torch.Size([2, 5037])\n",
            "2025-05-27 21:36:27,090 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3703, 200])\n",
            "2025-05-27 21:36:27,090 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3703, 37]) -> torch.Size([3703, 200])\n",
            "2025-05-27 21:36:27,090 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3703, 200]), Edge index shape: torch.Size([2, 5037])\n",
            "2025-05-27 21:36:27,091 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3703, 200])\n",
            "2025-05-27 21:36:27,091 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3703, 200]) -> torch.Size([3703, 200])\n",
            "2025-05-27 21:36:27,091 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3703, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,093 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2964, 200]), Nodes kept: 2964/3703 (80.0%)\n",
            "2025-05-27 21:36:27,093 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3703, 200]) -> torch.Size([2964, 200])\n",
            "2025-05-27 21:36:27,093 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2964, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,094 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,094 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2964, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,094 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,094 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,094 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,094 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0003\n",
            "2025-05-27 21:36:27,099 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2707 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,099 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2707, Edges: 3757, Graphs: 2\n",
            "2025-05-27 21:36:27,099 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2707]) -> torch.Size([2707, 37])\n",
            "2025-05-27 21:36:27,099 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2707, 37]), Edge index shape: torch.Size([2, 3757])\n",
            "2025-05-27 21:36:27,100 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2707, 200])\n",
            "2025-05-27 21:36:27,100 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2707, 37]) -> torch.Size([2707, 200])\n",
            "2025-05-27 21:36:27,100 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2707, 200]), Edge index shape: torch.Size([2, 3757])\n",
            "2025-05-27 21:36:27,101 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2707, 200])\n",
            "2025-05-27 21:36:27,101 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2707, 200]) -> torch.Size([2707, 200])\n",
            "2025-05-27 21:36:27,101 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2707, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,103 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2166, 200]), Nodes kept: 2166/2707 (80.0%)\n",
            "2025-05-27 21:36:27,103 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2707, 200]) -> torch.Size([2166, 200])\n",
            "2025-05-27 21:36:27,103 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2166, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,104 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,104 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2166, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,104 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,104 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,104 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,104 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0030\n",
            "Epoch: 0169, loss_train: 0.0443, time: 0.1s:  84% 169/200 [00:16<00:02, 11.82it/s]2025-05-27 21:36:27,107 - trainers.GraphTrainer - INFO - train:427 - Epoch 169 completed - Avg loss: 0.0443, Time: 0.1s\n",
            "2025-05-27 21:36:27,107 - trainers.GraphTrainer - INFO - train:427 - Epoch 169 completed - Avg loss: 0.0443, Time: 0.1s\n",
            "2025-05-27 21:36:27,109 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3235 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,109 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3235, Edges: 3779, Graphs: 4\n",
            "2025-05-27 21:36:27,109 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3235]) -> torch.Size([3235, 37])\n",
            "2025-05-27 21:36:27,109 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3235, 37]), Edge index shape: torch.Size([2, 3779])\n",
            "2025-05-27 21:36:27,110 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3235, 200])\n",
            "2025-05-27 21:36:27,110 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3235, 37]) -> torch.Size([3235, 200])\n",
            "2025-05-27 21:36:27,110 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3235, 200]), Edge index shape: torch.Size([2, 3779])\n",
            "2025-05-27 21:36:27,111 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3235, 200])\n",
            "2025-05-27 21:36:27,112 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3235, 200]) -> torch.Size([3235, 200])\n",
            "2025-05-27 21:36:27,112 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3235, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,114 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2589, 200]), Nodes kept: 2589/3235 (80.0%)\n",
            "2025-05-27 21:36:27,114 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3235, 200]) -> torch.Size([2589, 200])\n",
            "2025-05-27 21:36:27,114 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2589, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,114 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,114 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2589, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,114 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,114 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,115 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,115 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0009\n",
            "2025-05-27 21:36:27,118 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 170, Batch 0/5, Loss: 0.0009\n",
            "2025-05-27 21:36:27,119 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4328 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,119 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4328, Edges: 5721, Graphs: 4\n",
            "2025-05-27 21:36:27,119 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4328]) -> torch.Size([4328, 37])\n",
            "2025-05-27 21:36:27,120 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4328, 37]), Edge index shape: torch.Size([2, 5721])\n",
            "2025-05-27 21:36:27,120 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,121 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4328, 37]) -> torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,121 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4328, 200]), Edge index shape: torch.Size([2, 5721])\n",
            "2025-05-27 21:36:27,122 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,122 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4328, 200]) -> torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,122 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4328, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,124 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3464, 200]), Nodes kept: 3464/4328 (80.0%)\n",
            "2025-05-27 21:36:27,124 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4328, 200]) -> torch.Size([3464, 200])\n",
            "2025-05-27 21:36:27,124 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3464, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,124 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,125 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3464, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,125 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,125 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,125 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,125 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0984\n",
            "2025-05-27 21:36:27,130 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4659 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,130 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4659, Edges: 5408, Graphs: 4\n",
            "2025-05-27 21:36:27,130 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4659]) -> torch.Size([4659, 37])\n",
            "2025-05-27 21:36:27,130 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4659, 37]), Edge index shape: torch.Size([2, 5408])\n",
            "2025-05-27 21:36:27,131 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4659, 200])\n",
            "2025-05-27 21:36:27,131 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4659, 37]) -> torch.Size([4659, 200])\n",
            "2025-05-27 21:36:27,131 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4659, 200]), Edge index shape: torch.Size([2, 5408])\n",
            "2025-05-27 21:36:27,132 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4659, 200])\n",
            "2025-05-27 21:36:27,132 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4659, 200]) -> torch.Size([4659, 200])\n",
            "2025-05-27 21:36:27,133 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4659, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,134 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3729, 200]), Nodes kept: 3729/4659 (80.0%)\n",
            "2025-05-27 21:36:27,135 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4659, 200]) -> torch.Size([3729, 200])\n",
            "2025-05-27 21:36:27,135 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3729, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,135 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,135 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3729, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,135 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,135 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,136 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,136 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1290\n",
            "2025-05-27 21:36:27,141 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 7936 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,142 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 7936, Edges: 11112, Graphs: 4\n",
            "2025-05-27 21:36:27,142 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([7936]) -> torch.Size([7936, 37])\n",
            "2025-05-27 21:36:27,142 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7936, 37]), Edge index shape: torch.Size([2, 11112])\n",
            "2025-05-27 21:36:27,143 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7936, 200])\n",
            "2025-05-27 21:36:27,143 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([7936, 37]) -> torch.Size([7936, 200])\n",
            "2025-05-27 21:36:27,143 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7936, 200]), Edge index shape: torch.Size([2, 11112])\n",
            "2025-05-27 21:36:27,144 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7936, 200])\n",
            "2025-05-27 21:36:27,144 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([7936, 200]) -> torch.Size([7936, 200])\n",
            "2025-05-27 21:36:27,145 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([7936, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,147 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6350, 200]), Nodes kept: 6350/7936 (80.0%)\n",
            "2025-05-27 21:36:27,147 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([7936, 200]) -> torch.Size([6350, 200])\n",
            "2025-05-27 21:36:27,147 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6350, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,147 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,147 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6350, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,148 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,148 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,148 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,148 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0006\n",
            "2025-05-27 21:36:27,154 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1555 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,154 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1555, Edges: 1817, Graphs: 2\n",
            "2025-05-27 21:36:27,154 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1555]) -> torch.Size([1555, 37])\n",
            "2025-05-27 21:36:27,154 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1555, 37]), Edge index shape: torch.Size([2, 1817])\n",
            "2025-05-27 21:36:27,155 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1555, 200])\n",
            "2025-05-27 21:36:27,155 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1555, 37]) -> torch.Size([1555, 200])\n",
            "2025-05-27 21:36:27,155 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1555, 200]), Edge index shape: torch.Size([2, 1817])\n",
            "2025-05-27 21:36:27,156 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1555, 200])\n",
            "2025-05-27 21:36:27,156 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1555, 200]) -> torch.Size([1555, 200])\n",
            "2025-05-27 21:36:27,156 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1555, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,158 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1244, 200]), Nodes kept: 1244/1555 (80.0%)\n",
            "2025-05-27 21:36:27,158 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1555, 200]) -> torch.Size([1244, 200])\n",
            "2025-05-27 21:36:27,158 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1244, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,158 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,185 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1244, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,185 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,185 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,185 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,185 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0017\n",
            "Epoch: 0170, loss_train: 0.0461, time: 0.1s:  84% 169/200 [00:16<00:02, 11.82it/s]2025-05-27 21:36:27,188 - trainers.GraphTrainer - INFO - train:427 - Epoch 170 completed - Avg loss: 0.0461, Time: 0.1s\n",
            "2025-05-27 21:36:27,188 - trainers.GraphTrainer - INFO - train:427 - Epoch 170 completed - Avg loss: 0.0461, Time: 0.1s\n",
            "2025-05-27 21:36:27,188 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 170...\n",
            "2025-05-27 21:36:27,188 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 170...\n",
            "2025-05-27 21:36:27,189 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:27,189 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:27,190 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,190 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6350, Edges: 8013, Graphs: 4\n",
            "2025-05-27 21:36:27,191 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6350]) -> torch.Size([6350, 37])\n",
            "2025-05-27 21:36:27,191 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6350, 37]), Edge index shape: torch.Size([2, 8013])\n",
            "2025-05-27 21:36:27,192 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6350, 200])\n",
            "2025-05-27 21:36:27,192 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6350, 37]) -> torch.Size([6350, 200])\n",
            "2025-05-27 21:36:27,192 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6350, 200]), Edge index shape: torch.Size([2, 8013])\n",
            "2025-05-27 21:36:27,193 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6350, 200])\n",
            "2025-05-27 21:36:27,193 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6350, 200]) -> torch.Size([6350, 200])\n",
            "2025-05-27 21:36:27,193 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6350, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,195 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5081, 200]), Nodes kept: 5081/6350 (80.0%)\n",
            "2025-05-27 21:36:27,195 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6350, 200]) -> torch.Size([5081, 200])\n",
            "2025-05-27 21:36:27,195 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5081, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,196 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,196 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5081, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,196 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,196 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,196 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,196 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.1669\n",
            "2025-05-27 21:36:27,197 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:27,199 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,199 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6602, Edges: 8227, Graphs: 4\n",
            "2025-05-27 21:36:27,199 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6602]) -> torch.Size([6602, 37])\n",
            "2025-05-27 21:36:27,199 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6602, 37]), Edge index shape: torch.Size([2, 8227])\n",
            "2025-05-27 21:36:27,200 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6602, 200])\n",
            "2025-05-27 21:36:27,200 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6602, 37]) -> torch.Size([6602, 200])\n",
            "2025-05-27 21:36:27,201 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6602, 200]), Edge index shape: torch.Size([2, 8227])\n",
            "2025-05-27 21:36:27,202 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6602, 200])\n",
            "2025-05-27 21:36:27,202 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6602, 200]) -> torch.Size([6602, 200])\n",
            "2025-05-27 21:36:27,202 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6602, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,204 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5282, 200]), Nodes kept: 5282/6602 (80.0%)\n",
            "2025-05-27 21:36:27,204 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6602, 200]) -> torch.Size([5282, 200])\n",
            "2025-05-27 21:36:27,205 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5282, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,205 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,205 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5282, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,205 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,205 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,205 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,206 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0115\n",
            "2025-05-27 21:36:27,208 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,208 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1818, Edges: 2231, Graphs: 4\n",
            "2025-05-27 21:36:27,208 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1818]) -> torch.Size([1818, 37])\n",
            "2025-05-27 21:36:27,208 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1818, 37]), Edge index shape: torch.Size([2, 2231])\n",
            "2025-05-27 21:36:27,209 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1818, 200])\n",
            "2025-05-27 21:36:27,209 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1818, 37]) -> torch.Size([1818, 200])\n",
            "2025-05-27 21:36:27,209 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1818, 200]), Edge index shape: torch.Size([2, 2231])\n",
            "2025-05-27 21:36:27,210 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1818, 200])\n",
            "2025-05-27 21:36:27,211 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1818, 200]) -> torch.Size([1818, 200])\n",
            "2025-05-27 21:36:27,211 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1818, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,213 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1456, 200]), Nodes kept: 1456/1818 (80.1%)\n",
            "2025-05-27 21:36:27,213 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1818, 200]) -> torch.Size([1456, 200])\n",
            "2025-05-27 21:36:27,213 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1456, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,213 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,213 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1456, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,213 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,214 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,214 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,214 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0117\n",
            "2025-05-27 21:36:27,216 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,216 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6758, Edges: 9125, Graphs: 4\n",
            "2025-05-27 21:36:27,216 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6758]) -> torch.Size([6758, 37])\n",
            "2025-05-27 21:36:27,216 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6758, 37]), Edge index shape: torch.Size([2, 9125])\n",
            "2025-05-27 21:36:27,217 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6758, 200])\n",
            "2025-05-27 21:36:27,217 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6758, 37]) -> torch.Size([6758, 200])\n",
            "2025-05-27 21:36:27,217 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6758, 200]), Edge index shape: torch.Size([2, 9125])\n",
            "2025-05-27 21:36:27,218 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6758, 200])\n",
            "2025-05-27 21:36:27,218 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6758, 200]) -> torch.Size([6758, 200])\n",
            "2025-05-27 21:36:27,219 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6758, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,221 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5408, 200]), Nodes kept: 5408/6758 (80.0%)\n",
            "2025-05-27 21:36:27,221 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6758, 200]) -> torch.Size([5408, 200])\n",
            "2025-05-27 21:36:27,221 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5408, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,221 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,221 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5408, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,221 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,221 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,222 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,222 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.1675\n",
            "2025-05-27 21:36:27,223 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,224 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 185, Edges: 241, Graphs: 2\n",
            "2025-05-27 21:36:27,224 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([185]) -> torch.Size([185, 37])\n",
            "2025-05-27 21:36:27,224 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([185, 37]), Edge index shape: torch.Size([2, 241])\n",
            "2025-05-27 21:36:27,225 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([185, 200])\n",
            "2025-05-27 21:36:27,225 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([185, 37]) -> torch.Size([185, 200])\n",
            "2025-05-27 21:36:27,225 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([185, 200]), Edge index shape: torch.Size([2, 241])\n",
            "2025-05-27 21:36:27,226 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([185, 200])\n",
            "2025-05-27 21:36:27,226 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([185, 200]) -> torch.Size([185, 200])\n",
            "2025-05-27 21:36:27,226 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([185, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,228 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([149, 200]), Nodes kept: 149/185 (80.5%)\n",
            "2025-05-27 21:36:27,228 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([185, 200]) -> torch.Size([149, 200])\n",
            "2025-05-27 21:36:27,228 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([149, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,228 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,228 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([149, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,228 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,228 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,228 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,229 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0227\n",
            "2025-05-27 21:36:27,229 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0761, Predictions: 18\n",
            "2025-05-27 21:36:27,229 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0761, Predictions: 18\n",
            "2025-05-27 21:36:27,229 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:27,229 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:27,231 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,231 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 717, Edges: 838, Graphs: 1\n",
            "2025-05-27 21:36:27,231 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([717]) -> torch.Size([717, 37])\n",
            "2025-05-27 21:36:27,231 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 37]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:27,232 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:27,232 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([717, 37]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:27,232 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 200]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:27,233 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:27,233 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([717, 200]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:27,233 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([717, 200]), Batch size: 1\n",
            "2025-05-27 21:36:27,235 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([574, 200]), Nodes kept: 574/717 (80.1%)\n",
            "2025-05-27 21:36:27,235 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([717, 200]) -> torch.Size([574, 200])\n",
            "2025-05-27 21:36:27,235 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([574, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:27,235 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,235 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([574, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,235 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,235 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,236 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:27,236 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.8185\n",
            "2025-05-27 21:36:27,236 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:27,237 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,237 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1830, Edges: 2170, Graphs: 1\n",
            "2025-05-27 21:36:27,238 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1830]) -> torch.Size([1830, 37])\n",
            "2025-05-27 21:36:27,238 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 37]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:27,239 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:27,286 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1830, 37]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:27,287 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 200]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:27,289 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:27,289 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1830, 200]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:27,289 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1830, 200]), Batch size: 1\n",
            "2025-05-27 21:36:27,292 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1464, 200]), Nodes kept: 1464/1830 (80.0%)\n",
            "2025-05-27 21:36:27,292 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1830, 200]) -> torch.Size([1464, 200])\n",
            "2025-05-27 21:36:27,293 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1464, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:27,293 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,293 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1464, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,293 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,293 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,294 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:27,294 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 5.8759\n",
            "2025-05-27 21:36:27,296 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,296 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 833, Edges: 1034, Graphs: 1\n",
            "2025-05-27 21:36:27,296 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([833]) -> torch.Size([833, 37])\n",
            "2025-05-27 21:36:27,296 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 37]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:27,297 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:27,297 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([833, 37]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:27,297 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 200]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:27,298 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:27,298 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([833, 200]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:27,299 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([833, 200]), Batch size: 1\n",
            "2025-05-27 21:36:27,301 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([667, 200]), Nodes kept: 667/833 (80.1%)\n",
            "2025-05-27 21:36:27,301 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([833, 200]) -> torch.Size([667, 200])\n",
            "2025-05-27 21:36:27,301 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([667, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:27,301 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,301 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([667, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,301 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,301 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,302 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:27,302 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:27,303 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,304 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2541, Edges: 3576, Graphs: 1\n",
            "2025-05-27 21:36:27,304 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2541]) -> torch.Size([2541, 37])\n",
            "2025-05-27 21:36:27,304 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 37]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:27,305 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:27,305 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2541, 37]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:27,305 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 200]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:27,306 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:27,306 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2541, 200]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:27,306 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2541, 200]), Batch size: 1\n",
            "2025-05-27 21:36:27,308 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2033, 200]), Nodes kept: 2033/2541 (80.0%)\n",
            "2025-05-27 21:36:27,308 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2541, 200]) -> torch.Size([2033, 200])\n",
            "2025-05-27 21:36:27,308 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2033, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:27,309 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,309 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2033, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,309 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,309 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,309 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:27,309 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 6.7411\n",
            "2025-05-27 21:36:27,311 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:27,312 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 782, Edges: 972, Graphs: 1\n",
            "2025-05-27 21:36:27,312 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([782]) -> torch.Size([782, 37])\n",
            "2025-05-27 21:36:27,312 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 37]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:27,313 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:27,313 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([782, 37]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:27,313 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 200]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:27,314 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:27,314 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([782, 200]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:27,314 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([782, 200]), Batch size: 1\n",
            "2025-05-27 21:36:27,316 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([626, 200]), Nodes kept: 626/782 (80.1%)\n",
            "2025-05-27 21:36:27,316 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([782, 200]) -> torch.Size([626, 200])\n",
            "2025-05-27 21:36:27,317 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([626, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:27,317 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,317 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([626, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,317 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,317 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:27,317 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:27,317 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0001\n",
            "2025-05-27 21:36:27,318 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 2.6871, Predictions: 5\n",
            "2025-05-27 21:36:27,318 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 2.6871, Predictions: 5\n",
            "\n",
            "Mini Test for Epochs 170:\n",
            "2025-05-27 21:36:27,318 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for train...\n",
            "train loss: 0.0761, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:27,327 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0761, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:27,327 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0761, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:27,327 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for test ...\n",
            "test  loss: 2.6871, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:27,335 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 2.6871, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:27,335 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 2.6871, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:27,335 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.1s\n",
            "2025-05-27 21:36:27,335 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.1s\n",
            "Epoch: 0170, loss_train: 0.0461, time: 0.1s:  86% 171/200 [00:16<00:03,  9.62it/s]2025-05-27 21:36:27,338 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6767 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,338 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6767, Edges: 9139, Graphs: 4\n",
            "2025-05-27 21:36:27,338 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6767]) -> torch.Size([6767, 37])\n",
            "2025-05-27 21:36:27,338 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6767, 37]), Edge index shape: torch.Size([2, 9139])\n",
            "2025-05-27 21:36:27,339 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6767, 200])\n",
            "2025-05-27 21:36:27,340 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6767, 37]) -> torch.Size([6767, 200])\n",
            "2025-05-27 21:36:27,340 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6767, 200]), Edge index shape: torch.Size([2, 9139])\n",
            "2025-05-27 21:36:27,341 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6767, 200])\n",
            "2025-05-27 21:36:27,341 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6767, 200]) -> torch.Size([6767, 200])\n",
            "2025-05-27 21:36:27,341 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6767, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,344 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5415, 200]), Nodes kept: 5415/6767 (80.0%)\n",
            "2025-05-27 21:36:27,344 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6767, 200]) -> torch.Size([5415, 200])\n",
            "2025-05-27 21:36:27,344 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5415, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,344 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,344 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5415, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,345 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,345 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,345 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,345 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0572\n",
            "2025-05-27 21:36:27,349 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 171, Batch 0/5, Loss: 0.0572\n",
            "2025-05-27 21:36:27,351 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2594 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,351 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2594, Edges: 3179, Graphs: 4\n",
            "2025-05-27 21:36:27,352 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2594]) -> torch.Size([2594, 37])\n",
            "2025-05-27 21:36:27,352 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2594, 37]), Edge index shape: torch.Size([2, 3179])\n",
            "2025-05-27 21:36:27,353 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2594, 200])\n",
            "2025-05-27 21:36:27,353 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2594, 37]) -> torch.Size([2594, 200])\n",
            "2025-05-27 21:36:27,353 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2594, 200]), Edge index shape: torch.Size([2, 3179])\n",
            "2025-05-27 21:36:27,354 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2594, 200])\n",
            "2025-05-27 21:36:27,354 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2594, 200]) -> torch.Size([2594, 200])\n",
            "2025-05-27 21:36:27,354 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2594, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,356 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2077, 200]), Nodes kept: 2077/2594 (80.1%)\n",
            "2025-05-27 21:36:27,357 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2594, 200]) -> torch.Size([2077, 200])\n",
            "2025-05-27 21:36:27,357 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2077, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,357 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,357 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2077, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,357 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,357 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,357 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,358 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1174\n",
            "2025-05-27 21:36:27,363 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4889 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,363 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4889, Edges: 6235, Graphs: 4\n",
            "2025-05-27 21:36:27,364 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4889]) -> torch.Size([4889, 37])\n",
            "2025-05-27 21:36:27,364 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4889, 37]), Edge index shape: torch.Size([2, 6235])\n",
            "2025-05-27 21:36:27,365 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4889, 200])\n",
            "2025-05-27 21:36:27,365 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4889, 37]) -> torch.Size([4889, 200])\n",
            "2025-05-27 21:36:27,365 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4889, 200]), Edge index shape: torch.Size([2, 6235])\n",
            "2025-05-27 21:36:27,387 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4889, 200])\n",
            "2025-05-27 21:36:27,388 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4889, 200]) -> torch.Size([4889, 200])\n",
            "2025-05-27 21:36:27,388 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4889, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,390 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3912, 200]), Nodes kept: 3912/4889 (80.0%)\n",
            "2025-05-27 21:36:27,390 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4889, 200]) -> torch.Size([3912, 200])\n",
            "2025-05-27 21:36:27,390 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3912, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,390 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,390 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3912, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,390 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,391 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,391 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,391 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0003\n",
            "2025-05-27 21:36:27,396 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5786 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,396 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5786, Edges: 7256, Graphs: 4\n",
            "2025-05-27 21:36:27,396 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5786]) -> torch.Size([5786, 37])\n",
            "2025-05-27 21:36:27,396 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5786, 37]), Edge index shape: torch.Size([2, 7256])\n",
            "2025-05-27 21:36:27,397 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5786, 200])\n",
            "2025-05-27 21:36:27,397 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5786, 37]) -> torch.Size([5786, 200])\n",
            "2025-05-27 21:36:27,397 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5786, 200]), Edge index shape: torch.Size([2, 7256])\n",
            "2025-05-27 21:36:27,398 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5786, 200])\n",
            "2025-05-27 21:36:27,399 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5786, 200]) -> torch.Size([5786, 200])\n",
            "2025-05-27 21:36:27,399 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5786, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,401 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4630, 200]), Nodes kept: 4630/5786 (80.0%)\n",
            "2025-05-27 21:36:27,401 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5786, 200]) -> torch.Size([4630, 200])\n",
            "2025-05-27 21:36:27,401 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4630, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,401 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,401 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4630, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,402 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,402 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,402 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,402 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1354\n",
            "2025-05-27 21:36:27,407 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1677 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,407 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1677, Edges: 2028, Graphs: 2\n",
            "2025-05-27 21:36:27,407 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1677]) -> torch.Size([1677, 37])\n",
            "2025-05-27 21:36:27,407 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1677, 37]), Edge index shape: torch.Size([2, 2028])\n",
            "2025-05-27 21:36:27,408 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1677, 200])\n",
            "2025-05-27 21:36:27,408 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1677, 37]) -> torch.Size([1677, 200])\n",
            "2025-05-27 21:36:27,408 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1677, 200]), Edge index shape: torch.Size([2, 2028])\n",
            "2025-05-27 21:36:27,409 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1677, 200])\n",
            "2025-05-27 21:36:27,409 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1677, 200]) -> torch.Size([1677, 200])\n",
            "2025-05-27 21:36:27,410 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1677, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,412 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1342, 200]), Nodes kept: 1342/1677 (80.0%)\n",
            "2025-05-27 21:36:27,412 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1677, 200]) -> torch.Size([1342, 200])\n",
            "2025-05-27 21:36:27,412 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1342, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,412 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,413 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1342, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,413 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,413 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,413 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,413 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0002\n",
            "Epoch: 0171, loss_train: 0.0621, time: 0.1s:  86% 171/200 [00:16<00:03,  9.62it/s]2025-05-27 21:36:27,416 - trainers.GraphTrainer - INFO - train:427 - Epoch 171 completed - Avg loss: 0.0621, Time: 0.1s\n",
            "2025-05-27 21:36:27,416 - trainers.GraphTrainer - INFO - train:427 - Epoch 171 completed - Avg loss: 0.0621, Time: 0.1s\n",
            "2025-05-27 21:36:27,418 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6282 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,418 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6282, Edges: 8656, Graphs: 4\n",
            "2025-05-27 21:36:27,418 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6282]) -> torch.Size([6282, 37])\n",
            "2025-05-27 21:36:27,418 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6282, 37]), Edge index shape: torch.Size([2, 8656])\n",
            "2025-05-27 21:36:27,419 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6282, 200])\n",
            "2025-05-27 21:36:27,419 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6282, 37]) -> torch.Size([6282, 200])\n",
            "2025-05-27 21:36:27,419 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6282, 200]), Edge index shape: torch.Size([2, 8656])\n",
            "2025-05-27 21:36:27,420 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6282, 200])\n",
            "2025-05-27 21:36:27,420 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6282, 200]) -> torch.Size([6282, 200])\n",
            "2025-05-27 21:36:27,421 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6282, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,423 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5027, 200]), Nodes kept: 5027/6282 (80.0%)\n",
            "2025-05-27 21:36:27,423 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6282, 200]) -> torch.Size([5027, 200])\n",
            "2025-05-27 21:36:27,423 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5027, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,423 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,423 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5027, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,423 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,423 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,424 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,424 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0012\n",
            "2025-05-27 21:36:27,428 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 172, Batch 0/5, Loss: 0.0012\n",
            "2025-05-27 21:36:27,429 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4223 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,429 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4223, Edges: 5543, Graphs: 4\n",
            "2025-05-27 21:36:27,430 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4223]) -> torch.Size([4223, 37])\n",
            "2025-05-27 21:36:27,430 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4223, 37]), Edge index shape: torch.Size([2, 5543])\n",
            "2025-05-27 21:36:27,431 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4223, 200])\n",
            "2025-05-27 21:36:27,431 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4223, 37]) -> torch.Size([4223, 200])\n",
            "2025-05-27 21:36:27,431 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4223, 200]), Edge index shape: torch.Size([2, 5543])\n",
            "2025-05-27 21:36:27,432 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4223, 200])\n",
            "2025-05-27 21:36:27,432 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4223, 200]) -> torch.Size([4223, 200])\n",
            "2025-05-27 21:36:27,432 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4223, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,434 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3379, 200]), Nodes kept: 3379/4223 (80.0%)\n",
            "2025-05-27 21:36:27,434 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4223, 200]) -> torch.Size([3379, 200])\n",
            "2025-05-27 21:36:27,434 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3379, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,435 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,435 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3379, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,435 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,435 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,435 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,435 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0005\n",
            "2025-05-27 21:36:27,440 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5604 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,440 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5604, Edges: 7078, Graphs: 4\n",
            "2025-05-27 21:36:27,440 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5604]) -> torch.Size([5604, 37])\n",
            "2025-05-27 21:36:27,440 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5604, 37]), Edge index shape: torch.Size([2, 7078])\n",
            "2025-05-27 21:36:27,441 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5604, 200])\n",
            "2025-05-27 21:36:27,441 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5604, 37]) -> torch.Size([5604, 200])\n",
            "2025-05-27 21:36:27,441 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5604, 200]), Edge index shape: torch.Size([2, 7078])\n",
            "2025-05-27 21:36:27,442 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5604, 200])\n",
            "2025-05-27 21:36:27,442 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5604, 200]) -> torch.Size([5604, 200])\n",
            "2025-05-27 21:36:27,443 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5604, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,445 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4484, 200]), Nodes kept: 4484/5604 (80.0%)\n",
            "2025-05-27 21:36:27,445 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5604, 200]) -> torch.Size([4484, 200])\n",
            "2025-05-27 21:36:27,445 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4484, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,445 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,445 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4484, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,445 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,445 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,446 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,446 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0244\n",
            "2025-05-27 21:36:27,451 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2311 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,451 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2311, Edges: 2742, Graphs: 4\n",
            "2025-05-27 21:36:27,451 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2311]) -> torch.Size([2311, 37])\n",
            "2025-05-27 21:36:27,451 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2311, 37]), Edge index shape: torch.Size([2, 2742])\n",
            "2025-05-27 21:36:27,452 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2311, 200])\n",
            "2025-05-27 21:36:27,452 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2311, 37]) -> torch.Size([2311, 200])\n",
            "2025-05-27 21:36:27,452 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2311, 200]), Edge index shape: torch.Size([2, 2742])\n",
            "2025-05-27 21:36:27,453 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2311, 200])\n",
            "2025-05-27 21:36:27,453 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2311, 200]) -> torch.Size([2311, 200])\n",
            "2025-05-27 21:36:27,454 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2311, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,455 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1851, 200]), Nodes kept: 1851/2311 (80.1%)\n",
            "2025-05-27 21:36:27,455 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2311, 200]) -> torch.Size([1851, 200])\n",
            "2025-05-27 21:36:27,456 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1851, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,456 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,456 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1851, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,456 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,456 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,456 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,457 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.3966\n",
            "2025-05-27 21:36:27,460 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3293 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,461 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3293, Edges: 3818, Graphs: 2\n",
            "2025-05-27 21:36:27,487 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3293]) -> torch.Size([3293, 37])\n",
            "2025-05-27 21:36:27,488 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3293, 37]), Edge index shape: torch.Size([2, 3818])\n",
            "2025-05-27 21:36:27,491 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3293, 200])\n",
            "2025-05-27 21:36:27,491 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3293, 37]) -> torch.Size([3293, 200])\n",
            "2025-05-27 21:36:27,491 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3293, 200]), Edge index shape: torch.Size([2, 3818])\n",
            "2025-05-27 21:36:27,492 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3293, 200])\n",
            "2025-05-27 21:36:27,492 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3293, 200]) -> torch.Size([3293, 200])\n",
            "2025-05-27 21:36:27,493 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3293, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,495 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2635, 200]), Nodes kept: 2635/3293 (80.0%)\n",
            "2025-05-27 21:36:27,495 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3293, 200]) -> torch.Size([2635, 200])\n",
            "2025-05-27 21:36:27,495 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2635, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,496 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,496 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2635, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,496 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,496 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,496 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,496 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0172, loss_train: 0.0845, time: 0.1s:  86% 171/200 [00:16<00:03,  9.62it/s]2025-05-27 21:36:27,500 - trainers.GraphTrainer - INFO - train:427 - Epoch 172 completed - Avg loss: 0.0845, Time: 0.1s\n",
            "2025-05-27 21:36:27,500 - trainers.GraphTrainer - INFO - train:427 - Epoch 172 completed - Avg loss: 0.0845, Time: 0.1s\n",
            "Epoch: 0172, loss_train: 0.0845, time: 0.1s:  86% 173/200 [00:16<00:02, 10.26it/s]2025-05-27 21:36:27,503 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8281 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,503 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8281, Edges: 10883, Graphs: 4\n",
            "2025-05-27 21:36:27,503 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8281]) -> torch.Size([8281, 37])\n",
            "2025-05-27 21:36:27,503 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8281, 37]), Edge index shape: torch.Size([2, 10883])\n",
            "2025-05-27 21:36:27,504 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,505 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8281, 37]) -> torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,505 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8281, 200]), Edge index shape: torch.Size([2, 10883])\n",
            "2025-05-27 21:36:27,506 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,507 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8281, 200]) -> torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,507 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8281, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,509 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6626, 200]), Nodes kept: 6626/8281 (80.0%)\n",
            "2025-05-27 21:36:27,509 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8281, 200]) -> torch.Size([6626, 200])\n",
            "2025-05-27 21:36:27,509 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6626, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,510 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,510 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6626, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,510 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,510 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,510 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,510 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:27,515 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 173, Batch 0/5, Loss: 0.0000\n",
            "2025-05-27 21:36:27,517 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1572 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,517 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1572, Edges: 1831, Graphs: 4\n",
            "2025-05-27 21:36:27,517 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1572]) -> torch.Size([1572, 37])\n",
            "2025-05-27 21:36:27,517 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1572, 37]), Edge index shape: torch.Size([2, 1831])\n",
            "2025-05-27 21:36:27,518 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1572, 200])\n",
            "2025-05-27 21:36:27,519 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1572, 37]) -> torch.Size([1572, 200])\n",
            "2025-05-27 21:36:27,519 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1572, 200]), Edge index shape: torch.Size([2, 1831])\n",
            "2025-05-27 21:36:27,520 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1572, 200])\n",
            "2025-05-27 21:36:27,520 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1572, 200]) -> torch.Size([1572, 200])\n",
            "2025-05-27 21:36:27,520 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1572, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,522 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1259, 200]), Nodes kept: 1259/1572 (80.1%)\n",
            "2025-05-27 21:36:27,522 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1572, 200]) -> torch.Size([1259, 200])\n",
            "2025-05-27 21:36:27,522 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1259, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,522 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,523 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1259, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,523 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,523 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,523 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,523 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1399\n",
            "2025-05-27 21:36:27,528 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4122 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,528 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4122, Edges: 5415, Graphs: 4\n",
            "2025-05-27 21:36:27,528 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4122]) -> torch.Size([4122, 37])\n",
            "2025-05-27 21:36:27,528 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4122, 37]), Edge index shape: torch.Size([2, 5415])\n",
            "2025-05-27 21:36:27,529 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4122, 200])\n",
            "2025-05-27 21:36:27,529 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4122, 37]) -> torch.Size([4122, 200])\n",
            "2025-05-27 21:36:27,529 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4122, 200]), Edge index shape: torch.Size([2, 5415])\n",
            "2025-05-27 21:36:27,530 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4122, 200])\n",
            "2025-05-27 21:36:27,531 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4122, 200]) -> torch.Size([4122, 200])\n",
            "2025-05-27 21:36:27,531 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4122, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,533 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3299, 200]), Nodes kept: 3299/4122 (80.0%)\n",
            "2025-05-27 21:36:27,533 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4122, 200]) -> torch.Size([3299, 200])\n",
            "2025-05-27 21:36:27,533 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3299, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,533 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,533 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3299, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,534 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,534 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,534 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,534 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1312\n",
            "2025-05-27 21:36:27,539 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4307 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,539 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4307, Edges: 5088, Graphs: 4\n",
            "2025-05-27 21:36:27,539 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4307]) -> torch.Size([4307, 37])\n",
            "2025-05-27 21:36:27,540 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4307, 37]), Edge index shape: torch.Size([2, 5088])\n",
            "2025-05-27 21:36:27,540 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4307, 200])\n",
            "2025-05-27 21:36:27,541 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4307, 37]) -> torch.Size([4307, 200])\n",
            "2025-05-27 21:36:27,541 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4307, 200]), Edge index shape: torch.Size([2, 5088])\n",
            "2025-05-27 21:36:27,542 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4307, 200])\n",
            "2025-05-27 21:36:27,542 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4307, 200]) -> torch.Size([4307, 200])\n",
            "2025-05-27 21:36:27,542 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4307, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,544 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3447, 200]), Nodes kept: 3447/4307 (80.0%)\n",
            "2025-05-27 21:36:27,544 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4307, 200]) -> torch.Size([3447, 200])\n",
            "2025-05-27 21:36:27,544 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3447, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,545 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,545 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3447, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,545 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,545 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,545 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,545 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0014\n",
            "2025-05-27 21:36:27,550 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3431 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,550 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3431, Edges: 4620, Graphs: 2\n",
            "2025-05-27 21:36:27,551 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3431]) -> torch.Size([3431, 37])\n",
            "2025-05-27 21:36:27,551 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3431, 37]), Edge index shape: torch.Size([2, 4620])\n",
            "2025-05-27 21:36:27,552 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3431, 200])\n",
            "2025-05-27 21:36:27,552 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3431, 37]) -> torch.Size([3431, 200])\n",
            "2025-05-27 21:36:27,552 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3431, 200]), Edge index shape: torch.Size([2, 4620])\n",
            "2025-05-27 21:36:27,553 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3431, 200])\n",
            "2025-05-27 21:36:27,553 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3431, 200]) -> torch.Size([3431, 200])\n",
            "2025-05-27 21:36:27,553 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3431, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,556 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2745, 200]), Nodes kept: 2745/3431 (80.0%)\n",
            "2025-05-27 21:36:27,556 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3431, 200]) -> torch.Size([2745, 200])\n",
            "2025-05-27 21:36:27,556 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2745, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,557 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,557 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2745, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,557 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,557 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,557 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,558 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0003\n",
            "Epoch: 0173, loss_train: 0.0545, time: 0.1s:  86% 173/200 [00:16<00:02, 10.26it/s]2025-05-27 21:36:27,561 - trainers.GraphTrainer - INFO - train:427 - Epoch 173 completed - Avg loss: 0.0545, Time: 0.1s\n",
            "2025-05-27 21:36:27,561 - trainers.GraphTrainer - INFO - train:427 - Epoch 173 completed - Avg loss: 0.0545, Time: 0.1s\n",
            "2025-05-27 21:36:27,564 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2384 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,564 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2384, Edges: 2874, Graphs: 4\n",
            "2025-05-27 21:36:27,564 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2384]) -> torch.Size([2384, 37])\n",
            "2025-05-27 21:36:27,564 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2384, 37]), Edge index shape: torch.Size([2, 2874])\n",
            "2025-05-27 21:36:27,565 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2384, 200])\n",
            "2025-05-27 21:36:27,566 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2384, 37]) -> torch.Size([2384, 200])\n",
            "2025-05-27 21:36:27,566 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2384, 200]), Edge index shape: torch.Size([2, 2874])\n",
            "2025-05-27 21:36:27,567 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2384, 200])\n",
            "2025-05-27 21:36:27,567 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2384, 200]) -> torch.Size([2384, 200])\n",
            "2025-05-27 21:36:27,567 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2384, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,570 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1910, 200]), Nodes kept: 1910/2384 (80.1%)\n",
            "2025-05-27 21:36:27,570 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2384, 200]) -> torch.Size([1910, 200])\n",
            "2025-05-27 21:36:27,570 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1910, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,570 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,570 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1910, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,571 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,571 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,571 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,571 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1363\n",
            "2025-05-27 21:36:27,595 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 174, Batch 0/5, Loss: 0.1363\n",
            "2025-05-27 21:36:27,597 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6898 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,597 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6898, Edges: 9352, Graphs: 4\n",
            "2025-05-27 21:36:27,597 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6898]) -> torch.Size([6898, 37])\n",
            "2025-05-27 21:36:27,598 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6898, 37]), Edge index shape: torch.Size([2, 9352])\n",
            "2025-05-27 21:36:27,598 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6898, 200])\n",
            "2025-05-27 21:36:27,599 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6898, 37]) -> torch.Size([6898, 200])\n",
            "2025-05-27 21:36:27,599 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6898, 200]), Edge index shape: torch.Size([2, 9352])\n",
            "2025-05-27 21:36:27,600 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6898, 200])\n",
            "2025-05-27 21:36:27,600 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6898, 200]) -> torch.Size([6898, 200])\n",
            "2025-05-27 21:36:27,600 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6898, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,602 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5519, 200]), Nodes kept: 5519/6898 (80.0%)\n",
            "2025-05-27 21:36:27,602 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6898, 200]) -> torch.Size([5519, 200])\n",
            "2025-05-27 21:36:27,602 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5519, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,603 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,603 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5519, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,603 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,603 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,603 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,603 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0004\n",
            "2025-05-27 21:36:27,609 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1645 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,609 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1645, Edges: 1896, Graphs: 4\n",
            "2025-05-27 21:36:27,609 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1645]) -> torch.Size([1645, 37])\n",
            "2025-05-27 21:36:27,609 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1645, 37]), Edge index shape: torch.Size([2, 1896])\n",
            "2025-05-27 21:36:27,610 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1645, 200])\n",
            "2025-05-27 21:36:27,610 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1645, 37]) -> torch.Size([1645, 200])\n",
            "2025-05-27 21:36:27,610 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1645, 200]), Edge index shape: torch.Size([2, 1896])\n",
            "2025-05-27 21:36:27,611 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1645, 200])\n",
            "2025-05-27 21:36:27,611 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1645, 200]) -> torch.Size([1645, 200])\n",
            "2025-05-27 21:36:27,612 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1645, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,613 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1317, 200]), Nodes kept: 1317/1645 (80.1%)\n",
            "2025-05-27 21:36:27,613 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1645, 200]) -> torch.Size([1317, 200])\n",
            "2025-05-27 21:36:27,614 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1317, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,614 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,614 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1317, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,614 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,614 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,614 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,615 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0480\n",
            "2025-05-27 21:36:27,619 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5739 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,619 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5739, Edges: 7305, Graphs: 4\n",
            "2025-05-27 21:36:27,619 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5739]) -> torch.Size([5739, 37])\n",
            "2025-05-27 21:36:27,619 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5739, 37]), Edge index shape: torch.Size([2, 7305])\n",
            "2025-05-27 21:36:27,620 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5739, 200])\n",
            "2025-05-27 21:36:27,620 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5739, 37]) -> torch.Size([5739, 200])\n",
            "2025-05-27 21:36:27,620 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5739, 200]), Edge index shape: torch.Size([2, 7305])\n",
            "2025-05-27 21:36:27,621 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5739, 200])\n",
            "2025-05-27 21:36:27,621 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5739, 200]) -> torch.Size([5739, 200])\n",
            "2025-05-27 21:36:27,622 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5739, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,624 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4592, 200]), Nodes kept: 4592/5739 (80.0%)\n",
            "2025-05-27 21:36:27,624 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5739, 200]) -> torch.Size([4592, 200])\n",
            "2025-05-27 21:36:27,624 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4592, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,624 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,624 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4592, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,624 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,624 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,625 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,625 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:27,630 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5047 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,630 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5047, Edges: 6410, Graphs: 2\n",
            "2025-05-27 21:36:27,630 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5047]) -> torch.Size([5047, 37])\n",
            "2025-05-27 21:36:27,630 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5047, 37]), Edge index shape: torch.Size([2, 6410])\n",
            "2025-05-27 21:36:27,631 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5047, 200])\n",
            "2025-05-27 21:36:27,631 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5047, 37]) -> torch.Size([5047, 200])\n",
            "2025-05-27 21:36:27,631 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5047, 200]), Edge index shape: torch.Size([2, 6410])\n",
            "2025-05-27 21:36:27,632 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5047, 200])\n",
            "2025-05-27 21:36:27,632 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5047, 200]) -> torch.Size([5047, 200])\n",
            "2025-05-27 21:36:27,633 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5047, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,634 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4038, 200]), Nodes kept: 4038/5047 (80.0%)\n",
            "2025-05-27 21:36:27,635 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5047, 200]) -> torch.Size([4038, 200])\n",
            "2025-05-27 21:36:27,635 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4038, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,635 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,635 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4038, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,635 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,635 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,635 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,636 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0174, loss_train: 0.0369, time: 0.1s:  86% 173/200 [00:16<00:02, 10.26it/s]2025-05-27 21:36:27,639 - trainers.GraphTrainer - INFO - train:427 - Epoch 174 completed - Avg loss: 0.0369, Time: 0.1s\n",
            "2025-05-27 21:36:27,639 - trainers.GraphTrainer - INFO - train:427 - Epoch 174 completed - Avg loss: 0.0369, Time: 0.1s\n",
            "Epoch: 0174, loss_train: 0.0369, time: 0.1s:  88% 175/200 [00:16<00:02, 11.22it/s]2025-05-27 21:36:27,642 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4328 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,642 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4328, Edges: 5721, Graphs: 4\n",
            "2025-05-27 21:36:27,642 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4328]) -> torch.Size([4328, 37])\n",
            "2025-05-27 21:36:27,642 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4328, 37]), Edge index shape: torch.Size([2, 5721])\n",
            "2025-05-27 21:36:27,643 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,643 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4328, 37]) -> torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,644 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4328, 200]), Edge index shape: torch.Size([2, 5721])\n",
            "2025-05-27 21:36:27,645 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,645 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4328, 200]) -> torch.Size([4328, 200])\n",
            "2025-05-27 21:36:27,645 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4328, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,647 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3464, 200]), Nodes kept: 3464/4328 (80.0%)\n",
            "2025-05-27 21:36:27,648 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4328, 200]) -> torch.Size([3464, 200])\n",
            "2025-05-27 21:36:27,648 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3464, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,648 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,648 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3464, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,648 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,648 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,649 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,649 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0968\n",
            "2025-05-27 21:36:27,652 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 175, Batch 0/5, Loss: 0.0968\n",
            "2025-05-27 21:36:27,654 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2409 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,655 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2409, Edges: 2873, Graphs: 4\n",
            "2025-05-27 21:36:27,655 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2409]) -> torch.Size([2409, 37])\n",
            "2025-05-27 21:36:27,655 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2409, 37]), Edge index shape: torch.Size([2, 2873])\n",
            "2025-05-27 21:36:27,656 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2409, 200])\n",
            "2025-05-27 21:36:27,657 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2409, 37]) -> torch.Size([2409, 200])\n",
            "2025-05-27 21:36:27,657 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2409, 200]), Edge index shape: torch.Size([2, 2873])\n",
            "2025-05-27 21:36:27,658 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2409, 200])\n",
            "2025-05-27 21:36:27,658 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2409, 200]) -> torch.Size([2409, 200])\n",
            "2025-05-27 21:36:27,659 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2409, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,661 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1928, 200]), Nodes kept: 1928/2409 (80.0%)\n",
            "2025-05-27 21:36:27,661 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2409, 200]) -> torch.Size([1928, 200])\n",
            "2025-05-27 21:36:27,661 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1928, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,662 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,662 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1928, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,662 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,662 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,662 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,663 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0966\n",
            "2025-05-27 21:36:27,668 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8281 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,669 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8281, Edges: 10883, Graphs: 4\n",
            "2025-05-27 21:36:27,669 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8281]) -> torch.Size([8281, 37])\n",
            "2025-05-27 21:36:27,669 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8281, 37]), Edge index shape: torch.Size([2, 10883])\n",
            "2025-05-27 21:36:27,670 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,671 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8281, 37]) -> torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,671 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8281, 200]), Edge index shape: torch.Size([2, 10883])\n",
            "2025-05-27 21:36:27,672 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,672 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8281, 200]) -> torch.Size([8281, 200])\n",
            "2025-05-27 21:36:27,673 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8281, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,676 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6626, 200]), Nodes kept: 6626/8281 (80.0%)\n",
            "2025-05-27 21:36:27,694 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8281, 200]) -> torch.Size([6626, 200])\n",
            "2025-05-27 21:36:27,694 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6626, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,694 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,694 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6626, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,694 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,695 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,695 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,695 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:27,702 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4140 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,703 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4140, Edges: 5449, Graphs: 4\n",
            "2025-05-27 21:36:27,703 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4140]) -> torch.Size([4140, 37])\n",
            "2025-05-27 21:36:27,703 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4140, 37]), Edge index shape: torch.Size([2, 5449])\n",
            "2025-05-27 21:36:27,704 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4140, 200])\n",
            "2025-05-27 21:36:27,704 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4140, 37]) -> torch.Size([4140, 200])\n",
            "2025-05-27 21:36:27,704 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4140, 200]), Edge index shape: torch.Size([2, 5449])\n",
            "2025-05-27 21:36:27,706 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4140, 200])\n",
            "2025-05-27 21:36:27,706 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4140, 200]) -> torch.Size([4140, 200])\n",
            "2025-05-27 21:36:27,706 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4140, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,708 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3313, 200]), Nodes kept: 3313/4140 (80.0%)\n",
            "2025-05-27 21:36:27,708 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4140, 200]) -> torch.Size([3313, 200])\n",
            "2025-05-27 21:36:27,709 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3313, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,709 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,709 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3313, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,709 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,709 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,710 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,710 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1534\n",
            "2025-05-27 21:36:27,715 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2555 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,715 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2555, Edges: 2911, Graphs: 2\n",
            "2025-05-27 21:36:27,715 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2555]) -> torch.Size([2555, 37])\n",
            "2025-05-27 21:36:27,715 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2555, 37]), Edge index shape: torch.Size([2, 2911])\n",
            "2025-05-27 21:36:27,716 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2555, 200])\n",
            "2025-05-27 21:36:27,717 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2555, 37]) -> torch.Size([2555, 200])\n",
            "2025-05-27 21:36:27,717 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2555, 200]), Edge index shape: torch.Size([2, 2911])\n",
            "2025-05-27 21:36:27,718 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2555, 200])\n",
            "2025-05-27 21:36:27,718 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2555, 200]) -> torch.Size([2555, 200])\n",
            "2025-05-27 21:36:27,718 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2555, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,720 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2045, 200]), Nodes kept: 2045/2555 (80.0%)\n",
            "2025-05-27 21:36:27,720 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2555, 200]) -> torch.Size([2045, 200])\n",
            "2025-05-27 21:36:27,720 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2045, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,721 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,721 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2045, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,721 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,721 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,721 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,721 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0012\n",
            "Epoch: 0175, loss_train: 0.0696, time: 0.1s:  88% 175/200 [00:16<00:02, 11.22it/s]2025-05-27 21:36:27,724 - trainers.GraphTrainer - INFO - train:427 - Epoch 175 completed - Avg loss: 0.0696, Time: 0.1s\n",
            "2025-05-27 21:36:27,724 - trainers.GraphTrainer - INFO - train:427 - Epoch 175 completed - Avg loss: 0.0696, Time: 0.1s\n",
            "2025-05-27 21:36:27,727 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3646 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,727 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3646, Edges: 4878, Graphs: 4\n",
            "2025-05-27 21:36:27,727 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3646]) -> torch.Size([3646, 37])\n",
            "2025-05-27 21:36:27,727 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3646, 37]), Edge index shape: torch.Size([2, 4878])\n",
            "2025-05-27 21:36:27,728 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3646, 200])\n",
            "2025-05-27 21:36:27,728 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3646, 37]) -> torch.Size([3646, 200])\n",
            "2025-05-27 21:36:27,728 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3646, 200]), Edge index shape: torch.Size([2, 4878])\n",
            "2025-05-27 21:36:27,730 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3646, 200])\n",
            "2025-05-27 21:36:27,730 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3646, 200]) -> torch.Size([3646, 200])\n",
            "2025-05-27 21:36:27,730 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3646, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,732 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2918, 200]), Nodes kept: 2918/3646 (80.0%)\n",
            "2025-05-27 21:36:27,732 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3646, 200]) -> torch.Size([2918, 200])\n",
            "2025-05-27 21:36:27,732 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2918, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,733 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,733 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2918, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,733 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,733 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,733 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,733 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0048\n",
            "2025-05-27 21:36:27,737 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 176, Batch 0/5, Loss: 0.0048\n",
            "2025-05-27 21:36:27,739 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8561 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,739 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8561, Edges: 11204, Graphs: 4\n",
            "2025-05-27 21:36:27,739 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8561]) -> torch.Size([8561, 37])\n",
            "2025-05-27 21:36:27,739 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8561, 37]), Edge index shape: torch.Size([2, 11204])\n",
            "2025-05-27 21:36:27,740 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8561, 200])\n",
            "2025-05-27 21:36:27,740 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8561, 37]) -> torch.Size([8561, 200])\n",
            "2025-05-27 21:36:27,741 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8561, 200]), Edge index shape: torch.Size([2, 11204])\n",
            "2025-05-27 21:36:27,742 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8561, 200])\n",
            "2025-05-27 21:36:27,742 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8561, 200]) -> torch.Size([8561, 200])\n",
            "2025-05-27 21:36:27,743 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8561, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,745 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6850, 200]), Nodes kept: 6850/8561 (80.0%)\n",
            "2025-05-27 21:36:27,745 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8561, 200]) -> torch.Size([6850, 200])\n",
            "2025-05-27 21:36:27,745 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6850, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,745 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,745 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6850, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,746 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,746 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,746 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,746 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:27,753 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6317 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,753 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6317, Edges: 7974, Graphs: 4\n",
            "2025-05-27 21:36:27,753 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6317]) -> torch.Size([6317, 37])\n",
            "2025-05-27 21:36:27,753 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6317, 37]), Edge index shape: torch.Size([2, 7974])\n",
            "2025-05-27 21:36:27,754 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6317, 200])\n",
            "2025-05-27 21:36:27,754 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6317, 37]) -> torch.Size([6317, 200])\n",
            "2025-05-27 21:36:27,754 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6317, 200]), Edge index shape: torch.Size([2, 7974])\n",
            "2025-05-27 21:36:27,755 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6317, 200])\n",
            "2025-05-27 21:36:27,756 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6317, 200]) -> torch.Size([6317, 200])\n",
            "2025-05-27 21:36:27,756 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6317, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,758 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5055, 200]), Nodes kept: 5055/6317 (80.0%)\n",
            "2025-05-27 21:36:27,758 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6317, 200]) -> torch.Size([5055, 200])\n",
            "2025-05-27 21:36:27,758 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5055, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,759 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,759 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5055, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,759 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,759 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,759 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,759 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0890\n",
            "2025-05-27 21:36:27,765 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2401 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,765 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2401, Edges: 2860, Graphs: 4\n",
            "2025-05-27 21:36:27,765 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2401]) -> torch.Size([2401, 37])\n",
            "2025-05-27 21:36:27,766 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2401, 37]), Edge index shape: torch.Size([2, 2860])\n",
            "2025-05-27 21:36:27,767 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2401, 200])\n",
            "2025-05-27 21:36:27,767 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2401, 37]) -> torch.Size([2401, 200])\n",
            "2025-05-27 21:36:27,767 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2401, 200]), Edge index shape: torch.Size([2, 2860])\n",
            "2025-05-27 21:36:27,768 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2401, 200])\n",
            "2025-05-27 21:36:27,768 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2401, 200]) -> torch.Size([2401, 200])\n",
            "2025-05-27 21:36:27,768 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2401, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,770 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1922, 200]), Nodes kept: 1922/2401 (80.0%)\n",
            "2025-05-27 21:36:27,770 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2401, 200]) -> torch.Size([1922, 200])\n",
            "2025-05-27 21:36:27,770 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1922, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,771 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,771 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1922, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,771 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,771 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,771 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,772 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1034\n",
            "2025-05-27 21:36:27,777 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 788 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,777 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 788, Edges: 921, Graphs: 2\n",
            "2025-05-27 21:36:27,778 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([788]) -> torch.Size([788, 37])\n",
            "2025-05-27 21:36:27,778 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([788, 37]), Edge index shape: torch.Size([2, 921])\n",
            "2025-05-27 21:36:27,779 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([788, 200])\n",
            "2025-05-27 21:36:27,794 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([788, 37]) -> torch.Size([788, 200])\n",
            "2025-05-27 21:36:27,794 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([788, 200]), Edge index shape: torch.Size([2, 921])\n",
            "2025-05-27 21:36:27,795 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([788, 200])\n",
            "2025-05-27 21:36:27,795 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([788, 200]) -> torch.Size([788, 200])\n",
            "2025-05-27 21:36:27,796 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([788, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,797 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([631, 200]), Nodes kept: 631/788 (80.1%)\n",
            "2025-05-27 21:36:27,797 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([788, 200]) -> torch.Size([631, 200])\n",
            "2025-05-27 21:36:27,797 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([631, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,798 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,798 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([631, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,798 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,798 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,798 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,798 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0234\n",
            "Epoch: 0176, loss_train: 0.0441, time: 0.1s:  88% 175/200 [00:17<00:02, 11.22it/s]2025-05-27 21:36:27,801 - trainers.GraphTrainer - INFO - train:427 - Epoch 176 completed - Avg loss: 0.0441, Time: 0.1s\n",
            "2025-05-27 21:36:27,801 - trainers.GraphTrainer - INFO - train:427 - Epoch 176 completed - Avg loss: 0.0441, Time: 0.1s\n",
            "Epoch: 0176, loss_train: 0.0441, time: 0.1s:  88% 177/200 [00:17<00:01, 11.55it/s]2025-05-27 21:36:27,803 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4240 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,803 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4240, Edges: 5622, Graphs: 4\n",
            "2025-05-27 21:36:27,803 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4240]) -> torch.Size([4240, 37])\n",
            "2025-05-27 21:36:27,803 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4240, 37]), Edge index shape: torch.Size([2, 5622])\n",
            "2025-05-27 21:36:27,804 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4240, 200])\n",
            "2025-05-27 21:36:27,804 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4240, 37]) -> torch.Size([4240, 200])\n",
            "2025-05-27 21:36:27,804 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4240, 200]), Edge index shape: torch.Size([2, 5622])\n",
            "2025-05-27 21:36:27,805 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4240, 200])\n",
            "2025-05-27 21:36:27,805 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4240, 200]) -> torch.Size([4240, 200])\n",
            "2025-05-27 21:36:27,806 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4240, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,807 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3394, 200]), Nodes kept: 3394/4240 (80.0%)\n",
            "2025-05-27 21:36:27,807 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4240, 200]) -> torch.Size([3394, 200])\n",
            "2025-05-27 21:36:27,808 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3394, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,808 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,808 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3394, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,808 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,808 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,808 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,808 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0427\n",
            "2025-05-27 21:36:27,811 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 177, Batch 0/5, Loss: 0.0427\n",
            "2025-05-27 21:36:27,813 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6677 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,813 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6677, Edges: 8376, Graphs: 4\n",
            "2025-05-27 21:36:27,813 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6677]) -> torch.Size([6677, 37])\n",
            "2025-05-27 21:36:27,813 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6677, 37]), Edge index shape: torch.Size([2, 8376])\n",
            "2025-05-27 21:36:27,814 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6677, 200])\n",
            "2025-05-27 21:36:27,814 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6677, 37]) -> torch.Size([6677, 200])\n",
            "2025-05-27 21:36:27,814 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6677, 200]), Edge index shape: torch.Size([2, 8376])\n",
            "2025-05-27 21:36:27,815 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6677, 200])\n",
            "2025-05-27 21:36:27,815 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6677, 200]) -> torch.Size([6677, 200])\n",
            "2025-05-27 21:36:27,816 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6677, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,818 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5342, 200]), Nodes kept: 5342/6677 (80.0%)\n",
            "2025-05-27 21:36:27,818 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6677, 200]) -> torch.Size([5342, 200])\n",
            "2025-05-27 21:36:27,818 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5342, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,818 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,818 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5342, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,818 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,818 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,819 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,819 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:27,824 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3898 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,824 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3898, Edges: 4537, Graphs: 4\n",
            "2025-05-27 21:36:27,824 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3898]) -> torch.Size([3898, 37])\n",
            "2025-05-27 21:36:27,824 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3898, 37]), Edge index shape: torch.Size([2, 4537])\n",
            "2025-05-27 21:36:27,825 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3898, 200])\n",
            "2025-05-27 21:36:27,825 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3898, 37]) -> torch.Size([3898, 200])\n",
            "2025-05-27 21:36:27,826 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3898, 200]), Edge index shape: torch.Size([2, 4537])\n",
            "2025-05-27 21:36:27,826 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3898, 200])\n",
            "2025-05-27 21:36:27,827 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3898, 200]) -> torch.Size([3898, 200])\n",
            "2025-05-27 21:36:27,827 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3898, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,828 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3119, 200]), Nodes kept: 3119/3898 (80.0%)\n",
            "2025-05-27 21:36:27,829 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3898, 200]) -> torch.Size([3119, 200])\n",
            "2025-05-27 21:36:27,829 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3119, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,829 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,829 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3119, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,829 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,829 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,829 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,830 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:27,834 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4195 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,834 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4195, Edges: 5547, Graphs: 4\n",
            "2025-05-27 21:36:27,834 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4195]) -> torch.Size([4195, 37])\n",
            "2025-05-27 21:36:27,835 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4195, 37]), Edge index shape: torch.Size([2, 5547])\n",
            "2025-05-27 21:36:27,835 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4195, 200])\n",
            "2025-05-27 21:36:27,836 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4195, 37]) -> torch.Size([4195, 200])\n",
            "2025-05-27 21:36:27,836 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4195, 200]), Edge index shape: torch.Size([2, 5547])\n",
            "2025-05-27 21:36:27,837 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4195, 200])\n",
            "2025-05-27 21:36:27,837 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4195, 200]) -> torch.Size([4195, 200])\n",
            "2025-05-27 21:36:27,837 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4195, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,839 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3358, 200]), Nodes kept: 3358/4195 (80.0%)\n",
            "2025-05-27 21:36:27,839 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4195, 200]) -> torch.Size([3358, 200])\n",
            "2025-05-27 21:36:27,839 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3358, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,839 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,840 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3358, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,840 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,840 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,840 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,840 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2551\n",
            "2025-05-27 21:36:27,845 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2703 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,845 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2703, Edges: 3755, Graphs: 2\n",
            "2025-05-27 21:36:27,845 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2703]) -> torch.Size([2703, 37])\n",
            "2025-05-27 21:36:27,845 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2703, 37]), Edge index shape: torch.Size([2, 3755])\n",
            "2025-05-27 21:36:27,846 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2703, 200])\n",
            "2025-05-27 21:36:27,846 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2703, 37]) -> torch.Size([2703, 200])\n",
            "2025-05-27 21:36:27,846 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2703, 200]), Edge index shape: torch.Size([2, 3755])\n",
            "2025-05-27 21:36:27,847 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2703, 200])\n",
            "2025-05-27 21:36:27,847 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2703, 200]) -> torch.Size([2703, 200])\n",
            "2025-05-27 21:36:27,847 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2703, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,849 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2163, 200]), Nodes kept: 2163/2703 (80.0%)\n",
            "2025-05-27 21:36:27,849 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2703, 200]) -> torch.Size([2163, 200])\n",
            "2025-05-27 21:36:27,849 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2163, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,850 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,850 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2163, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,850 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,850 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,850 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,850 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0072\n",
            "Epoch: 0177, loss_train: 0.0610, time: 0.1s:  88% 177/200 [00:17<00:01, 11.55it/s]2025-05-27 21:36:27,853 - trainers.GraphTrainer - INFO - train:427 - Epoch 177 completed - Avg loss: 0.0610, Time: 0.1s\n",
            "2025-05-27 21:36:27,853 - trainers.GraphTrainer - INFO - train:427 - Epoch 177 completed - Avg loss: 0.0610, Time: 0.1s\n",
            "2025-05-27 21:36:27,855 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3621 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,855 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3621, Edges: 4891, Graphs: 4\n",
            "2025-05-27 21:36:27,855 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3621]) -> torch.Size([3621, 37])\n",
            "2025-05-27 21:36:27,855 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3621, 37]), Edge index shape: torch.Size([2, 4891])\n",
            "2025-05-27 21:36:27,856 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3621, 200])\n",
            "2025-05-27 21:36:27,856 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3621, 37]) -> torch.Size([3621, 200])\n",
            "2025-05-27 21:36:27,856 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3621, 200]), Edge index shape: torch.Size([2, 4891])\n",
            "2025-05-27 21:36:27,857 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3621, 200])\n",
            "2025-05-27 21:36:27,857 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3621, 200]) -> torch.Size([3621, 200])\n",
            "2025-05-27 21:36:27,858 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3621, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,859 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2898, 200]), Nodes kept: 2898/3621 (80.0%)\n",
            "2025-05-27 21:36:27,859 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3621, 200]) -> torch.Size([2898, 200])\n",
            "2025-05-27 21:36:27,859 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2898, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,860 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,860 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2898, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,894 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,895 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,895 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,895 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0010\n",
            "2025-05-27 21:36:27,899 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 178, Batch 0/5, Loss: 0.0010\n",
            "2025-05-27 21:36:27,902 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 9863 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,902 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 9863, Edges: 12567, Graphs: 4\n",
            "2025-05-27 21:36:27,903 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([9863]) -> torch.Size([9863, 37])\n",
            "2025-05-27 21:36:27,903 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([9863, 37]), Edge index shape: torch.Size([2, 12567])\n",
            "2025-05-27 21:36:27,904 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([9863, 200])\n",
            "2025-05-27 21:36:27,905 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([9863, 37]) -> torch.Size([9863, 200])\n",
            "2025-05-27 21:36:27,905 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([9863, 200]), Edge index shape: torch.Size([2, 12567])\n",
            "2025-05-27 21:36:27,906 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([9863, 200])\n",
            "2025-05-27 21:36:27,906 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([9863, 200]) -> torch.Size([9863, 200])\n",
            "2025-05-27 21:36:27,907 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([9863, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,909 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([7891, 200]), Nodes kept: 7891/9863 (80.0%)\n",
            "2025-05-27 21:36:27,910 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([9863, 200]) -> torch.Size([7891, 200])\n",
            "2025-05-27 21:36:27,910 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([7891, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,910 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,910 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([7891, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,910 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,910 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,911 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,911 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:27,918 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4159 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,918 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4159, Edges: 5475, Graphs: 4\n",
            "2025-05-27 21:36:27,918 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4159]) -> torch.Size([4159, 37])\n",
            "2025-05-27 21:36:27,918 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4159, 37]), Edge index shape: torch.Size([2, 5475])\n",
            "2025-05-27 21:36:27,919 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4159, 200])\n",
            "2025-05-27 21:36:27,920 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4159, 37]) -> torch.Size([4159, 200])\n",
            "2025-05-27 21:36:27,920 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4159, 200]), Edge index shape: torch.Size([2, 5475])\n",
            "2025-05-27 21:36:27,921 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4159, 200])\n",
            "2025-05-27 21:36:27,921 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4159, 200]) -> torch.Size([4159, 200])\n",
            "2025-05-27 21:36:27,921 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4159, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,923 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3329, 200]), Nodes kept: 3329/4159 (80.0%)\n",
            "2025-05-27 21:36:27,924 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4159, 200]) -> torch.Size([3329, 200])\n",
            "2025-05-27 21:36:27,924 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3329, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,924 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,924 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3329, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,924 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,924 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,925 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,925 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0629\n",
            "2025-05-27 21:36:27,930 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2642 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,930 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2642, Edges: 3230, Graphs: 4\n",
            "2025-05-27 21:36:27,930 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2642]) -> torch.Size([2642, 37])\n",
            "2025-05-27 21:36:27,930 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2642, 37]), Edge index shape: torch.Size([2, 3230])\n",
            "2025-05-27 21:36:27,931 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2642, 200])\n",
            "2025-05-27 21:36:27,932 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2642, 37]) -> torch.Size([2642, 200])\n",
            "2025-05-27 21:36:27,932 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2642, 200]), Edge index shape: torch.Size([2, 3230])\n",
            "2025-05-27 21:36:27,933 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2642, 200])\n",
            "2025-05-27 21:36:27,933 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2642, 200]) -> torch.Size([2642, 200])\n",
            "2025-05-27 21:36:27,933 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2642, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,935 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2115, 200]), Nodes kept: 2115/2642 (80.1%)\n",
            "2025-05-27 21:36:27,935 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2642, 200]) -> torch.Size([2115, 200])\n",
            "2025-05-27 21:36:27,935 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2115, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,936 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,936 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2115, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,936 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,936 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,936 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,937 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0008\n",
            "2025-05-27 21:36:27,941 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1428 nodes, 2 graphs\n",
            "2025-05-27 21:36:27,941 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1428, Edges: 1674, Graphs: 2\n",
            "2025-05-27 21:36:27,942 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1428]) -> torch.Size([1428, 37])\n",
            "2025-05-27 21:36:27,942 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1428, 37]), Edge index shape: torch.Size([2, 1674])\n",
            "2025-05-27 21:36:27,943 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1428, 200])\n",
            "2025-05-27 21:36:27,943 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1428, 37]) -> torch.Size([1428, 200])\n",
            "2025-05-27 21:36:27,943 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1428, 200]), Edge index shape: torch.Size([2, 1674])\n",
            "2025-05-27 21:36:27,944 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1428, 200])\n",
            "2025-05-27 21:36:27,944 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1428, 200]) -> torch.Size([1428, 200])\n",
            "2025-05-27 21:36:27,945 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1428, 200]), Batch size: 2\n",
            "2025-05-27 21:36:27,946 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1143, 200]), Nodes kept: 1143/1428 (80.0%)\n",
            "2025-05-27 21:36:27,947 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1428, 200]) -> torch.Size([1143, 200])\n",
            "2025-05-27 21:36:27,947 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1143, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:27,947 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,947 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1143, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,947 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,947 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:27,948 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:27,948 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2318\n",
            "Epoch: 0178, loss_train: 0.0593, time: 0.1s:  88% 177/200 [00:17<00:01, 11.55it/s]2025-05-27 21:36:27,951 - trainers.GraphTrainer - INFO - train:427 - Epoch 178 completed - Avg loss: 0.0593, Time: 0.1s\n",
            "2025-05-27 21:36:27,951 - trainers.GraphTrainer - INFO - train:427 - Epoch 178 completed - Avg loss: 0.0593, Time: 0.1s\n",
            "Epoch: 0178, loss_train: 0.0593, time: 0.1s:  90% 179/200 [00:17<00:01, 12.03it/s]2025-05-27 21:36:27,953 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8516 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,953 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8516, Edges: 11138, Graphs: 4\n",
            "2025-05-27 21:36:27,954 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8516]) -> torch.Size([8516, 37])\n",
            "2025-05-27 21:36:27,954 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8516, 37]), Edge index shape: torch.Size([2, 11138])\n",
            "2025-05-27 21:36:27,955 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8516, 200])\n",
            "2025-05-27 21:36:27,955 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8516, 37]) -> torch.Size([8516, 200])\n",
            "2025-05-27 21:36:27,955 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8516, 200]), Edge index shape: torch.Size([2, 11138])\n",
            "2025-05-27 21:36:27,956 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8516, 200])\n",
            "2025-05-27 21:36:27,956 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8516, 200]) -> torch.Size([8516, 200])\n",
            "2025-05-27 21:36:27,957 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8516, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,959 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6814, 200]), Nodes kept: 6814/8516 (80.0%)\n",
            "2025-05-27 21:36:27,959 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8516, 200]) -> torch.Size([6814, 200])\n",
            "2025-05-27 21:36:27,960 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6814, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,960 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,960 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6814, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,960 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,960 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,960 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,961 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:27,965 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 179, Batch 0/5, Loss: 0.0000\n",
            "2025-05-27 21:36:27,967 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3125 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,967 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3125, Edges: 3595, Graphs: 4\n",
            "2025-05-27 21:36:27,968 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3125]) -> torch.Size([3125, 37])\n",
            "2025-05-27 21:36:27,968 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3125, 37]), Edge index shape: torch.Size([2, 3595])\n",
            "2025-05-27 21:36:27,969 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3125, 200])\n",
            "2025-05-27 21:36:27,969 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3125, 37]) -> torch.Size([3125, 200])\n",
            "2025-05-27 21:36:27,969 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3125, 200]), Edge index shape: torch.Size([2, 3595])\n",
            "2025-05-27 21:36:27,970 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3125, 200])\n",
            "2025-05-27 21:36:27,970 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3125, 200]) -> torch.Size([3125, 200])\n",
            "2025-05-27 21:36:27,971 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3125, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,973 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2501, 200]), Nodes kept: 2501/3125 (80.0%)\n",
            "2025-05-27 21:36:27,973 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3125, 200]) -> torch.Size([2501, 200])\n",
            "2025-05-27 21:36:27,973 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2501, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,973 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,973 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2501, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,974 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,974 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,974 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,974 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0012\n",
            "2025-05-27 21:36:27,980 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2356 nodes, 4 graphs\n",
            "2025-05-27 21:36:27,980 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2356, Edges: 2796, Graphs: 4\n",
            "2025-05-27 21:36:27,980 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2356]) -> torch.Size([2356, 37])\n",
            "2025-05-27 21:36:27,980 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2356, 37]), Edge index shape: torch.Size([2, 2796])\n",
            "2025-05-27 21:36:27,981 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2356, 200])\n",
            "2025-05-27 21:36:27,982 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2356, 37]) -> torch.Size([2356, 200])\n",
            "2025-05-27 21:36:27,982 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2356, 200]), Edge index shape: torch.Size([2, 2796])\n",
            "2025-05-27 21:36:27,983 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2356, 200])\n",
            "2025-05-27 21:36:27,996 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2356, 200]) -> torch.Size([2356, 200])\n",
            "2025-05-27 21:36:27,996 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2356, 200]), Batch size: 4\n",
            "2025-05-27 21:36:27,998 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1886, 200]), Nodes kept: 1886/2356 (80.1%)\n",
            "2025-05-27 21:36:27,998 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2356, 200]) -> torch.Size([1886, 200])\n",
            "2025-05-27 21:36:27,998 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1886, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:27,998 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,998 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1886, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,998 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,999 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:27,999 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:27,999 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1633\n",
            "2025-05-27 21:36:28,003 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6889 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,003 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6889, Edges: 9350, Graphs: 4\n",
            "2025-05-27 21:36:28,004 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6889]) -> torch.Size([6889, 37])\n",
            "2025-05-27 21:36:28,004 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6889, 37]), Edge index shape: torch.Size([2, 9350])\n",
            "2025-05-27 21:36:28,005 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6889, 200])\n",
            "2025-05-27 21:36:28,005 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6889, 37]) -> torch.Size([6889, 200])\n",
            "2025-05-27 21:36:28,005 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6889, 200]), Edge index shape: torch.Size([2, 9350])\n",
            "2025-05-27 21:36:28,006 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6889, 200])\n",
            "2025-05-27 21:36:28,006 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6889, 200]) -> torch.Size([6889, 200])\n",
            "2025-05-27 21:36:28,007 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6889, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,009 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5513, 200]), Nodes kept: 5513/6889 (80.0%)\n",
            "2025-05-27 21:36:28,009 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6889, 200]) -> torch.Size([5513, 200])\n",
            "2025-05-27 21:36:28,009 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5513, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,009 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,009 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5513, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,009 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,009 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,010 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,010 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1224\n",
            "2025-05-27 21:36:28,015 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 827 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,015 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 827, Edges: 958, Graphs: 2\n",
            "2025-05-27 21:36:28,015 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([827]) -> torch.Size([827, 37])\n",
            "2025-05-27 21:36:28,015 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([827, 37]), Edge index shape: torch.Size([2, 958])\n",
            "2025-05-27 21:36:28,016 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([827, 200])\n",
            "2025-05-27 21:36:28,016 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([827, 37]) -> torch.Size([827, 200])\n",
            "2025-05-27 21:36:28,017 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([827, 200]), Edge index shape: torch.Size([2, 958])\n",
            "2025-05-27 21:36:28,017 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([827, 200])\n",
            "2025-05-27 21:36:28,018 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([827, 200]) -> torch.Size([827, 200])\n",
            "2025-05-27 21:36:28,018 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([827, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,019 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([662, 200]), Nodes kept: 662/827 (80.0%)\n",
            "2025-05-27 21:36:28,019 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([827, 200]) -> torch.Size([662, 200])\n",
            "2025-05-27 21:36:28,020 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([662, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,020 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,020 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([662, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,020 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,020 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,020 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,021 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0018\n",
            "Epoch: 0179, loss_train: 0.0577, time: 0.1s:  90% 179/200 [00:17<00:01, 12.03it/s]2025-05-27 21:36:28,023 - trainers.GraphTrainer - INFO - train:427 - Epoch 179 completed - Avg loss: 0.0577, Time: 0.1s\n",
            "2025-05-27 21:36:28,023 - trainers.GraphTrainer - INFO - train:427 - Epoch 179 completed - Avg loss: 0.0577, Time: 0.1s\n",
            "2025-05-27 21:36:28,025 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3731 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,025 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3731, Edges: 4303, Graphs: 4\n",
            "2025-05-27 21:36:28,025 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3731]) -> torch.Size([3731, 37])\n",
            "2025-05-27 21:36:28,025 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3731, 37]), Edge index shape: torch.Size([2, 4303])\n",
            "2025-05-27 21:36:28,026 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3731, 200])\n",
            "2025-05-27 21:36:28,026 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3731, 37]) -> torch.Size([3731, 200])\n",
            "2025-05-27 21:36:28,026 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3731, 200]), Edge index shape: torch.Size([2, 4303])\n",
            "2025-05-27 21:36:28,027 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3731, 200])\n",
            "2025-05-27 21:36:28,028 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3731, 200]) -> torch.Size([3731, 200])\n",
            "2025-05-27 21:36:28,028 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3731, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,029 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2987, 200]), Nodes kept: 2987/3731 (80.1%)\n",
            "2025-05-27 21:36:28,030 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3731, 200]) -> torch.Size([2987, 200])\n",
            "2025-05-27 21:36:28,030 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2987, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,030 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,030 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2987, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,030 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,030 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,030 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,031 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0640\n",
            "2025-05-27 21:36:28,034 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 180, Batch 0/5, Loss: 0.0640\n",
            "2025-05-27 21:36:28,035 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3530 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,035 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3530, Edges: 4713, Graphs: 4\n",
            "2025-05-27 21:36:28,035 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3530]) -> torch.Size([3530, 37])\n",
            "2025-05-27 21:36:28,036 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3530, 37]), Edge index shape: torch.Size([2, 4713])\n",
            "2025-05-27 21:36:28,036 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3530, 200])\n",
            "2025-05-27 21:36:28,037 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3530, 37]) -> torch.Size([3530, 200])\n",
            "2025-05-27 21:36:28,037 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3530, 200]), Edge index shape: torch.Size([2, 4713])\n",
            "2025-05-27 21:36:28,038 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3530, 200])\n",
            "2025-05-27 21:36:28,038 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3530, 200]) -> torch.Size([3530, 200])\n",
            "2025-05-27 21:36:28,038 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3530, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,040 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2825, 200]), Nodes kept: 2825/3530 (80.0%)\n",
            "2025-05-27 21:36:28,040 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3530, 200]) -> torch.Size([2825, 200])\n",
            "2025-05-27 21:36:28,040 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2825, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,040 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,040 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2825, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,040 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,041 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,041 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,041 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0019\n",
            "2025-05-27 21:36:28,045 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4380 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,045 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4380, Edges: 5849, Graphs: 4\n",
            "2025-05-27 21:36:28,046 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4380]) -> torch.Size([4380, 37])\n",
            "2025-05-27 21:36:28,046 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4380, 37]), Edge index shape: torch.Size([2, 5849])\n",
            "2025-05-27 21:36:28,047 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4380, 200])\n",
            "2025-05-27 21:36:28,047 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4380, 37]) -> torch.Size([4380, 200])\n",
            "2025-05-27 21:36:28,047 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4380, 200]), Edge index shape: torch.Size([2, 5849])\n",
            "2025-05-27 21:36:28,048 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4380, 200])\n",
            "2025-05-27 21:36:28,048 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4380, 200]) -> torch.Size([4380, 200])\n",
            "2025-05-27 21:36:28,048 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4380, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,050 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3505, 200]), Nodes kept: 3505/4380 (80.0%)\n",
            "2025-05-27 21:36:28,050 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4380, 200]) -> torch.Size([3505, 200])\n",
            "2025-05-27 21:36:28,050 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3505, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,051 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,051 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3505, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,051 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,051 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,051 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,051 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:28,056 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6689 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,056 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6689, Edges: 8403, Graphs: 4\n",
            "2025-05-27 21:36:28,057 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6689]) -> torch.Size([6689, 37])\n",
            "2025-05-27 21:36:28,057 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6689, 37]), Edge index shape: torch.Size([2, 8403])\n",
            "2025-05-27 21:36:28,058 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6689, 200])\n",
            "2025-05-27 21:36:28,058 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6689, 37]) -> torch.Size([6689, 200])\n",
            "2025-05-27 21:36:28,058 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6689, 200]), Edge index shape: torch.Size([2, 8403])\n",
            "2025-05-27 21:36:28,059 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6689, 200])\n",
            "2025-05-27 21:36:28,059 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6689, 200]) -> torch.Size([6689, 200])\n",
            "2025-05-27 21:36:28,060 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6689, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,062 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5352, 200]), Nodes kept: 5352/6689 (80.0%)\n",
            "2025-05-27 21:36:28,062 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6689, 200]) -> torch.Size([5352, 200])\n",
            "2025-05-27 21:36:28,062 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5352, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,062 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,063 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5352, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,063 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,063 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,063 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,063 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0005\n",
            "2025-05-27 21:36:28,069 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3383 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,069 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3383, Edges: 4569, Graphs: 2\n",
            "2025-05-27 21:36:28,096 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3383]) -> torch.Size([3383, 37])\n",
            "2025-05-27 21:36:28,096 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3383, 37]), Edge index shape: torch.Size([2, 4569])\n",
            "2025-05-27 21:36:28,097 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,097 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3383, 37]) -> torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,097 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3383, 200]), Edge index shape: torch.Size([2, 4569])\n",
            "2025-05-27 21:36:28,098 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,098 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3383, 200]) -> torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,098 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3383, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,100 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2707, 200]), Nodes kept: 2707/3383 (80.0%)\n",
            "2025-05-27 21:36:28,100 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3383, 200]) -> torch.Size([2707, 200])\n",
            "2025-05-27 21:36:28,100 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2707, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,101 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,101 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2707, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,101 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,101 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,101 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,101 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.5305\n",
            "Epoch: 0180, loss_train: 0.1194, time: 0.1s:  90% 179/200 [00:17<00:01, 12.03it/s]2025-05-27 21:36:28,104 - trainers.GraphTrainer - INFO - train:427 - Epoch 180 completed - Avg loss: 0.1194, Time: 0.1s\n",
            "2025-05-27 21:36:28,104 - trainers.GraphTrainer - INFO - train:427 - Epoch 180 completed - Avg loss: 0.1194, Time: 0.1s\n",
            "2025-05-27 21:36:28,104 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 180...\n",
            "2025-05-27 21:36:28,104 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 180...\n",
            "2025-05-27 21:36:28,105 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:28,105 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:28,106 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,106 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5060, Edges: 6597, Graphs: 4\n",
            "2025-05-27 21:36:28,106 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5060]) -> torch.Size([5060, 37])\n",
            "2025-05-27 21:36:28,106 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5060, 37]), Edge index shape: torch.Size([2, 6597])\n",
            "2025-05-27 21:36:28,107 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,108 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5060, 37]) -> torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,108 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5060, 200]), Edge index shape: torch.Size([2, 6597])\n",
            "2025-05-27 21:36:28,108 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,109 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5060, 200]) -> torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,109 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5060, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,111 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4049, 200]), Nodes kept: 4049/5060 (80.0%)\n",
            "2025-05-27 21:36:28,111 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5060, 200]) -> torch.Size([4049, 200])\n",
            "2025-05-27 21:36:28,111 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4049, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,111 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,111 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4049, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,111 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,112 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,112 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,112 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0716\n",
            "2025-05-27 21:36:28,113 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:28,114 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,114 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 7827, Edges: 10299, Graphs: 4\n",
            "2025-05-27 21:36:28,114 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([7827]) -> torch.Size([7827, 37])\n",
            "2025-05-27 21:36:28,114 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7827, 37]), Edge index shape: torch.Size([2, 10299])\n",
            "2025-05-27 21:36:28,115 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7827, 200])\n",
            "2025-05-27 21:36:28,115 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([7827, 37]) -> torch.Size([7827, 200])\n",
            "2025-05-27 21:36:28,115 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7827, 200]), Edge index shape: torch.Size([2, 10299])\n",
            "2025-05-27 21:36:28,116 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7827, 200])\n",
            "2025-05-27 21:36:28,117 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([7827, 200]) -> torch.Size([7827, 200])\n",
            "2025-05-27 21:36:28,117 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([7827, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,119 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6263, 200]), Nodes kept: 6263/7827 (80.0%)\n",
            "2025-05-27 21:36:28,119 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([7827, 200]) -> torch.Size([6263, 200])\n",
            "2025-05-27 21:36:28,119 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6263, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,119 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,119 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6263, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,120 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,120 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,120 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,120 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0173\n",
            "2025-05-27 21:36:28,122 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,122 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2474, Edges: 3003, Graphs: 4\n",
            "2025-05-27 21:36:28,122 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2474]) -> torch.Size([2474, 37])\n",
            "2025-05-27 21:36:28,123 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2474, 37]), Edge index shape: torch.Size([2, 3003])\n",
            "2025-05-27 21:36:28,123 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2474, 200])\n",
            "2025-05-27 21:36:28,124 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2474, 37]) -> torch.Size([2474, 200])\n",
            "2025-05-27 21:36:28,124 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2474, 200]), Edge index shape: torch.Size([2, 3003])\n",
            "2025-05-27 21:36:28,124 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2474, 200])\n",
            "2025-05-27 21:36:28,125 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2474, 200]) -> torch.Size([2474, 200])\n",
            "2025-05-27 21:36:28,125 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2474, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,126 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1981, 200]), Nodes kept: 1981/2474 (80.1%)\n",
            "2025-05-27 21:36:28,127 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2474, 200]) -> torch.Size([1981, 200])\n",
            "2025-05-27 21:36:28,127 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1981, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,127 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,127 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1981, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,127 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,127 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,127 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,128 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.1068\n",
            "2025-05-27 21:36:28,129 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,129 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3649, Edges: 4183, Graphs: 4\n",
            "2025-05-27 21:36:28,129 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3649]) -> torch.Size([3649, 37])\n",
            "2025-05-27 21:36:28,130 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3649, 37]), Edge index shape: torch.Size([2, 4183])\n",
            "2025-05-27 21:36:28,130 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3649, 200])\n",
            "2025-05-27 21:36:28,131 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3649, 37]) -> torch.Size([3649, 200])\n",
            "2025-05-27 21:36:28,131 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3649, 200]), Edge index shape: torch.Size([2, 4183])\n",
            "2025-05-27 21:36:28,131 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3649, 200])\n",
            "2025-05-27 21:36:28,132 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3649, 200]) -> torch.Size([3649, 200])\n",
            "2025-05-27 21:36:28,132 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3649, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,133 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2920, 200]), Nodes kept: 2920/3649 (80.0%)\n",
            "2025-05-27 21:36:28,133 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3649, 200]) -> torch.Size([2920, 200])\n",
            "2025-05-27 21:36:28,134 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2920, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,134 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,134 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2920, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,134 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,134 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,134 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,134 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.1250\n",
            "2025-05-27 21:36:28,136 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,136 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2703, Edges: 3755, Graphs: 2\n",
            "2025-05-27 21:36:28,136 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2703]) -> torch.Size([2703, 37])\n",
            "2025-05-27 21:36:28,136 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2703, 37]), Edge index shape: torch.Size([2, 3755])\n",
            "2025-05-27 21:36:28,137 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2703, 200])\n",
            "2025-05-27 21:36:28,137 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2703, 37]) -> torch.Size([2703, 200])\n",
            "2025-05-27 21:36:28,138 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2703, 200]), Edge index shape: torch.Size([2, 3755])\n",
            "2025-05-27 21:36:28,138 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2703, 200])\n",
            "2025-05-27 21:36:28,138 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2703, 200]) -> torch.Size([2703, 200])\n",
            "2025-05-27 21:36:28,139 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2703, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,141 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2163, 200]), Nodes kept: 2163/2703 (80.0%)\n",
            "2025-05-27 21:36:28,141 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2703, 200]) -> torch.Size([2163, 200])\n",
            "2025-05-27 21:36:28,141 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2163, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,141 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,142 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2163, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,142 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,142 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,142 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,142 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0062\n",
            "2025-05-27 21:36:28,143 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0654, Predictions: 18\n",
            "2025-05-27 21:36:28,143 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0654, Predictions: 18\n",
            "2025-05-27 21:36:28,143 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:28,143 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:28,144 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,145 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 782, Edges: 972, Graphs: 1\n",
            "2025-05-27 21:36:28,145 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([782]) -> torch.Size([782, 37])\n",
            "2025-05-27 21:36:28,145 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 37]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:28,146 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:28,146 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([782, 37]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:28,146 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 200]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:28,147 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:28,147 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([782, 200]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:28,147 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([782, 200]), Batch size: 1\n",
            "2025-05-27 21:36:28,149 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([626, 200]), Nodes kept: 626/782 (80.1%)\n",
            "2025-05-27 21:36:28,197 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([782, 200]) -> torch.Size([626, 200])\n",
            "2025-05-27 21:36:28,197 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([626, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:28,198 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,198 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([626, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,198 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,198 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,198 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:28,199 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:28,199 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:28,201 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,201 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 833, Edges: 1034, Graphs: 1\n",
            "2025-05-27 21:36:28,202 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([833]) -> torch.Size([833, 37])\n",
            "2025-05-27 21:36:28,202 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 37]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:28,204 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:28,204 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([833, 37]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:28,205 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 200]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:28,205 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:28,206 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([833, 200]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:28,206 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([833, 200]), Batch size: 1\n",
            "2025-05-27 21:36:28,208 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([667, 200]), Nodes kept: 667/833 (80.1%)\n",
            "2025-05-27 21:36:28,208 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([833, 200]) -> torch.Size([667, 200])\n",
            "2025-05-27 21:36:28,208 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([667, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:28,209 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,209 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([667, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,209 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,209 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,209 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:28,209 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:28,211 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,211 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2541, Edges: 3576, Graphs: 1\n",
            "2025-05-27 21:36:28,211 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2541]) -> torch.Size([2541, 37])\n",
            "2025-05-27 21:36:28,212 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 37]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:28,212 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:28,213 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2541, 37]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:28,213 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 200]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:28,214 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:28,214 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2541, 200]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:28,214 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2541, 200]), Batch size: 1\n",
            "2025-05-27 21:36:28,216 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2033, 200]), Nodes kept: 2033/2541 (80.0%)\n",
            "2025-05-27 21:36:28,216 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2541, 200]) -> torch.Size([2033, 200])\n",
            "2025-05-27 21:36:28,216 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2033, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:28,217 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,217 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2033, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,217 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,217 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,217 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:28,217 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 7.8336\n",
            "2025-05-27 21:36:28,219 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,219 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 717, Edges: 838, Graphs: 1\n",
            "2025-05-27 21:36:28,219 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([717]) -> torch.Size([717, 37])\n",
            "2025-05-27 21:36:28,219 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 37]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:28,220 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:28,220 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([717, 37]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:28,221 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 200]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:28,221 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:28,222 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([717, 200]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:28,222 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([717, 200]), Batch size: 1\n",
            "2025-05-27 21:36:28,224 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([574, 200]), Nodes kept: 574/717 (80.1%)\n",
            "2025-05-27 21:36:28,224 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([717, 200]) -> torch.Size([574, 200])\n",
            "2025-05-27 21:36:28,224 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([574, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:28,224 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,224 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([574, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,224 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,224 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,225 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:28,225 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.9368\n",
            "2025-05-27 21:36:28,226 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:28,227 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1830, Edges: 2170, Graphs: 1\n",
            "2025-05-27 21:36:28,227 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1830]) -> torch.Size([1830, 37])\n",
            "2025-05-27 21:36:28,227 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 37]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:28,228 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:28,228 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1830, 37]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:28,228 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 200]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:28,229 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:28,229 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1830, 200]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:28,229 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1830, 200]), Batch size: 1\n",
            "2025-05-27 21:36:28,231 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1464, 200]), Nodes kept: 1464/1830 (80.0%)\n",
            "2025-05-27 21:36:28,231 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1830, 200]) -> torch.Size([1464, 200])\n",
            "2025-05-27 21:36:28,231 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1464, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:28,232 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,232 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1464, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,232 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,232 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:28,232 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:28,232 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 5.6591\n",
            "2025-05-27 21:36:28,233 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 2.8859, Predictions: 5\n",
            "2025-05-27 21:36:28,233 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 2.8859, Predictions: 5\n",
            "\n",
            "Mini Test for Epochs 180:\n",
            "2025-05-27 21:36:28,233 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for train...\n",
            "train loss: 0.0654, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:28,242 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0654, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:28,242 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0654, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:28,242 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for test ...\n",
            "test  loss: 2.8859, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:28,250 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 2.8859, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:28,250 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 2.8859, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:28,250 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.1s\n",
            "2025-05-27 21:36:28,250 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.1s\n",
            "Epoch: 0180, loss_train: 0.1194, time: 0.1s:  90% 181/200 [00:17<00:01,  9.69it/s]2025-05-27 21:36:28,253 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3294 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,253 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3294, Edges: 3757, Graphs: 4\n",
            "2025-05-27 21:36:28,253 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3294]) -> torch.Size([3294, 37])\n",
            "2025-05-27 21:36:28,254 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3294, 37]), Edge index shape: torch.Size([2, 3757])\n",
            "2025-05-27 21:36:28,255 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3294, 200])\n",
            "2025-05-27 21:36:28,255 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3294, 37]) -> torch.Size([3294, 200])\n",
            "2025-05-27 21:36:28,255 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3294, 200]), Edge index shape: torch.Size([2, 3757])\n",
            "2025-05-27 21:36:28,256 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3294, 200])\n",
            "2025-05-27 21:36:28,256 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3294, 200]) -> torch.Size([3294, 200])\n",
            "2025-05-27 21:36:28,257 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3294, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,259 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2637, 200]), Nodes kept: 2637/3294 (80.1%)\n",
            "2025-05-27 21:36:28,259 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3294, 200]) -> torch.Size([2637, 200])\n",
            "2025-05-27 21:36:28,259 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2637, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,259 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,259 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2637, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,259 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,260 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,260 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,260 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0391\n",
            "2025-05-27 21:36:28,264 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 181, Batch 0/5, Loss: 0.0391\n",
            "2025-05-27 21:36:28,265 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3270 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,266 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3270, Edges: 3953, Graphs: 4\n",
            "2025-05-27 21:36:28,266 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3270]) -> torch.Size([3270, 37])\n",
            "2025-05-27 21:36:28,266 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3270, 37]), Edge index shape: torch.Size([2, 3953])\n",
            "2025-05-27 21:36:28,267 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3270, 200])\n",
            "2025-05-27 21:36:28,267 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3270, 37]) -> torch.Size([3270, 200])\n",
            "2025-05-27 21:36:28,267 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3270, 200]), Edge index shape: torch.Size([2, 3953])\n",
            "2025-05-27 21:36:28,268 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3270, 200])\n",
            "2025-05-27 21:36:28,269 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3270, 200]) -> torch.Size([3270, 200])\n",
            "2025-05-27 21:36:28,269 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3270, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,271 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2617, 200]), Nodes kept: 2617/3270 (80.0%)\n",
            "2025-05-27 21:36:28,271 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3270, 200]) -> torch.Size([2617, 200])\n",
            "2025-05-27 21:36:28,298 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2617, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,298 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,298 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2617, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,298 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,298 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,299 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,299 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0006\n",
            "2025-05-27 21:36:28,303 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6048 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,303 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6048, Edges: 8294, Graphs: 4\n",
            "2025-05-27 21:36:28,304 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6048]) -> torch.Size([6048, 37])\n",
            "2025-05-27 21:36:28,304 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6048, 37]), Edge index shape: torch.Size([2, 8294])\n",
            "2025-05-27 21:36:28,305 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6048, 200])\n",
            "2025-05-27 21:36:28,305 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6048, 37]) -> torch.Size([6048, 200])\n",
            "2025-05-27 21:36:28,305 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6048, 200]), Edge index shape: torch.Size([2, 8294])\n",
            "2025-05-27 21:36:28,306 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6048, 200])\n",
            "2025-05-27 21:36:28,306 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6048, 200]) -> torch.Size([6048, 200])\n",
            "2025-05-27 21:36:28,307 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6048, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,308 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4840, 200]), Nodes kept: 4840/6048 (80.0%)\n",
            "2025-05-27 21:36:28,309 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6048, 200]) -> torch.Size([4840, 200])\n",
            "2025-05-27 21:36:28,309 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4840, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,309 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,309 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4840, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,309 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,309 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,310 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,310 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0448\n",
            "2025-05-27 21:36:28,315 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5595 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,315 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5595, Edges: 7064, Graphs: 4\n",
            "2025-05-27 21:36:28,316 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5595]) -> torch.Size([5595, 37])\n",
            "2025-05-27 21:36:28,316 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5595, 37]), Edge index shape: torch.Size([2, 7064])\n",
            "2025-05-27 21:36:28,317 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5595, 200])\n",
            "2025-05-27 21:36:28,317 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5595, 37]) -> torch.Size([5595, 200])\n",
            "2025-05-27 21:36:28,317 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5595, 200]), Edge index shape: torch.Size([2, 7064])\n",
            "2025-05-27 21:36:28,318 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5595, 200])\n",
            "2025-05-27 21:36:28,318 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5595, 200]) -> torch.Size([5595, 200])\n",
            "2025-05-27 21:36:28,318 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5595, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,320 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4477, 200]), Nodes kept: 4477/5595 (80.0%)\n",
            "2025-05-27 21:36:28,320 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5595, 200]) -> torch.Size([4477, 200])\n",
            "2025-05-27 21:36:28,320 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4477, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,321 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,321 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4477, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,321 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,321 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,321 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,321 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0158\n",
            "2025-05-27 21:36:28,326 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3506 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,326 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3506, Edges: 4769, Graphs: 2\n",
            "2025-05-27 21:36:28,327 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3506]) -> torch.Size([3506, 37])\n",
            "2025-05-27 21:36:28,327 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3506, 37]), Edge index shape: torch.Size([2, 4769])\n",
            "2025-05-27 21:36:28,328 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3506, 200])\n",
            "2025-05-27 21:36:28,328 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3506, 37]) -> torch.Size([3506, 200])\n",
            "2025-05-27 21:36:28,328 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3506, 200]), Edge index shape: torch.Size([2, 4769])\n",
            "2025-05-27 21:36:28,329 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3506, 200])\n",
            "2025-05-27 21:36:28,329 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3506, 200]) -> torch.Size([3506, 200])\n",
            "2025-05-27 21:36:28,329 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3506, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,331 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2805, 200]), Nodes kept: 2805/3506 (80.0%)\n",
            "2025-05-27 21:36:28,331 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3506, 200]) -> torch.Size([2805, 200])\n",
            "2025-05-27 21:36:28,331 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2805, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,331 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,331 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2805, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,332 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,332 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,332 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,332 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0181, loss_train: 0.0201, time: 0.1s:  90% 181/200 [00:17<00:01,  9.69it/s]2025-05-27 21:36:28,335 - trainers.GraphTrainer - INFO - train:427 - Epoch 181 completed - Avg loss: 0.0201, Time: 0.1s\n",
            "2025-05-27 21:36:28,335 - trainers.GraphTrainer - INFO - train:427 - Epoch 181 completed - Avg loss: 0.0201, Time: 0.1s\n",
            "2025-05-27 21:36:28,337 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5013 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,337 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5013, Edges: 6535, Graphs: 4\n",
            "2025-05-27 21:36:28,337 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5013]) -> torch.Size([5013, 37])\n",
            "2025-05-27 21:36:28,337 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5013, 37]), Edge index shape: torch.Size([2, 6535])\n",
            "2025-05-27 21:36:28,338 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5013, 200])\n",
            "2025-05-27 21:36:28,339 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5013, 37]) -> torch.Size([5013, 200])\n",
            "2025-05-27 21:36:28,339 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5013, 200]), Edge index shape: torch.Size([2, 6535])\n",
            "2025-05-27 21:36:28,340 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5013, 200])\n",
            "2025-05-27 21:36:28,340 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5013, 200]) -> torch.Size([5013, 200])\n",
            "2025-05-27 21:36:28,340 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5013, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,342 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4011, 200]), Nodes kept: 4011/5013 (80.0%)\n",
            "2025-05-27 21:36:28,342 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5013, 200]) -> torch.Size([4011, 200])\n",
            "2025-05-27 21:36:28,343 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4011, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,343 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,343 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4011, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,343 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,343 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,343 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,344 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0055\n",
            "2025-05-27 21:36:28,347 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 182, Batch 0/5, Loss: 0.0055\n",
            "2025-05-27 21:36:28,348 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2448 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,349 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2448, Edges: 2922, Graphs: 4\n",
            "2025-05-27 21:36:28,349 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2448]) -> torch.Size([2448, 37])\n",
            "2025-05-27 21:36:28,349 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2448, 37]), Edge index shape: torch.Size([2, 2922])\n",
            "2025-05-27 21:36:28,350 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2448, 200])\n",
            "2025-05-27 21:36:28,350 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2448, 37]) -> torch.Size([2448, 200])\n",
            "2025-05-27 21:36:28,350 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2448, 200]), Edge index shape: torch.Size([2, 2922])\n",
            "2025-05-27 21:36:28,351 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2448, 200])\n",
            "2025-05-27 21:36:28,351 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2448, 200]) -> torch.Size([2448, 200])\n",
            "2025-05-27 21:36:28,351 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2448, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,353 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1960, 200]), Nodes kept: 1960/2448 (80.1%)\n",
            "2025-05-27 21:36:28,353 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2448, 200]) -> torch.Size([1960, 200])\n",
            "2025-05-27 21:36:28,353 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1960, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,353 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,354 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1960, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,354 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,354 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,354 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,354 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0246\n",
            "2025-05-27 21:36:28,358 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4281 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,358 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4281, Edges: 5706, Graphs: 4\n",
            "2025-05-27 21:36:28,358 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4281]) -> torch.Size([4281, 37])\n",
            "2025-05-27 21:36:28,358 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4281, 37]), Edge index shape: torch.Size([2, 5706])\n",
            "2025-05-27 21:36:28,359 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4281, 200])\n",
            "2025-05-27 21:36:28,359 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4281, 37]) -> torch.Size([4281, 200])\n",
            "2025-05-27 21:36:28,359 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4281, 200]), Edge index shape: torch.Size([2, 5706])\n",
            "2025-05-27 21:36:28,360 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4281, 200])\n",
            "2025-05-27 21:36:28,361 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4281, 200]) -> torch.Size([4281, 200])\n",
            "2025-05-27 21:36:28,361 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4281, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,363 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3427, 200]), Nodes kept: 3427/4281 (80.1%)\n",
            "2025-05-27 21:36:28,363 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4281, 200]) -> torch.Size([3427, 200])\n",
            "2025-05-27 21:36:28,363 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3427, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,363 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,363 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3427, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,363 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,363 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,364 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,364 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.4520\n",
            "2025-05-27 21:36:28,368 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 7298 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,369 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 7298, Edges: 8936, Graphs: 4\n",
            "2025-05-27 21:36:28,369 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([7298]) -> torch.Size([7298, 37])\n",
            "2025-05-27 21:36:28,369 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7298, 37]), Edge index shape: torch.Size([2, 8936])\n",
            "2025-05-27 21:36:28,370 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7298, 200])\n",
            "2025-05-27 21:36:28,370 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([7298, 37]) -> torch.Size([7298, 200])\n",
            "2025-05-27 21:36:28,370 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7298, 200]), Edge index shape: torch.Size([2, 8936])\n",
            "2025-05-27 21:36:28,371 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7298, 200])\n",
            "2025-05-27 21:36:28,371 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([7298, 200]) -> torch.Size([7298, 200])\n",
            "2025-05-27 21:36:28,372 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([7298, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,374 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5839, 200]), Nodes kept: 5839/7298 (80.0%)\n",
            "2025-05-27 21:36:28,398 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([7298, 200]) -> torch.Size([5839, 200])\n",
            "2025-05-27 21:36:28,398 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5839, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,399 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,399 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5839, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,399 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,399 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,399 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,399 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0055\n",
            "2025-05-27 21:36:28,406 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2673 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,407 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2673, Edges: 3738, Graphs: 2\n",
            "2025-05-27 21:36:28,407 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2673]) -> torch.Size([2673, 37])\n",
            "2025-05-27 21:36:28,407 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2673, 37]), Edge index shape: torch.Size([2, 3738])\n",
            "2025-05-27 21:36:28,408 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2673, 200])\n",
            "2025-05-27 21:36:28,408 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2673, 37]) -> torch.Size([2673, 200])\n",
            "2025-05-27 21:36:28,408 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2673, 200]), Edge index shape: torch.Size([2, 3738])\n",
            "2025-05-27 21:36:28,409 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2673, 200])\n",
            "2025-05-27 21:36:28,410 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2673, 200]) -> torch.Size([2673, 200])\n",
            "2025-05-27 21:36:28,410 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2673, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,415 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2139, 200]), Nodes kept: 2139/2673 (80.0%)\n",
            "2025-05-27 21:36:28,415 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2673, 200]) -> torch.Size([2139, 200])\n",
            "2025-05-27 21:36:28,415 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2139, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,416 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,416 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2139, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,416 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,416 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,416 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,416 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0182, loss_train: 0.0975, time: 0.1s:  90% 181/200 [00:17<00:01,  9.69it/s]2025-05-27 21:36:28,420 - trainers.GraphTrainer - INFO - train:427 - Epoch 182 completed - Avg loss: 0.0975, Time: 0.1s\n",
            "2025-05-27 21:36:28,420 - trainers.GraphTrainer - INFO - train:427 - Epoch 182 completed - Avg loss: 0.0975, Time: 0.1s\n",
            "Epoch: 0182, loss_train: 0.0975, time: 0.1s:  92% 183/200 [00:17<00:01, 10.25it/s]2025-05-27 21:36:28,422 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6170 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,422 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6170, Edges: 8493, Graphs: 4\n",
            "2025-05-27 21:36:28,422 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6170]) -> torch.Size([6170, 37])\n",
            "2025-05-27 21:36:28,422 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6170, 37]), Edge index shape: torch.Size([2, 8493])\n",
            "2025-05-27 21:36:28,423 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6170, 200])\n",
            "2025-05-27 21:36:28,424 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6170, 37]) -> torch.Size([6170, 200])\n",
            "2025-05-27 21:36:28,424 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6170, 200]), Edge index shape: torch.Size([2, 8493])\n",
            "2025-05-27 21:36:28,425 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6170, 200])\n",
            "2025-05-27 21:36:28,425 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6170, 200]) -> torch.Size([6170, 200])\n",
            "2025-05-27 21:36:28,425 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6170, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,427 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4937, 200]), Nodes kept: 4937/6170 (80.0%)\n",
            "2025-05-27 21:36:28,428 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6170, 200]) -> torch.Size([4937, 200])\n",
            "2025-05-27 21:36:28,428 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4937, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,428 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,428 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4937, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,428 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,428 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,429 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,429 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0002\n",
            "2025-05-27 21:36:28,433 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 183, Batch 0/5, Loss: 0.0002\n",
            "2025-05-27 21:36:28,435 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5060 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,435 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5060, Edges: 6597, Graphs: 4\n",
            "2025-05-27 21:36:28,435 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5060]) -> torch.Size([5060, 37])\n",
            "2025-05-27 21:36:28,435 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5060, 37]), Edge index shape: torch.Size([2, 6597])\n",
            "2025-05-27 21:36:28,436 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,436 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5060, 37]) -> torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,436 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5060, 200]), Edge index shape: torch.Size([2, 6597])\n",
            "2025-05-27 21:36:28,437 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,438 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5060, 200]) -> torch.Size([5060, 200])\n",
            "2025-05-27 21:36:28,438 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5060, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,440 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4049, 200]), Nodes kept: 4049/5060 (80.0%)\n",
            "2025-05-27 21:36:28,440 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5060, 200]) -> torch.Size([4049, 200])\n",
            "2025-05-27 21:36:28,440 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4049, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,441 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,441 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4049, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,441 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,441 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,441 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,441 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0020\n",
            "2025-05-27 21:36:28,446 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1613 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,446 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1613, Edges: 1926, Graphs: 4\n",
            "2025-05-27 21:36:28,447 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1613]) -> torch.Size([1613, 37])\n",
            "2025-05-27 21:36:28,447 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1613, 37]), Edge index shape: torch.Size([2, 1926])\n",
            "2025-05-27 21:36:28,448 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1613, 200])\n",
            "2025-05-27 21:36:28,448 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1613, 37]) -> torch.Size([1613, 200])\n",
            "2025-05-27 21:36:28,448 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1613, 200]), Edge index shape: torch.Size([2, 1926])\n",
            "2025-05-27 21:36:28,449 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1613, 200])\n",
            "2025-05-27 21:36:28,449 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1613, 200]) -> torch.Size([1613, 200])\n",
            "2025-05-27 21:36:28,450 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1613, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,452 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1292, 200]), Nodes kept: 1292/1613 (80.1%)\n",
            "2025-05-27 21:36:28,452 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1613, 200]) -> torch.Size([1292, 200])\n",
            "2025-05-27 21:36:28,452 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1292, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,452 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,452 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1292, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,452 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,452 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,453 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,453 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2609\n",
            "2025-05-27 21:36:28,458 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5699 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,458 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5699, Edges: 7214, Graphs: 4\n",
            "2025-05-27 21:36:28,458 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5699]) -> torch.Size([5699, 37])\n",
            "2025-05-27 21:36:28,458 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5699, 37]), Edge index shape: torch.Size([2, 7214])\n",
            "2025-05-27 21:36:28,459 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5699, 200])\n",
            "2025-05-27 21:36:28,459 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5699, 37]) -> torch.Size([5699, 200])\n",
            "2025-05-27 21:36:28,459 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5699, 200]), Edge index shape: torch.Size([2, 7214])\n",
            "2025-05-27 21:36:28,460 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5699, 200])\n",
            "2025-05-27 21:36:28,461 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5699, 200]) -> torch.Size([5699, 200])\n",
            "2025-05-27 21:36:28,461 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5699, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,463 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4561, 200]), Nodes kept: 4561/5699 (80.0%)\n",
            "2025-05-27 21:36:28,463 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5699, 200]) -> torch.Size([4561, 200])\n",
            "2025-05-27 21:36:28,463 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4561, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,464 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,464 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4561, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,464 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,464 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,464 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,464 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0306\n",
            "2025-05-27 21:36:28,470 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3171 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,470 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3171, Edges: 3607, Graphs: 2\n",
            "2025-05-27 21:36:28,470 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3171]) -> torch.Size([3171, 37])\n",
            "2025-05-27 21:36:28,470 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3171, 37]), Edge index shape: torch.Size([2, 3607])\n",
            "2025-05-27 21:36:28,471 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3171, 200])\n",
            "2025-05-27 21:36:28,471 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3171, 37]) -> torch.Size([3171, 200])\n",
            "2025-05-27 21:36:28,471 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3171, 200]), Edge index shape: torch.Size([2, 3607])\n",
            "2025-05-27 21:36:28,472 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3171, 200])\n",
            "2025-05-27 21:36:28,473 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3171, 200]) -> torch.Size([3171, 200])\n",
            "2025-05-27 21:36:28,473 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3171, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,475 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2537, 200]), Nodes kept: 2537/3171 (80.0%)\n",
            "2025-05-27 21:36:28,475 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3171, 200]) -> torch.Size([2537, 200])\n",
            "2025-05-27 21:36:28,475 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2537, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,475 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,475 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2537, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,476 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,476 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,476 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,476 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "Epoch: 0183, loss_train: 0.0588, time: 0.1s:  92% 183/200 [00:17<00:01, 10.25it/s]2025-05-27 21:36:28,479 - trainers.GraphTrainer - INFO - train:427 - Epoch 183 completed - Avg loss: 0.0588, Time: 0.1s\n",
            "2025-05-27 21:36:28,479 - trainers.GraphTrainer - INFO - train:427 - Epoch 183 completed - Avg loss: 0.0588, Time: 0.1s\n",
            "2025-05-27 21:36:28,481 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4187 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,481 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4187, Edges: 5534, Graphs: 4\n",
            "2025-05-27 21:36:28,482 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4187]) -> torch.Size([4187, 37])\n",
            "2025-05-27 21:36:28,499 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4187, 37]), Edge index shape: torch.Size([2, 5534])\n",
            "2025-05-27 21:36:28,500 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4187, 200])\n",
            "2025-05-27 21:36:28,500 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4187, 37]) -> torch.Size([4187, 200])\n",
            "2025-05-27 21:36:28,501 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4187, 200]), Edge index shape: torch.Size([2, 5534])\n",
            "2025-05-27 21:36:28,502 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4187, 200])\n",
            "2025-05-27 21:36:28,502 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4187, 200]) -> torch.Size([4187, 200])\n",
            "2025-05-27 21:36:28,502 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4187, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,504 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3352, 200]), Nodes kept: 3352/4187 (80.1%)\n",
            "2025-05-27 21:36:28,504 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4187, 200]) -> torch.Size([3352, 200])\n",
            "2025-05-27 21:36:28,504 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3352, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,504 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,505 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3352, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,505 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,505 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,505 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,505 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1609\n",
            "2025-05-27 21:36:28,508 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 184, Batch 0/5, Loss: 0.1609\n",
            "2025-05-27 21:36:28,510 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3030 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,510 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3030, Edges: 3433, Graphs: 4\n",
            "2025-05-27 21:36:28,510 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3030]) -> torch.Size([3030, 37])\n",
            "2025-05-27 21:36:28,510 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3030, 37]), Edge index shape: torch.Size([2, 3433])\n",
            "2025-05-27 21:36:28,511 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3030, 200])\n",
            "2025-05-27 21:36:28,511 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3030, 37]) -> torch.Size([3030, 200])\n",
            "2025-05-27 21:36:28,511 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3030, 200]), Edge index shape: torch.Size([2, 3433])\n",
            "2025-05-27 21:36:28,512 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3030, 200])\n",
            "2025-05-27 21:36:28,513 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3030, 200]) -> torch.Size([3030, 200])\n",
            "2025-05-27 21:36:28,513 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3030, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,515 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2425, 200]), Nodes kept: 2425/3030 (80.0%)\n",
            "2025-05-27 21:36:28,515 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3030, 200]) -> torch.Size([2425, 200])\n",
            "2025-05-27 21:36:28,515 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2425, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,515 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,515 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2425, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,515 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,515 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,516 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,516 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0111\n",
            "2025-05-27 21:36:28,520 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4354 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,520 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4354, Edges: 5768, Graphs: 4\n",
            "2025-05-27 21:36:28,520 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4354]) -> torch.Size([4354, 37])\n",
            "2025-05-27 21:36:28,520 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4354, 37]), Edge index shape: torch.Size([2, 5768])\n",
            "2025-05-27 21:36:28,521 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4354, 200])\n",
            "2025-05-27 21:36:28,521 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4354, 37]) -> torch.Size([4354, 200])\n",
            "2025-05-27 21:36:28,522 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4354, 200]), Edge index shape: torch.Size([2, 5768])\n",
            "2025-05-27 21:36:28,522 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4354, 200])\n",
            "2025-05-27 21:36:28,523 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4354, 200]) -> torch.Size([4354, 200])\n",
            "2025-05-27 21:36:28,523 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4354, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,525 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3484, 200]), Nodes kept: 3484/4354 (80.0%)\n",
            "2025-05-27 21:36:28,525 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4354, 200]) -> torch.Size([3484, 200])\n",
            "2025-05-27 21:36:28,525 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3484, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,525 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,525 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3484, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,525 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,526 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,526 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,526 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:28,531 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6673 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,531 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6673, Edges: 8374, Graphs: 4\n",
            "2025-05-27 21:36:28,531 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6673]) -> torch.Size([6673, 37])\n",
            "2025-05-27 21:36:28,531 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6673, 37]), Edge index shape: torch.Size([2, 8374])\n",
            "2025-05-27 21:36:28,532 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6673, 200])\n",
            "2025-05-27 21:36:28,532 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6673, 37]) -> torch.Size([6673, 200])\n",
            "2025-05-27 21:36:28,532 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6673, 200]), Edge index shape: torch.Size([2, 8374])\n",
            "2025-05-27 21:36:28,533 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6673, 200])\n",
            "2025-05-27 21:36:28,534 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6673, 200]) -> torch.Size([6673, 200])\n",
            "2025-05-27 21:36:28,534 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6673, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,536 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5339, 200]), Nodes kept: 5339/6673 (80.0%)\n",
            "2025-05-27 21:36:28,536 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6673, 200]) -> torch.Size([5339, 200])\n",
            "2025-05-27 21:36:28,536 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5339, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,536 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,536 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5339, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,537 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,537 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,537 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,537 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:28,542 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3469 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,542 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3469, Edges: 4728, Graphs: 2\n",
            "2025-05-27 21:36:28,543 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3469]) -> torch.Size([3469, 37])\n",
            "2025-05-27 21:36:28,543 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3469, 37]), Edge index shape: torch.Size([2, 4728])\n",
            "2025-05-27 21:36:28,543 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3469, 200])\n",
            "2025-05-27 21:36:28,544 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3469, 37]) -> torch.Size([3469, 200])\n",
            "2025-05-27 21:36:28,544 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3469, 200]), Edge index shape: torch.Size([2, 4728])\n",
            "2025-05-27 21:36:28,545 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3469, 200])\n",
            "2025-05-27 21:36:28,545 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3469, 200]) -> torch.Size([3469, 200])\n",
            "2025-05-27 21:36:28,545 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3469, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,547 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2776, 200]), Nodes kept: 2776/3469 (80.0%)\n",
            "2025-05-27 21:36:28,547 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3469, 200]) -> torch.Size([2776, 200])\n",
            "2025-05-27 21:36:28,547 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2776, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,547 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,547 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2776, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,547 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,547 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,548 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,548 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0184, loss_train: 0.0344, time: 0.1s:  92% 183/200 [00:17<00:01, 10.25it/s]2025-05-27 21:36:28,551 - trainers.GraphTrainer - INFO - train:427 - Epoch 184 completed - Avg loss: 0.0344, Time: 0.1s\n",
            "2025-05-27 21:36:28,551 - trainers.GraphTrainer - INFO - train:427 - Epoch 184 completed - Avg loss: 0.0344, Time: 0.1s\n",
            "Epoch: 0184, loss_train: 0.0344, time: 0.1s:  92% 185/200 [00:17<00:01, 11.37it/s]2025-05-27 21:36:28,553 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4261 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,553 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4261, Edges: 5651, Graphs: 4\n",
            "2025-05-27 21:36:28,553 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4261]) -> torch.Size([4261, 37])\n",
            "2025-05-27 21:36:28,553 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4261, 37]), Edge index shape: torch.Size([2, 5651])\n",
            "2025-05-27 21:36:28,554 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4261, 200])\n",
            "2025-05-27 21:36:28,554 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4261, 37]) -> torch.Size([4261, 200])\n",
            "2025-05-27 21:36:28,554 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4261, 200]), Edge index shape: torch.Size([2, 5651])\n",
            "2025-05-27 21:36:28,555 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4261, 200])\n",
            "2025-05-27 21:36:28,556 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4261, 200]) -> torch.Size([4261, 200])\n",
            "2025-05-27 21:36:28,556 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4261, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,558 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3410, 200]), Nodes kept: 3410/4261 (80.0%)\n",
            "2025-05-27 21:36:28,558 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4261, 200]) -> torch.Size([3410, 200])\n",
            "2025-05-27 21:36:28,558 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3410, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,559 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,559 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3410, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,559 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,559 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,559 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,559 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0004\n",
            "2025-05-27 21:36:28,563 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 185, Batch 0/5, Loss: 0.0004\n",
            "2025-05-27 21:36:28,564 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8474 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,564 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8474, Edges: 11028, Graphs: 4\n",
            "2025-05-27 21:36:28,565 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8474]) -> torch.Size([8474, 37])\n",
            "2025-05-27 21:36:28,565 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8474, 37]), Edge index shape: torch.Size([2, 11028])\n",
            "2025-05-27 21:36:28,566 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8474, 200])\n",
            "2025-05-27 21:36:28,566 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8474, 37]) -> torch.Size([8474, 200])\n",
            "2025-05-27 21:36:28,566 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8474, 200]), Edge index shape: torch.Size([2, 11028])\n",
            "2025-05-27 21:36:28,567 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8474, 200])\n",
            "2025-05-27 21:36:28,567 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8474, 200]) -> torch.Size([8474, 200])\n",
            "2025-05-27 21:36:28,568 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8474, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,570 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6780, 200]), Nodes kept: 6780/8474 (80.0%)\n",
            "2025-05-27 21:36:28,570 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8474, 200]) -> torch.Size([6780, 200])\n",
            "2025-05-27 21:36:28,570 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6780, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,570 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,570 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6780, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,571 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,571 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,600 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,600 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0005\n",
            "2025-05-27 21:36:28,606 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4457 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,606 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4457, Edges: 5183, Graphs: 4\n",
            "2025-05-27 21:36:28,607 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4457]) -> torch.Size([4457, 37])\n",
            "2025-05-27 21:36:28,607 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4457, 37]), Edge index shape: torch.Size([2, 5183])\n",
            "2025-05-27 21:36:28,608 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4457, 200])\n",
            "2025-05-27 21:36:28,608 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4457, 37]) -> torch.Size([4457, 200])\n",
            "2025-05-27 21:36:28,608 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4457, 200]), Edge index shape: torch.Size([2, 5183])\n",
            "2025-05-27 21:36:28,609 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4457, 200])\n",
            "2025-05-27 21:36:28,609 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4457, 200]) -> torch.Size([4457, 200])\n",
            "2025-05-27 21:36:28,609 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4457, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,611 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3567, 200]), Nodes kept: 3567/4457 (80.0%)\n",
            "2025-05-27 21:36:28,611 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4457, 200]) -> torch.Size([3567, 200])\n",
            "2025-05-27 21:36:28,611 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3567, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,612 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,612 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3567, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,612 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,612 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,612 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,612 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2502\n",
            "2025-05-27 21:36:28,617 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3733 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,617 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3733, Edges: 5054, Graphs: 4\n",
            "2025-05-27 21:36:28,617 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3733]) -> torch.Size([3733, 37])\n",
            "2025-05-27 21:36:28,617 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3733, 37]), Edge index shape: torch.Size([2, 5054])\n",
            "2025-05-27 21:36:28,618 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3733, 200])\n",
            "2025-05-27 21:36:28,618 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3733, 37]) -> torch.Size([3733, 200])\n",
            "2025-05-27 21:36:28,618 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3733, 200]), Edge index shape: torch.Size([2, 5054])\n",
            "2025-05-27 21:36:28,619 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3733, 200])\n",
            "2025-05-27 21:36:28,619 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3733, 200]) -> torch.Size([3733, 200])\n",
            "2025-05-27 21:36:28,620 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3733, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,621 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2988, 200]), Nodes kept: 2988/3733 (80.0%)\n",
            "2025-05-27 21:36:28,621 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3733, 200]) -> torch.Size([2988, 200])\n",
            "2025-05-27 21:36:28,621 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2988, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,622 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,622 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2988, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,622 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,622 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,622 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,622 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:28,626 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 788 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,627 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 788, Edges: 921, Graphs: 2\n",
            "2025-05-27 21:36:28,627 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([788]) -> torch.Size([788, 37])\n",
            "2025-05-27 21:36:28,627 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([788, 37]), Edge index shape: torch.Size([2, 921])\n",
            "2025-05-27 21:36:28,628 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([788, 200])\n",
            "2025-05-27 21:36:28,628 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([788, 37]) -> torch.Size([788, 200])\n",
            "2025-05-27 21:36:28,628 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([788, 200]), Edge index shape: torch.Size([2, 921])\n",
            "2025-05-27 21:36:28,629 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([788, 200])\n",
            "2025-05-27 21:36:28,629 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([788, 200]) -> torch.Size([788, 200])\n",
            "2025-05-27 21:36:28,629 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([788, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,631 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([631, 200]), Nodes kept: 631/788 (80.1%)\n",
            "2025-05-27 21:36:28,631 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([788, 200]) -> torch.Size([631, 200])\n",
            "2025-05-27 21:36:28,631 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([631, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,631 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,631 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([631, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,632 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,632 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,632 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,632 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1383\n",
            "Epoch: 0185, loss_train: 0.0779, time: 0.1s:  92% 185/200 [00:17<00:01, 11.37it/s]2025-05-27 21:36:28,634 - trainers.GraphTrainer - INFO - train:427 - Epoch 185 completed - Avg loss: 0.0779, Time: 0.1s\n",
            "2025-05-27 21:36:28,634 - trainers.GraphTrainer - INFO - train:427 - Epoch 185 completed - Avg loss: 0.0779, Time: 0.1s\n",
            "2025-05-27 21:36:28,636 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5555 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,636 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5555, Edges: 7003, Graphs: 4\n",
            "2025-05-27 21:36:28,637 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5555]) -> torch.Size([5555, 37])\n",
            "2025-05-27 21:36:28,637 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5555, 37]), Edge index shape: torch.Size([2, 7003])\n",
            "2025-05-27 21:36:28,638 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5555, 200])\n",
            "2025-05-27 21:36:28,638 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5555, 37]) -> torch.Size([5555, 200])\n",
            "2025-05-27 21:36:28,638 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5555, 200]), Edge index shape: torch.Size([2, 7003])\n",
            "2025-05-27 21:36:28,639 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5555, 200])\n",
            "2025-05-27 21:36:28,639 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5555, 200]) -> torch.Size([5555, 200])\n",
            "2025-05-27 21:36:28,639 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5555, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,641 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4445, 200]), Nodes kept: 4445/5555 (80.0%)\n",
            "2025-05-27 21:36:28,641 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5555, 200]) -> torch.Size([4445, 200])\n",
            "2025-05-27 21:36:28,641 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4445, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,642 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,642 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4445, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,642 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,642 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,642 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,642 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0616\n",
            "2025-05-27 21:36:28,646 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 186, Batch 0/5, Loss: 0.0616\n",
            "2025-05-27 21:36:28,648 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5938 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,648 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5938, Edges: 7480, Graphs: 4\n",
            "2025-05-27 21:36:28,648 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5938]) -> torch.Size([5938, 37])\n",
            "2025-05-27 21:36:28,648 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5938, 37]), Edge index shape: torch.Size([2, 7480])\n",
            "2025-05-27 21:36:28,649 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5938, 200])\n",
            "2025-05-27 21:36:28,649 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5938, 37]) -> torch.Size([5938, 200])\n",
            "2025-05-27 21:36:28,649 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5938, 200]), Edge index shape: torch.Size([2, 7480])\n",
            "2025-05-27 21:36:28,650 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5938, 200])\n",
            "2025-05-27 21:36:28,650 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5938, 200]) -> torch.Size([5938, 200])\n",
            "2025-05-27 21:36:28,651 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5938, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,652 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4752, 200]), Nodes kept: 4752/5938 (80.0%)\n",
            "2025-05-27 21:36:28,652 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5938, 200]) -> torch.Size([4752, 200])\n",
            "2025-05-27 21:36:28,653 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4752, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,653 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,653 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4752, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,653 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,653 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,653 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,654 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0158\n",
            "2025-05-27 21:36:28,659 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3251 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,659 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3251, Edges: 3930, Graphs: 4\n",
            "2025-05-27 21:36:28,659 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3251]) -> torch.Size([3251, 37])\n",
            "2025-05-27 21:36:28,659 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3251, 37]), Edge index shape: torch.Size([2, 3930])\n",
            "2025-05-27 21:36:28,660 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3251, 200])\n",
            "2025-05-27 21:36:28,660 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3251, 37]) -> torch.Size([3251, 200])\n",
            "2025-05-27 21:36:28,660 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3251, 200]), Edge index shape: torch.Size([2, 3930])\n",
            "2025-05-27 21:36:28,661 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3251, 200])\n",
            "2025-05-27 21:36:28,661 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3251, 200]) -> torch.Size([3251, 200])\n",
            "2025-05-27 21:36:28,661 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3251, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,663 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2602, 200]), Nodes kept: 2602/3251 (80.0%)\n",
            "2025-05-27 21:36:28,663 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3251, 200]) -> torch.Size([2602, 200])\n",
            "2025-05-27 21:36:28,663 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2602, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,664 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,664 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2602, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,664 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,664 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,664 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,664 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1158\n",
            "2025-05-27 21:36:28,668 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5341 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,669 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5341, Edges: 7464, Graphs: 4\n",
            "2025-05-27 21:36:28,669 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5341]) -> torch.Size([5341, 37])\n",
            "2025-05-27 21:36:28,669 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5341, 37]), Edge index shape: torch.Size([2, 7464])\n",
            "2025-05-27 21:36:28,670 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5341, 200])\n",
            "2025-05-27 21:36:28,670 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5341, 37]) -> torch.Size([5341, 200])\n",
            "2025-05-27 21:36:28,670 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5341, 200]), Edge index shape: torch.Size([2, 7464])\n",
            "2025-05-27 21:36:28,671 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5341, 200])\n",
            "2025-05-27 21:36:28,671 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5341, 200]) -> torch.Size([5341, 200])\n",
            "2025-05-27 21:36:28,672 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5341, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,673 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4274, 200]), Nodes kept: 4274/5341 (80.0%)\n",
            "2025-05-27 21:36:28,674 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5341, 200]) -> torch.Size([4274, 200])\n",
            "2025-05-27 21:36:28,674 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4274, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,674 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,701 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4274, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,701 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,701 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,701 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,702 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0002\n",
            "2025-05-27 21:36:28,708 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1628 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,708 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1628, Edges: 1960, Graphs: 2\n",
            "2025-05-27 21:36:28,709 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1628]) -> torch.Size([1628, 37])\n",
            "2025-05-27 21:36:28,709 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1628, 37]), Edge index shape: torch.Size([2, 1960])\n",
            "2025-05-27 21:36:28,710 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1628, 200])\n",
            "2025-05-27 21:36:28,710 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1628, 37]) -> torch.Size([1628, 200])\n",
            "2025-05-27 21:36:28,710 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1628, 200]), Edge index shape: torch.Size([2, 1960])\n",
            "2025-05-27 21:36:28,712 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1628, 200])\n",
            "2025-05-27 21:36:28,712 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1628, 200]) -> torch.Size([1628, 200])\n",
            "2025-05-27 21:36:28,712 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1628, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,714 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1303, 200]), Nodes kept: 1303/1628 (80.0%)\n",
            "2025-05-27 21:36:28,714 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1628, 200]) -> torch.Size([1303, 200])\n",
            "2025-05-27 21:36:28,715 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1303, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,715 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,715 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1303, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,715 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,715 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,715 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,716 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0008\n",
            "Epoch: 0186, loss_train: 0.0388, time: 0.1s:  92% 185/200 [00:17<00:01, 11.37it/s]2025-05-27 21:36:28,719 - trainers.GraphTrainer - INFO - train:427 - Epoch 186 completed - Avg loss: 0.0388, Time: 0.1s\n",
            "2025-05-27 21:36:28,719 - trainers.GraphTrainer - INFO - train:427 - Epoch 186 completed - Avg loss: 0.0388, Time: 0.1s\n",
            "Epoch: 0186, loss_train: 0.0388, time: 0.1s:  94% 187/200 [00:17<00:01, 11.51it/s]2025-05-27 21:36:28,722 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6881 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,722 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6881, Edges: 9325, Graphs: 4\n",
            "2025-05-27 21:36:28,722 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6881]) -> torch.Size([6881, 37])\n",
            "2025-05-27 21:36:28,722 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6881, 37]), Edge index shape: torch.Size([2, 9325])\n",
            "2025-05-27 21:36:28,723 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6881, 200])\n",
            "2025-05-27 21:36:28,724 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6881, 37]) -> torch.Size([6881, 200])\n",
            "2025-05-27 21:36:28,724 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6881, 200]), Edge index shape: torch.Size([2, 9325])\n",
            "2025-05-27 21:36:28,725 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6881, 200])\n",
            "2025-05-27 21:36:28,725 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6881, 200]) -> torch.Size([6881, 200])\n",
            "2025-05-27 21:36:28,725 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6881, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,727 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5506, 200]), Nodes kept: 5506/6881 (80.0%)\n",
            "2025-05-27 21:36:28,728 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6881, 200]) -> torch.Size([5506, 200])\n",
            "2025-05-27 21:36:28,728 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5506, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,728 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,728 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5506, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,728 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,728 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,729 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,729 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0958\n",
            "2025-05-27 21:36:28,733 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 187, Batch 0/5, Loss: 0.0958\n",
            "2025-05-27 21:36:28,735 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1658 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,735 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1658, Edges: 1912, Graphs: 4\n",
            "2025-05-27 21:36:28,735 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1658]) -> torch.Size([1658, 37])\n",
            "2025-05-27 21:36:28,735 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1658, 37]), Edge index shape: torch.Size([2, 1912])\n",
            "2025-05-27 21:36:28,736 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1658, 200])\n",
            "2025-05-27 21:36:28,737 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1658, 37]) -> torch.Size([1658, 200])\n",
            "2025-05-27 21:36:28,737 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1658, 200]), Edge index shape: torch.Size([2, 1912])\n",
            "2025-05-27 21:36:28,738 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1658, 200])\n",
            "2025-05-27 21:36:28,738 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1658, 200]) -> torch.Size([1658, 200])\n",
            "2025-05-27 21:36:28,738 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1658, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,740 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1327, 200]), Nodes kept: 1327/1658 (80.0%)\n",
            "2025-05-27 21:36:28,740 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1658, 200]) -> torch.Size([1327, 200])\n",
            "2025-05-27 21:36:28,741 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1327, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,741 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,741 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1327, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,741 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,741 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,742 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,743 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0006\n",
            "2025-05-27 21:36:28,748 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5752 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,748 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5752, Edges: 7237, Graphs: 4\n",
            "2025-05-27 21:36:28,748 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5752]) -> torch.Size([5752, 37])\n",
            "2025-05-27 21:36:28,748 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5752, 37]), Edge index shape: torch.Size([2, 7237])\n",
            "2025-05-27 21:36:28,749 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5752, 200])\n",
            "2025-05-27 21:36:28,750 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5752, 37]) -> torch.Size([5752, 200])\n",
            "2025-05-27 21:36:28,750 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5752, 200]), Edge index shape: torch.Size([2, 7237])\n",
            "2025-05-27 21:36:28,751 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5752, 200])\n",
            "2025-05-27 21:36:28,751 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5752, 200]) -> torch.Size([5752, 200])\n",
            "2025-05-27 21:36:28,751 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5752, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,753 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4603, 200]), Nodes kept: 4603/5752 (80.0%)\n",
            "2025-05-27 21:36:28,754 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5752, 200]) -> torch.Size([4603, 200])\n",
            "2025-05-27 21:36:28,754 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4603, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,754 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,754 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4603, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,754 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,754 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,755 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,755 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0904\n",
            "2025-05-27 21:36:28,760 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2606 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,761 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2606, Edges: 3206, Graphs: 4\n",
            "2025-05-27 21:36:28,761 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2606]) -> torch.Size([2606, 37])\n",
            "2025-05-27 21:36:28,761 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2606, 37]), Edge index shape: torch.Size([2, 3206])\n",
            "2025-05-27 21:36:28,762 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2606, 200])\n",
            "2025-05-27 21:36:28,762 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2606, 37]) -> torch.Size([2606, 200])\n",
            "2025-05-27 21:36:28,762 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2606, 200]), Edge index shape: torch.Size([2, 3206])\n",
            "2025-05-27 21:36:28,763 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2606, 200])\n",
            "2025-05-27 21:36:28,764 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2606, 200]) -> torch.Size([2606, 200])\n",
            "2025-05-27 21:36:28,764 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2606, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,766 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2087, 200]), Nodes kept: 2087/2606 (80.1%)\n",
            "2025-05-27 21:36:28,766 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2606, 200]) -> torch.Size([2087, 200])\n",
            "2025-05-27 21:36:28,766 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2087, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,766 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,767 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2087, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,767 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,767 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,767 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,767 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0134\n",
            "2025-05-27 21:36:28,772 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4816 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,772 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4816, Edges: 6157, Graphs: 2\n",
            "2025-05-27 21:36:28,772 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4816]) -> torch.Size([4816, 37])\n",
            "2025-05-27 21:36:28,772 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4816, 37]), Edge index shape: torch.Size([2, 6157])\n",
            "2025-05-27 21:36:28,773 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4816, 200])\n",
            "2025-05-27 21:36:28,774 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4816, 37]) -> torch.Size([4816, 200])\n",
            "2025-05-27 21:36:28,774 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4816, 200]), Edge index shape: torch.Size([2, 6157])\n",
            "2025-05-27 21:36:28,775 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4816, 200])\n",
            "2025-05-27 21:36:28,775 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4816, 200]) -> torch.Size([4816, 200])\n",
            "2025-05-27 21:36:28,775 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4816, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,777 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3853, 200]), Nodes kept: 3853/4816 (80.0%)\n",
            "2025-05-27 21:36:28,778 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4816, 200]) -> torch.Size([3853, 200])\n",
            "2025-05-27 21:36:28,778 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3853, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,778 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,778 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3853, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,778 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,778 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,779 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,779 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0187, loss_train: 0.0400, time: 0.1s:  94% 187/200 [00:18<00:01, 11.51it/s]2025-05-27 21:36:28,783 - trainers.GraphTrainer - INFO - train:427 - Epoch 187 completed - Avg loss: 0.0400, Time: 0.1s\n",
            "2025-05-27 21:36:28,783 - trainers.GraphTrainer - INFO - train:427 - Epoch 187 completed - Avg loss: 0.0400, Time: 0.1s\n",
            "2025-05-27 21:36:28,785 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8120 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,785 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8120, Edges: 10634, Graphs: 4\n",
            "2025-05-27 21:36:28,786 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8120]) -> torch.Size([8120, 37])\n",
            "2025-05-27 21:36:28,786 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8120, 37]), Edge index shape: torch.Size([2, 10634])\n",
            "2025-05-27 21:36:28,787 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8120, 200])\n",
            "2025-05-27 21:36:28,787 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8120, 37]) -> torch.Size([8120, 200])\n",
            "2025-05-27 21:36:28,801 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8120, 200]), Edge index shape: torch.Size([2, 10634])\n",
            "2025-05-27 21:36:28,803 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8120, 200])\n",
            "2025-05-27 21:36:28,803 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8120, 200]) -> torch.Size([8120, 200])\n",
            "2025-05-27 21:36:28,803 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8120, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,805 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6497, 200]), Nodes kept: 6497/8120 (80.0%)\n",
            "2025-05-27 21:36:28,806 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8120, 200]) -> torch.Size([6497, 200])\n",
            "2025-05-27 21:36:28,806 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6497, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,806 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,806 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6497, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,806 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,806 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,807 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,807 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1911\n",
            "2025-05-27 21:36:28,811 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 188, Batch 0/5, Loss: 0.1911\n",
            "2025-05-27 21:36:28,813 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2429 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,813 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2429, Edges: 2897, Graphs: 4\n",
            "2025-05-27 21:36:28,813 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2429]) -> torch.Size([2429, 37])\n",
            "2025-05-27 21:36:28,813 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2429, 37]), Edge index shape: torch.Size([2, 2897])\n",
            "2025-05-27 21:36:28,814 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2429, 200])\n",
            "2025-05-27 21:36:28,814 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2429, 37]) -> torch.Size([2429, 200])\n",
            "2025-05-27 21:36:28,815 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2429, 200]), Edge index shape: torch.Size([2, 2897])\n",
            "2025-05-27 21:36:28,816 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2429, 200])\n",
            "2025-05-27 21:36:28,816 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2429, 200]) -> torch.Size([2429, 200])\n",
            "2025-05-27 21:36:28,816 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2429, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,818 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1944, 200]), Nodes kept: 1944/2429 (80.0%)\n",
            "2025-05-27 21:36:28,818 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2429, 200]) -> torch.Size([1944, 200])\n",
            "2025-05-27 21:36:28,818 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1944, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,818 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,818 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1944, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,818 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,819 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,819 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,819 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:28,823 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6660 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,823 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6660, Edges: 8358, Graphs: 4\n",
            "2025-05-27 21:36:28,823 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6660]) -> torch.Size([6660, 37])\n",
            "2025-05-27 21:36:28,824 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6660, 37]), Edge index shape: torch.Size([2, 8358])\n",
            "2025-05-27 21:36:28,824 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6660, 200])\n",
            "2025-05-27 21:36:28,825 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6660, 37]) -> torch.Size([6660, 200])\n",
            "2025-05-27 21:36:28,825 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6660, 200]), Edge index shape: torch.Size([2, 8358])\n",
            "2025-05-27 21:36:28,826 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6660, 200])\n",
            "2025-05-27 21:36:28,826 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6660, 200]) -> torch.Size([6660, 200])\n",
            "2025-05-27 21:36:28,826 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6660, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,828 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5329, 200]), Nodes kept: 5329/6660 (80.0%)\n",
            "2025-05-27 21:36:28,828 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6660, 200]) -> torch.Size([5329, 200])\n",
            "2025-05-27 21:36:28,828 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5329, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,829 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,829 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5329, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,829 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,829 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,829 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,829 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0247\n",
            "2025-05-27 21:36:28,835 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3551 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,835 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3551, Edges: 4783, Graphs: 4\n",
            "2025-05-27 21:36:28,835 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3551]) -> torch.Size([3551, 37])\n",
            "2025-05-27 21:36:28,835 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3551, 37]), Edge index shape: torch.Size([2, 4783])\n",
            "2025-05-27 21:36:28,836 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3551, 200])\n",
            "2025-05-27 21:36:28,836 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3551, 37]) -> torch.Size([3551, 200])\n",
            "2025-05-27 21:36:28,836 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3551, 200]), Edge index shape: torch.Size([2, 4783])\n",
            "2025-05-27 21:36:28,837 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3551, 200])\n",
            "2025-05-27 21:36:28,837 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3551, 200]) -> torch.Size([3551, 200])\n",
            "2025-05-27 21:36:28,838 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3551, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,839 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2843, 200]), Nodes kept: 2843/3551 (80.1%)\n",
            "2025-05-27 21:36:28,839 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3551, 200]) -> torch.Size([2843, 200])\n",
            "2025-05-27 21:36:28,840 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2843, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,840 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,840 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2843, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,840 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,840 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,840 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,841 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0364\n",
            "2025-05-27 21:36:28,845 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 953 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,845 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 953, Edges: 1165, Graphs: 2\n",
            "2025-05-27 21:36:28,845 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([953]) -> torch.Size([953, 37])\n",
            "2025-05-27 21:36:28,845 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([953, 37]), Edge index shape: torch.Size([2, 1165])\n",
            "2025-05-27 21:36:28,846 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([953, 200])\n",
            "2025-05-27 21:36:28,846 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([953, 37]) -> torch.Size([953, 200])\n",
            "2025-05-27 21:36:28,846 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([953, 200]), Edge index shape: torch.Size([2, 1165])\n",
            "2025-05-27 21:36:28,847 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([953, 200])\n",
            "2025-05-27 21:36:28,847 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([953, 200]) -> torch.Size([953, 200])\n",
            "2025-05-27 21:36:28,847 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([953, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,849 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([763, 200]), Nodes kept: 763/953 (80.1%)\n",
            "2025-05-27 21:36:28,849 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([953, 200]) -> torch.Size([763, 200])\n",
            "2025-05-27 21:36:28,849 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([763, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,850 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,850 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([763, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,850 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,850 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,850 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,850 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0013\n",
            "Epoch: 0188, loss_train: 0.0507, time: 0.1s:  94% 187/200 [00:18<00:01, 11.51it/s]2025-05-27 21:36:28,853 - trainers.GraphTrainer - INFO - train:427 - Epoch 188 completed - Avg loss: 0.0507, Time: 0.1s\n",
            "2025-05-27 21:36:28,853 - trainers.GraphTrainer - INFO - train:427 - Epoch 188 completed - Avg loss: 0.0507, Time: 0.1s\n",
            "Epoch: 0188, loss_train: 0.0507, time: 0.1s:  94% 189/200 [00:18<00:00, 12.37it/s]2025-05-27 21:36:28,855 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1776 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,855 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1776, Edges: 2187, Graphs: 4\n",
            "2025-05-27 21:36:28,855 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1776]) -> torch.Size([1776, 37])\n",
            "2025-05-27 21:36:28,855 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1776, 37]), Edge index shape: torch.Size([2, 2187])\n",
            "2025-05-27 21:36:28,856 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1776, 200])\n",
            "2025-05-27 21:36:28,856 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1776, 37]) -> torch.Size([1776, 200])\n",
            "2025-05-27 21:36:28,856 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1776, 200]), Edge index shape: torch.Size([2, 2187])\n",
            "2025-05-27 21:36:28,857 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1776, 200])\n",
            "2025-05-27 21:36:28,857 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1776, 200]) -> torch.Size([1776, 200])\n",
            "2025-05-27 21:36:28,857 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1776, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,859 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1422, 200]), Nodes kept: 1422/1776 (80.1%)\n",
            "2025-05-27 21:36:28,859 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1776, 200]) -> torch.Size([1422, 200])\n",
            "2025-05-27 21:36:28,859 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1422, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,860 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,860 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1422, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,860 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,860 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,860 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,860 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:28,863 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 189, Batch 0/5, Loss: 0.0001\n",
            "2025-05-27 21:36:28,864 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 7823 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,864 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 7823, Edges: 10297, Graphs: 4\n",
            "2025-05-27 21:36:28,865 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([7823]) -> torch.Size([7823, 37])\n",
            "2025-05-27 21:36:28,865 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7823, 37]), Edge index shape: torch.Size([2, 10297])\n",
            "2025-05-27 21:36:28,866 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7823, 200])\n",
            "2025-05-27 21:36:28,866 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([7823, 37]) -> torch.Size([7823, 200])\n",
            "2025-05-27 21:36:28,866 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([7823, 200]), Edge index shape: torch.Size([2, 10297])\n",
            "2025-05-27 21:36:28,867 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([7823, 200])\n",
            "2025-05-27 21:36:28,867 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([7823, 200]) -> torch.Size([7823, 200])\n",
            "2025-05-27 21:36:28,868 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([7823, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,870 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6260, 200]), Nodes kept: 6260/7823 (80.0%)\n",
            "2025-05-27 21:36:28,870 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([7823, 200]) -> torch.Size([6260, 200])\n",
            "2025-05-27 21:36:28,870 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6260, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,870 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,870 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6260, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,870 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,870 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,871 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,871 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0028\n",
            "2025-05-27 21:36:28,877 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6371 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,877 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6371, Edges: 7974, Graphs: 4\n",
            "2025-05-27 21:36:28,902 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6371]) -> torch.Size([6371, 37])\n",
            "2025-05-27 21:36:28,902 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6371, 37]), Edge index shape: torch.Size([2, 7974])\n",
            "2025-05-27 21:36:28,904 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6371, 200])\n",
            "2025-05-27 21:36:28,905 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6371, 37]) -> torch.Size([6371, 200])\n",
            "2025-05-27 21:36:28,905 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6371, 200]), Edge index shape: torch.Size([2, 7974])\n",
            "2025-05-27 21:36:28,906 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6371, 200])\n",
            "2025-05-27 21:36:28,907 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6371, 200]) -> torch.Size([6371, 200])\n",
            "2025-05-27 21:36:28,907 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6371, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,909 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5097, 200]), Nodes kept: 5097/6371 (80.0%)\n",
            "2025-05-27 21:36:28,909 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6371, 200]) -> torch.Size([5097, 200])\n",
            "2025-05-27 21:36:28,910 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5097, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,910 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,910 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5097, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,910 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,910 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,911 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,911 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0003\n",
            "2025-05-27 21:36:28,918 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4336 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,918 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4336, Edges: 5734, Graphs: 4\n",
            "2025-05-27 21:36:28,918 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4336]) -> torch.Size([4336, 37])\n",
            "2025-05-27 21:36:28,918 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4336, 37]), Edge index shape: torch.Size([2, 5734])\n",
            "2025-05-27 21:36:28,919 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4336, 200])\n",
            "2025-05-27 21:36:28,919 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4336, 37]) -> torch.Size([4336, 200])\n",
            "2025-05-27 21:36:28,919 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4336, 200]), Edge index shape: torch.Size([2, 5734])\n",
            "2025-05-27 21:36:28,920 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4336, 200])\n",
            "2025-05-27 21:36:28,921 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4336, 200]) -> torch.Size([4336, 200])\n",
            "2025-05-27 21:36:28,921 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4336, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,923 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3470, 200]), Nodes kept: 3470/4336 (80.0%)\n",
            "2025-05-27 21:36:28,923 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4336, 200]) -> torch.Size([3470, 200])\n",
            "2025-05-27 21:36:28,923 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3470, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,924 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,924 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3470, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,924 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,924 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,924 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,924 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0207\n",
            "2025-05-27 21:36:28,929 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1407 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,930 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1407, Edges: 1645, Graphs: 2\n",
            "2025-05-27 21:36:28,930 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1407]) -> torch.Size([1407, 37])\n",
            "2025-05-27 21:36:28,930 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1407, 37]), Edge index shape: torch.Size([2, 1645])\n",
            "2025-05-27 21:36:28,931 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1407, 200])\n",
            "2025-05-27 21:36:28,931 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1407, 37]) -> torch.Size([1407, 200])\n",
            "2025-05-27 21:36:28,931 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1407, 200]), Edge index shape: torch.Size([2, 1645])\n",
            "2025-05-27 21:36:28,932 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1407, 200])\n",
            "2025-05-27 21:36:28,932 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1407, 200]) -> torch.Size([1407, 200])\n",
            "2025-05-27 21:36:28,932 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1407, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,934 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1127, 200]), Nodes kept: 1127/1407 (80.1%)\n",
            "2025-05-27 21:36:28,935 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1407, 200]) -> torch.Size([1127, 200])\n",
            "2025-05-27 21:36:28,935 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1127, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:28,935 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,935 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1127, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,935 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,935 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:28,936 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:28,936 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.4276\n",
            "Epoch: 0189, loss_train: 0.0903, time: 0.1s:  94% 189/200 [00:18<00:00, 12.37it/s]2025-05-27 21:36:28,939 - trainers.GraphTrainer - INFO - train:427 - Epoch 189 completed - Avg loss: 0.0903, Time: 0.1s\n",
            "2025-05-27 21:36:28,939 - trainers.GraphTrainer - INFO - train:427 - Epoch 189 completed - Avg loss: 0.0903, Time: 0.1s\n",
            "2025-05-27 21:36:28,941 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4167 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,941 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4167, Edges: 4898, Graphs: 4\n",
            "2025-05-27 21:36:28,942 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4167]) -> torch.Size([4167, 37])\n",
            "2025-05-27 21:36:28,942 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4167, 37]), Edge index shape: torch.Size([2, 4898])\n",
            "2025-05-27 21:36:28,943 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4167, 200])\n",
            "2025-05-27 21:36:28,943 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4167, 37]) -> torch.Size([4167, 200])\n",
            "2025-05-27 21:36:28,943 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4167, 200]), Edge index shape: torch.Size([2, 4898])\n",
            "2025-05-27 21:36:28,944 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4167, 200])\n",
            "2025-05-27 21:36:28,944 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4167, 200]) -> torch.Size([4167, 200])\n",
            "2025-05-27 21:36:28,944 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4167, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,946 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3335, 200]), Nodes kept: 3335/4167 (80.0%)\n",
            "2025-05-27 21:36:28,947 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4167, 200]) -> torch.Size([3335, 200])\n",
            "2025-05-27 21:36:28,947 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3335, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,947 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,947 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3335, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,947 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,947 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,948 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,948 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:28,951 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 190, Batch 0/5, Loss: 0.0000\n",
            "2025-05-27 21:36:28,953 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5031 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,953 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5031, Edges: 6415, Graphs: 4\n",
            "2025-05-27 21:36:28,953 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5031]) -> torch.Size([5031, 37])\n",
            "2025-05-27 21:36:28,954 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5031, 37]), Edge index shape: torch.Size([2, 6415])\n",
            "2025-05-27 21:36:28,955 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5031, 200])\n",
            "2025-05-27 21:36:28,955 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5031, 37]) -> torch.Size([5031, 200])\n",
            "2025-05-27 21:36:28,955 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5031, 200]), Edge index shape: torch.Size([2, 6415])\n",
            "2025-05-27 21:36:28,956 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5031, 200])\n",
            "2025-05-27 21:36:28,956 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5031, 200]) -> torch.Size([5031, 200])\n",
            "2025-05-27 21:36:28,956 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5031, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,959 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4026, 200]), Nodes kept: 4026/5031 (80.0%)\n",
            "2025-05-27 21:36:28,959 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5031, 200]) -> torch.Size([4026, 200])\n",
            "2025-05-27 21:36:28,959 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4026, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,959 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,959 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4026, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,959 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,959 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,960 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,960 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0010\n",
            "2025-05-27 21:36:28,965 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2436 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,965 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2436, Edges: 2895, Graphs: 4\n",
            "2025-05-27 21:36:28,966 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2436]) -> torch.Size([2436, 37])\n",
            "2025-05-27 21:36:28,966 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2436, 37]), Edge index shape: torch.Size([2, 2895])\n",
            "2025-05-27 21:36:28,967 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2436, 200])\n",
            "2025-05-27 21:36:28,967 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2436, 37]) -> torch.Size([2436, 200])\n",
            "2025-05-27 21:36:28,967 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2436, 200]), Edge index shape: torch.Size([2, 2895])\n",
            "2025-05-27 21:36:28,968 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2436, 200])\n",
            "2025-05-27 21:36:28,968 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2436, 200]) -> torch.Size([2436, 200])\n",
            "2025-05-27 21:36:28,969 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2436, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,971 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1950, 200]), Nodes kept: 1950/2436 (80.0%)\n",
            "2025-05-27 21:36:28,971 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2436, 200]) -> torch.Size([1950, 200])\n",
            "2025-05-27 21:36:28,971 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1950, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,971 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,971 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1950, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,971 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,971 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,972 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,972 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0808\n",
            "2025-05-27 21:36:28,977 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6696 nodes, 4 graphs\n",
            "2025-05-27 21:36:28,977 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6696, Edges: 9060, Graphs: 4\n",
            "2025-05-27 21:36:28,977 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6696]) -> torch.Size([6696, 37])\n",
            "2025-05-27 21:36:28,977 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6696, 37]), Edge index shape: torch.Size([2, 9060])\n",
            "2025-05-27 21:36:28,978 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6696, 200])\n",
            "2025-05-27 21:36:28,979 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6696, 37]) -> torch.Size([6696, 200])\n",
            "2025-05-27 21:36:28,979 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6696, 200]), Edge index shape: torch.Size([2, 9060])\n",
            "2025-05-27 21:36:28,980 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6696, 200])\n",
            "2025-05-27 21:36:28,980 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6696, 200]) -> torch.Size([6696, 200])\n",
            "2025-05-27 21:36:28,980 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6696, 200]), Batch size: 4\n",
            "2025-05-27 21:36:28,983 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5358, 200]), Nodes kept: 5358/6696 (80.0%)\n",
            "2025-05-27 21:36:28,983 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6696, 200]) -> torch.Size([5358, 200])\n",
            "2025-05-27 21:36:28,983 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5358, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:28,984 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,984 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5358, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,984 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,984 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:28,984 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:28,984 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1116\n",
            "2025-05-27 21:36:28,990 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3383 nodes, 2 graphs\n",
            "2025-05-27 21:36:28,991 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3383, Edges: 4569, Graphs: 2\n",
            "2025-05-27 21:36:28,991 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3383]) -> torch.Size([3383, 37])\n",
            "2025-05-27 21:36:28,991 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3383, 37]), Edge index shape: torch.Size([2, 4569])\n",
            "2025-05-27 21:36:28,992 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,992 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3383, 37]) -> torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,992 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3383, 200]), Edge index shape: torch.Size([2, 4569])\n",
            "2025-05-27 21:36:28,993 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,994 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3383, 200]) -> torch.Size([3383, 200])\n",
            "2025-05-27 21:36:28,994 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3383, 200]), Batch size: 2\n",
            "2025-05-27 21:36:28,996 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2707, 200]), Nodes kept: 2707/3383 (80.0%)\n",
            "2025-05-27 21:36:29,011 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3383, 200]) -> torch.Size([2707, 200])\n",
            "2025-05-27 21:36:29,011 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2707, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,011 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,011 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2707, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,011 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,011 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,012 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,012 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0981\n",
            "Epoch: 0190, loss_train: 0.0583, time: 0.1s:  94% 189/200 [00:18<00:00, 12.37it/s]2025-05-27 21:36:29,015 - trainers.GraphTrainer - INFO - train:427 - Epoch 190 completed - Avg loss: 0.0583, Time: 0.1s\n",
            "2025-05-27 21:36:29,015 - trainers.GraphTrainer - INFO - train:427 - Epoch 190 completed - Avg loss: 0.0583, Time: 0.1s\n",
            "2025-05-27 21:36:29,015 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 190...\n",
            "2025-05-27 21:36:29,015 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 190...\n",
            "2025-05-27 21:36:29,015 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,015 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,017 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,017 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8097, Edges: 9948, Graphs: 4\n",
            "2025-05-27 21:36:29,017 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8097]) -> torch.Size([8097, 37])\n",
            "2025-05-27 21:36:29,017 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8097, 37]), Edge index shape: torch.Size([2, 9948])\n",
            "2025-05-27 21:36:29,018 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8097, 200])\n",
            "2025-05-27 21:36:29,018 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8097, 37]) -> torch.Size([8097, 200])\n",
            "2025-05-27 21:36:29,018 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8097, 200]), Edge index shape: torch.Size([2, 9948])\n",
            "2025-05-27 21:36:29,019 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8097, 200])\n",
            "2025-05-27 21:36:29,019 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8097, 200]) -> torch.Size([8097, 200])\n",
            "2025-05-27 21:36:29,020 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8097, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,022 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6478, 200]), Nodes kept: 6478/8097 (80.0%)\n",
            "2025-05-27 21:36:29,022 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8097, 200]) -> torch.Size([6478, 200])\n",
            "2025-05-27 21:36:29,022 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6478, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,022 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,023 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6478, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,023 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,023 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,023 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,023 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0008\n",
            "2025-05-27 21:36:29,024 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:29,025 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,025 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1814, Edges: 2218, Graphs: 4\n",
            "2025-05-27 21:36:29,025 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1814]) -> torch.Size([1814, 37])\n",
            "2025-05-27 21:36:29,025 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1814, 37]), Edge index shape: torch.Size([2, 2218])\n",
            "2025-05-27 21:36:29,026 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1814, 200])\n",
            "2025-05-27 21:36:29,026 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1814, 37]) -> torch.Size([1814, 200])\n",
            "2025-05-27 21:36:29,027 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1814, 200]), Edge index shape: torch.Size([2, 2218])\n",
            "2025-05-27 21:36:29,027 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1814, 200])\n",
            "2025-05-27 21:36:29,028 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1814, 200]) -> torch.Size([1814, 200])\n",
            "2025-05-27 21:36:29,028 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1814, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,029 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1453, 200]), Nodes kept: 1453/1814 (80.1%)\n",
            "2025-05-27 21:36:29,030 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1814, 200]) -> torch.Size([1453, 200])\n",
            "2025-05-27 21:36:29,030 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1453, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,030 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,030 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1453, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,030 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,030 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,031 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,031 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0592\n",
            "2025-05-27 21:36:29,032 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,033 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4296, Edges: 5686, Graphs: 4\n",
            "2025-05-27 21:36:29,033 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4296]) -> torch.Size([4296, 37])\n",
            "2025-05-27 21:36:29,033 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4296, 37]), Edge index shape: torch.Size([2, 5686])\n",
            "2025-05-27 21:36:29,034 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4296, 200])\n",
            "2025-05-27 21:36:29,034 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4296, 37]) -> torch.Size([4296, 200])\n",
            "2025-05-27 21:36:29,034 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4296, 200]), Edge index shape: torch.Size([2, 5686])\n",
            "2025-05-27 21:36:29,035 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4296, 200])\n",
            "2025-05-27 21:36:29,035 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4296, 200]) -> torch.Size([4296, 200])\n",
            "2025-05-27 21:36:29,035 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4296, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,037 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3438, 200]), Nodes kept: 3438/4296 (80.0%)\n",
            "2025-05-27 21:36:29,037 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4296, 200]) -> torch.Size([3438, 200])\n",
            "2025-05-27 21:36:29,037 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3438, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,037 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,038 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3438, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,038 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,038 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,038 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,038 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0158\n",
            "2025-05-27 21:36:29,040 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,040 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4803, Edges: 6230, Graphs: 4\n",
            "2025-05-27 21:36:29,040 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4803]) -> torch.Size([4803, 37])\n",
            "2025-05-27 21:36:29,040 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4803, 37]), Edge index shape: torch.Size([2, 6230])\n",
            "2025-05-27 21:36:29,041 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4803, 200])\n",
            "2025-05-27 21:36:29,041 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4803, 37]) -> torch.Size([4803, 200])\n",
            "2025-05-27 21:36:29,041 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4803, 200]), Edge index shape: torch.Size([2, 6230])\n",
            "2025-05-27 21:36:29,042 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4803, 200])\n",
            "2025-05-27 21:36:29,043 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4803, 200]) -> torch.Size([4803, 200])\n",
            "2025-05-27 21:36:29,043 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4803, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,044 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3844, 200]), Nodes kept: 3844/4803 (80.0%)\n",
            "2025-05-27 21:36:29,045 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4803, 200]) -> torch.Size([3844, 200])\n",
            "2025-05-27 21:36:29,045 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3844, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,045 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,045 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3844, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,045 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,045 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,045 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,046 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.2433\n",
            "2025-05-27 21:36:29,047 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,047 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2703, Edges: 3755, Graphs: 2\n",
            "2025-05-27 21:36:29,048 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2703]) -> torch.Size([2703, 37])\n",
            "2025-05-27 21:36:29,048 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2703, 37]), Edge index shape: torch.Size([2, 3755])\n",
            "2025-05-27 21:36:29,049 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2703, 200])\n",
            "2025-05-27 21:36:29,049 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2703, 37]) -> torch.Size([2703, 200])\n",
            "2025-05-27 21:36:29,049 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2703, 200]), Edge index shape: torch.Size([2, 3755])\n",
            "2025-05-27 21:36:29,050 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2703, 200])\n",
            "2025-05-27 21:36:29,050 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2703, 200]) -> torch.Size([2703, 200])\n",
            "2025-05-27 21:36:29,050 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2703, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,051 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2163, 200]), Nodes kept: 2163/2703 (80.0%)\n",
            "2025-05-27 21:36:29,052 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2703, 200]) -> torch.Size([2163, 200])\n",
            "2025-05-27 21:36:29,052 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2163, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,052 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,052 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2163, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,052 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,052 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,052 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,053 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0052\n",
            "2025-05-27 21:36:29,053 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0649, Predictions: 18\n",
            "2025-05-27 21:36:29,053 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0649, Predictions: 18\n",
            "2025-05-27 21:36:29,054 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,054 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,055 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,055 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2541, Edges: 3576, Graphs: 1\n",
            "2025-05-27 21:36:29,055 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2541]) -> torch.Size([2541, 37])\n",
            "2025-05-27 21:36:29,056 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 37]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:29,057 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,057 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2541, 37]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,057 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 200]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:29,058 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,058 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2541, 200]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,058 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2541, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,060 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2033, 200]), Nodes kept: 2033/2541 (80.0%)\n",
            "2025-05-27 21:36:29,060 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2541, 200]) -> torch.Size([2033, 200])\n",
            "2025-05-27 21:36:29,060 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2033, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,061 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,061 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2033, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,061 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,061 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,061 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,061 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 6.4229\n",
            "2025-05-27 21:36:29,062 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:29,063 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,112 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 717, Edges: 838, Graphs: 1\n",
            "2025-05-27 21:36:29,113 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([717]) -> torch.Size([717, 37])\n",
            "2025-05-27 21:36:29,113 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 37]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:29,116 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,116 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([717, 37]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,117 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 200]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:29,118 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,118 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([717, 200]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,119 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([717, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,121 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([574, 200]), Nodes kept: 574/717 (80.1%)\n",
            "2025-05-27 21:36:29,121 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([717, 200]) -> torch.Size([574, 200])\n",
            "2025-05-27 21:36:29,121 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([574, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,121 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,122 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([574, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,122 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,122 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,122 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,122 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 1.0035\n",
            "2025-05-27 21:36:29,124 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,124 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 782, Edges: 972, Graphs: 1\n",
            "2025-05-27 21:36:29,124 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([782]) -> torch.Size([782, 37])\n",
            "2025-05-27 21:36:29,125 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 37]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:29,126 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,126 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([782, 37]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,126 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 200]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:29,127 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,127 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([782, 200]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,127 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([782, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,129 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([626, 200]), Nodes kept: 626/782 (80.1%)\n",
            "2025-05-27 21:36:29,129 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([782, 200]) -> torch.Size([626, 200])\n",
            "2025-05-27 21:36:29,129 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([626, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,130 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,130 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([626, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,130 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,130 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,130 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,130 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:29,132 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,132 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1830, Edges: 2170, Graphs: 1\n",
            "2025-05-27 21:36:29,133 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1830]) -> torch.Size([1830, 37])\n",
            "2025-05-27 21:36:29,133 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 37]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:29,134 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,134 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1830, 37]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,134 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 200]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:29,135 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,135 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1830, 200]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,135 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1830, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,137 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1464, 200]), Nodes kept: 1464/1830 (80.0%)\n",
            "2025-05-27 21:36:29,137 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1830, 200]) -> torch.Size([1464, 200])\n",
            "2025-05-27 21:36:29,137 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1464, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,138 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,138 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1464, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,138 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,138 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,138 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,138 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 4.6650\n",
            "2025-05-27 21:36:29,140 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,140 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 833, Edges: 1034, Graphs: 1\n",
            "2025-05-27 21:36:29,140 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([833]) -> torch.Size([833, 37])\n",
            "2025-05-27 21:36:29,141 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 37]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:29,141 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,142 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([833, 37]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,142 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 200]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:29,143 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,143 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([833, 200]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,143 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([833, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,145 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([667, 200]), Nodes kept: 667/833 (80.1%)\n",
            "2025-05-27 21:36:29,145 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([833, 200]) -> torch.Size([667, 200])\n",
            "2025-05-27 21:36:29,145 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([667, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,146 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,146 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([667, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,146 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,146 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,146 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,146 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:29,147 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 2.4183, Predictions: 5\n",
            "2025-05-27 21:36:29,147 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 2.4183, Predictions: 5\n",
            "\n",
            "Mini Test for Epochs 190:\n",
            "2025-05-27 21:36:29,147 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for train...\n",
            "train loss: 0.0649, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:29,156 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0649, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:29,156 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0649, train accuracy: 1.0000, train f1 score: 1.0000, train confusion_matrix: [[ 7  0], [ 0 11]], train precision: 1.0000, train recall: 1.0000\n",
            "2025-05-27 21:36:29,156 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for test ...\n",
            "test  loss: 2.4183, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:29,166 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 2.4183, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:29,166 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 2.4183, test  accuracy: 0.4000, test  f1 score: 0.5714, test  confusion_matrix: [[0 2], [1 2]], test  precision: 0.5000, test  recall: 0.6667\n",
            "2025-05-27 21:36:29,166 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.2s\n",
            "2025-05-27 21:36:29,166 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.2s\n",
            "Epoch: 0190, loss_train: 0.0583, time: 0.1s:  96% 191/200 [00:18<00:00,  9.64it/s]2025-05-27 21:36:29,170 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6298 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,170 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6298, Edges: 8685, Graphs: 4\n",
            "2025-05-27 21:36:29,170 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6298]) -> torch.Size([6298, 37])\n",
            "2025-05-27 21:36:29,170 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6298, 37]), Edge index shape: torch.Size([2, 8685])\n",
            "2025-05-27 21:36:29,172 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6298, 200])\n",
            "2025-05-27 21:36:29,172 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6298, 37]) -> torch.Size([6298, 200])\n",
            "2025-05-27 21:36:29,172 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6298, 200]), Edge index shape: torch.Size([2, 8685])\n",
            "2025-05-27 21:36:29,173 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6298, 200])\n",
            "2025-05-27 21:36:29,173 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6298, 200]) -> torch.Size([6298, 200])\n",
            "2025-05-27 21:36:29,174 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6298, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,176 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5040, 200]), Nodes kept: 5040/6298 (80.0%)\n",
            "2025-05-27 21:36:29,176 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6298, 200]) -> torch.Size([5040, 200])\n",
            "2025-05-27 21:36:29,176 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5040, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,177 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,177 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5040, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,177 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,177 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,177 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,177 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:29,182 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 191, Batch 0/5, Loss: 0.0001\n",
            "2025-05-27 21:36:29,184 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3752 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,184 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3752, Edges: 4343, Graphs: 4\n",
            "2025-05-27 21:36:29,184 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3752]) -> torch.Size([3752, 37])\n",
            "2025-05-27 21:36:29,184 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3752, 37]), Edge index shape: torch.Size([2, 4343])\n",
            "2025-05-27 21:36:29,185 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3752, 200])\n",
            "2025-05-27 21:36:29,185 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3752, 37]) -> torch.Size([3752, 200])\n",
            "2025-05-27 21:36:29,185 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3752, 200]), Edge index shape: torch.Size([2, 4343])\n",
            "2025-05-27 21:36:29,186 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3752, 200])\n",
            "2025-05-27 21:36:29,186 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3752, 200]) -> torch.Size([3752, 200])\n",
            "2025-05-27 21:36:29,187 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3752, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,189 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3003, 200]), Nodes kept: 3003/3752 (80.0%)\n",
            "2025-05-27 21:36:29,189 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3752, 200]) -> torch.Size([3003, 200])\n",
            "2025-05-27 21:36:29,189 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3003, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,189 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,190 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3003, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,190 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,190 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,190 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,190 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0598\n",
            "2025-05-27 21:36:29,196 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6802 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,196 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6802, Edges: 9174, Graphs: 4\n",
            "2025-05-27 21:36:29,196 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6802]) -> torch.Size([6802, 37])\n",
            "2025-05-27 21:36:29,196 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6802, 37]), Edge index shape: torch.Size([2, 9174])\n",
            "2025-05-27 21:36:29,214 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6802, 200])\n",
            "2025-05-27 21:36:29,214 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6802, 37]) -> torch.Size([6802, 200])\n",
            "2025-05-27 21:36:29,214 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6802, 200]), Edge index shape: torch.Size([2, 9174])\n",
            "2025-05-27 21:36:29,215 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6802, 200])\n",
            "2025-05-27 21:36:29,215 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6802, 200]) -> torch.Size([6802, 200])\n",
            "2025-05-27 21:36:29,216 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6802, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,218 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5443, 200]), Nodes kept: 5443/6802 (80.0%)\n",
            "2025-05-27 21:36:29,218 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6802, 200]) -> torch.Size([5443, 200])\n",
            "2025-05-27 21:36:29,218 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5443, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,218 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,218 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5443, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,218 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,218 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,219 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,219 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1282\n",
            "2025-05-27 21:36:29,224 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3950 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,225 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3950, Edges: 4514, Graphs: 4\n",
            "2025-05-27 21:36:29,225 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3950]) -> torch.Size([3950, 37])\n",
            "2025-05-27 21:36:29,225 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3950, 37]), Edge index shape: torch.Size([2, 4514])\n",
            "2025-05-27 21:36:29,226 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3950, 200])\n",
            "2025-05-27 21:36:29,226 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3950, 37]) -> torch.Size([3950, 200])\n",
            "2025-05-27 21:36:29,226 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3950, 200]), Edge index shape: torch.Size([2, 4514])\n",
            "2025-05-27 21:36:29,227 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3950, 200])\n",
            "2025-05-27 21:36:29,227 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3950, 200]) -> torch.Size([3950, 200])\n",
            "2025-05-27 21:36:29,228 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3950, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,229 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3161, 200]), Nodes kept: 3161/3950 (80.0%)\n",
            "2025-05-27 21:36:29,229 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3950, 200]) -> torch.Size([3161, 200])\n",
            "2025-05-27 21:36:29,230 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3161, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,230 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,230 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3161, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,230 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,230 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,230 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,231 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0326\n",
            "2025-05-27 21:36:29,235 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 911 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,235 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 911, Edges: 1121, Graphs: 2\n",
            "2025-05-27 21:36:29,235 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([911]) -> torch.Size([911, 37])\n",
            "2025-05-27 21:36:29,235 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([911, 37]), Edge index shape: torch.Size([2, 1121])\n",
            "2025-05-27 21:36:29,236 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([911, 200])\n",
            "2025-05-27 21:36:29,236 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([911, 37]) -> torch.Size([911, 200])\n",
            "2025-05-27 21:36:29,237 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([911, 200]), Edge index shape: torch.Size([2, 1121])\n",
            "2025-05-27 21:36:29,237 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([911, 200])\n",
            "2025-05-27 21:36:29,238 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([911, 200]) -> torch.Size([911, 200])\n",
            "2025-05-27 21:36:29,238 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([911, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,240 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([729, 200]), Nodes kept: 729/911 (80.0%)\n",
            "2025-05-27 21:36:29,240 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([911, 200]) -> torch.Size([729, 200])\n",
            "2025-05-27 21:36:29,240 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([729, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,240 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,240 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([729, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,241 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,241 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,241 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,241 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0191, loss_train: 0.0441, time: 0.1s:  96% 191/200 [00:18<00:00,  9.64it/s]2025-05-27 21:36:29,244 - trainers.GraphTrainer - INFO - train:427 - Epoch 191 completed - Avg loss: 0.0441, Time: 0.1s\n",
            "2025-05-27 21:36:29,244 - trainers.GraphTrainer - INFO - train:427 - Epoch 191 completed - Avg loss: 0.0441, Time: 0.1s\n",
            "2025-05-27 21:36:29,246 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 8347 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,246 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 8347, Edges: 10885, Graphs: 4\n",
            "2025-05-27 21:36:29,246 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([8347]) -> torch.Size([8347, 37])\n",
            "2025-05-27 21:36:29,247 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8347, 37]), Edge index shape: torch.Size([2, 10885])\n",
            "2025-05-27 21:36:29,247 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8347, 200])\n",
            "2025-05-27 21:36:29,248 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([8347, 37]) -> torch.Size([8347, 200])\n",
            "2025-05-27 21:36:29,248 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([8347, 200]), Edge index shape: torch.Size([2, 10885])\n",
            "2025-05-27 21:36:29,249 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([8347, 200])\n",
            "2025-05-27 21:36:29,249 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([8347, 200]) -> torch.Size([8347, 200])\n",
            "2025-05-27 21:36:29,250 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([8347, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,252 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([6679, 200]), Nodes kept: 6679/8347 (80.0%)\n",
            "2025-05-27 21:36:29,252 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([8347, 200]) -> torch.Size([6679, 200])\n",
            "2025-05-27 21:36:29,252 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([6679, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,252 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,252 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([6679, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,252 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,252 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,253 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,253 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0153\n",
            "2025-05-27 21:36:29,257 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 192, Batch 0/5, Loss: 0.0153\n",
            "2025-05-27 21:36:29,259 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3618 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,259 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3618, Edges: 4878, Graphs: 4\n",
            "2025-05-27 21:36:29,259 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3618]) -> torch.Size([3618, 37])\n",
            "2025-05-27 21:36:29,260 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3618, 37]), Edge index shape: torch.Size([2, 4878])\n",
            "2025-05-27 21:36:29,260 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3618, 200])\n",
            "2025-05-27 21:36:29,261 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3618, 37]) -> torch.Size([3618, 200])\n",
            "2025-05-27 21:36:29,261 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3618, 200]), Edge index shape: torch.Size([2, 4878])\n",
            "2025-05-27 21:36:29,262 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3618, 200])\n",
            "2025-05-27 21:36:29,262 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3618, 200]) -> torch.Size([3618, 200])\n",
            "2025-05-27 21:36:29,262 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3618, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,264 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2895, 200]), Nodes kept: 2895/3618 (80.0%)\n",
            "2025-05-27 21:36:29,264 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3618, 200]) -> torch.Size([2895, 200])\n",
            "2025-05-27 21:36:29,264 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2895, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,264 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,264 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2895, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,264 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,264 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,265 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,265 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0008\n",
            "2025-05-27 21:36:29,269 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4655 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,269 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4655, Edges: 5490, Graphs: 4\n",
            "2025-05-27 21:36:29,270 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4655]) -> torch.Size([4655, 37])\n",
            "2025-05-27 21:36:29,270 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4655, 37]), Edge index shape: torch.Size([2, 5490])\n",
            "2025-05-27 21:36:29,271 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4655, 200])\n",
            "2025-05-27 21:36:29,271 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4655, 37]) -> torch.Size([4655, 200])\n",
            "2025-05-27 21:36:29,271 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4655, 200]), Edge index shape: torch.Size([2, 5490])\n",
            "2025-05-27 21:36:29,272 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4655, 200])\n",
            "2025-05-27 21:36:29,272 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4655, 200]) -> torch.Size([4655, 200])\n",
            "2025-05-27 21:36:29,272 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4655, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,274 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3725, 200]), Nodes kept: 3725/4655 (80.0%)\n",
            "2025-05-27 21:36:29,274 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4655, 200]) -> torch.Size([3725, 200])\n",
            "2025-05-27 21:36:29,274 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3725, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,275 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,275 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3725, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,275 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,275 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,275 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,275 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:29,280 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3559 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,280 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3559, Edges: 4796, Graphs: 4\n",
            "2025-05-27 21:36:29,280 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3559]) -> torch.Size([3559, 37])\n",
            "2025-05-27 21:36:29,280 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3559, 37]), Edge index shape: torch.Size([2, 4796])\n",
            "2025-05-27 21:36:29,281 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,281 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3559, 37]) -> torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,282 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3559, 200]), Edge index shape: torch.Size([2, 4796])\n",
            "2025-05-27 21:36:29,282 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,283 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3559, 200]) -> torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,283 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3559, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,284 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2849, 200]), Nodes kept: 2849/3559 (80.1%)\n",
            "2025-05-27 21:36:29,285 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3559, 200]) -> torch.Size([2849, 200])\n",
            "2025-05-27 21:36:29,285 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2849, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,285 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,285 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2849, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,285 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,285 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,285 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,286 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0915\n",
            "2025-05-27 21:36:29,290 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1534 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,290 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1534, Edges: 1788, Graphs: 2\n",
            "2025-05-27 21:36:29,314 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1534]) -> torch.Size([1534, 37])\n",
            "2025-05-27 21:36:29,314 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1534, 37]), Edge index shape: torch.Size([2, 1788])\n",
            "2025-05-27 21:36:29,315 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1534, 200])\n",
            "2025-05-27 21:36:29,316 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1534, 37]) -> torch.Size([1534, 200])\n",
            "2025-05-27 21:36:29,316 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1534, 200]), Edge index shape: torch.Size([2, 1788])\n",
            "2025-05-27 21:36:29,317 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1534, 200])\n",
            "2025-05-27 21:36:29,317 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1534, 200]) -> torch.Size([1534, 200])\n",
            "2025-05-27 21:36:29,318 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1534, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,321 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1228, 200]), Nodes kept: 1228/1534 (80.1%)\n",
            "2025-05-27 21:36:29,321 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1534, 200]) -> torch.Size([1228, 200])\n",
            "2025-05-27 21:36:29,321 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1228, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,321 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,321 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1228, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,321 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,322 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,322 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,322 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1688\n",
            "Epoch: 0192, loss_train: 0.0553, time: 0.1s:  96% 191/200 [00:18<00:00,  9.64it/s]2025-05-27 21:36:29,326 - trainers.GraphTrainer - INFO - train:427 - Epoch 192 completed - Avg loss: 0.0553, Time: 0.1s\n",
            "2025-05-27 21:36:29,326 - trainers.GraphTrainer - INFO - train:427 - Epoch 192 completed - Avg loss: 0.0553, Time: 0.1s\n",
            "Epoch: 0192, loss_train: 0.0553, time: 0.1s:  96% 193/200 [00:18<00:00, 10.37it/s]2025-05-27 21:36:29,328 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4041 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,329 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4041, Edges: 4648, Graphs: 4\n",
            "2025-05-27 21:36:29,329 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4041]) -> torch.Size([4041, 37])\n",
            "2025-05-27 21:36:29,329 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4041, 37]), Edge index shape: torch.Size([2, 4648])\n",
            "2025-05-27 21:36:29,330 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4041, 200])\n",
            "2025-05-27 21:36:29,330 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4041, 37]) -> torch.Size([4041, 200])\n",
            "2025-05-27 21:36:29,330 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4041, 200]), Edge index shape: torch.Size([2, 4648])\n",
            "2025-05-27 21:36:29,331 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4041, 200])\n",
            "2025-05-27 21:36:29,332 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4041, 200]) -> torch.Size([4041, 200])\n",
            "2025-05-27 21:36:29,332 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4041, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,334 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3235, 200]), Nodes kept: 3235/4041 (80.1%)\n",
            "2025-05-27 21:36:29,334 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4041, 200]) -> torch.Size([3235, 200])\n",
            "2025-05-27 21:36:29,334 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3235, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,334 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,335 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3235, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,335 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,335 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,335 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,335 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0897\n",
            "2025-05-27 21:36:29,339 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 193, Batch 0/5, Loss: 0.0897\n",
            "2025-05-27 21:36:29,341 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4003 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,341 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4003, Edges: 4703, Graphs: 4\n",
            "2025-05-27 21:36:29,342 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4003]) -> torch.Size([4003, 37])\n",
            "2025-05-27 21:36:29,342 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4003, 37]), Edge index shape: torch.Size([2, 4703])\n",
            "2025-05-27 21:36:29,343 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4003, 200])\n",
            "2025-05-27 21:36:29,343 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4003, 37]) -> torch.Size([4003, 200])\n",
            "2025-05-27 21:36:29,343 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4003, 200]), Edge index shape: torch.Size([2, 4703])\n",
            "2025-05-27 21:36:29,344 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4003, 200])\n",
            "2025-05-27 21:36:29,344 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4003, 200]) -> torch.Size([4003, 200])\n",
            "2025-05-27 21:36:29,345 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4003, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,347 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3203, 200]), Nodes kept: 3203/4003 (80.0%)\n",
            "2025-05-27 21:36:29,347 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4003, 200]) -> torch.Size([3203, 200])\n",
            "2025-05-27 21:36:29,347 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3203, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,347 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,347 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3203, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,347 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,347 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,348 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,348 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0021\n",
            "2025-05-27 21:36:29,353 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4232 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,353 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4232, Edges: 5557, Graphs: 4\n",
            "2025-05-27 21:36:29,353 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4232]) -> torch.Size([4232, 37])\n",
            "2025-05-27 21:36:29,353 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4232, 37]), Edge index shape: torch.Size([2, 5557])\n",
            "2025-05-27 21:36:29,354 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4232, 200])\n",
            "2025-05-27 21:36:29,355 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4232, 37]) -> torch.Size([4232, 200])\n",
            "2025-05-27 21:36:29,355 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4232, 200]), Edge index shape: torch.Size([2, 5557])\n",
            "2025-05-27 21:36:29,356 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4232, 200])\n",
            "2025-05-27 21:36:29,356 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4232, 200]) -> torch.Size([4232, 200])\n",
            "2025-05-27 21:36:29,356 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4232, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,358 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3386, 200]), Nodes kept: 3386/4232 (80.0%)\n",
            "2025-05-27 21:36:29,358 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4232, 200]) -> torch.Size([3386, 200])\n",
            "2025-05-27 21:36:29,358 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3386, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,359 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,359 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3386, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,359 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,359 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,359 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,359 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:29,364 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5968 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,365 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5968, Edges: 8201, Graphs: 4\n",
            "2025-05-27 21:36:29,365 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5968]) -> torch.Size([5968, 37])\n",
            "2025-05-27 21:36:29,365 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5968, 37]), Edge index shape: torch.Size([2, 8201])\n",
            "2025-05-27 21:36:29,366 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5968, 200])\n",
            "2025-05-27 21:36:29,366 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5968, 37]) -> torch.Size([5968, 200])\n",
            "2025-05-27 21:36:29,366 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5968, 200]), Edge index shape: torch.Size([2, 8201])\n",
            "2025-05-27 21:36:29,367 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5968, 200])\n",
            "2025-05-27 21:36:29,367 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5968, 200]) -> torch.Size([5968, 200])\n",
            "2025-05-27 21:36:29,368 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5968, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,370 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4776, 200]), Nodes kept: 4776/5968 (80.0%)\n",
            "2025-05-27 21:36:29,370 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5968, 200]) -> torch.Size([4776, 200])\n",
            "2025-05-27 21:36:29,370 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4776, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,370 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,371 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4776, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,371 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,371 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,371 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,371 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2212\n",
            "2025-05-27 21:36:29,377 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3469 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,377 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3469, Edges: 4728, Graphs: 2\n",
            "2025-05-27 21:36:29,377 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3469]) -> torch.Size([3469, 37])\n",
            "2025-05-27 21:36:29,377 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3469, 37]), Edge index shape: torch.Size([2, 4728])\n",
            "2025-05-27 21:36:29,378 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,378 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3469, 37]) -> torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,378 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3469, 200]), Edge index shape: torch.Size([2, 4728])\n",
            "2025-05-27 21:36:29,379 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,380 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3469, 200]) -> torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,380 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3469, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,382 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2776, 200]), Nodes kept: 2776/3469 (80.0%)\n",
            "2025-05-27 21:36:29,382 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3469, 200]) -> torch.Size([2776, 200])\n",
            "2025-05-27 21:36:29,382 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2776, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,382 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,382 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2776, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,382 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,382 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,383 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,383 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0193, loss_train: 0.0626, time: 0.1s:  96% 193/200 [00:18<00:00, 10.37it/s]2025-05-27 21:36:29,386 - trainers.GraphTrainer - INFO - train:427 - Epoch 193 completed - Avg loss: 0.0626, Time: 0.1s\n",
            "2025-05-27 21:36:29,386 - trainers.GraphTrainer - INFO - train:427 - Epoch 193 completed - Avg loss: 0.0626, Time: 0.1s\n",
            "2025-05-27 21:36:29,388 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5951 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,388 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5951, Edges: 7507, Graphs: 4\n",
            "2025-05-27 21:36:29,389 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5951]) -> torch.Size([5951, 37])\n",
            "2025-05-27 21:36:29,389 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5951, 37]), Edge index shape: torch.Size([2, 7507])\n",
            "2025-05-27 21:36:29,390 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5951, 200])\n",
            "2025-05-27 21:36:29,390 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5951, 37]) -> torch.Size([5951, 200])\n",
            "2025-05-27 21:36:29,390 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5951, 200]), Edge index shape: torch.Size([2, 7507])\n",
            "2025-05-27 21:36:29,392 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5951, 200])\n",
            "2025-05-27 21:36:29,392 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5951, 200]) -> torch.Size([5951, 200])\n",
            "2025-05-27 21:36:29,393 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5951, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,395 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4762, 200]), Nodes kept: 4762/5951 (80.0%)\n",
            "2025-05-27 21:36:29,395 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5951, 200]) -> torch.Size([4762, 200])\n",
            "2025-05-27 21:36:29,414 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4762, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,414 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,415 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4762, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,415 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,415 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,415 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,415 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0013\n",
            "2025-05-27 21:36:29,420 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 194, Batch 0/5, Loss: 0.0013\n",
            "2025-05-27 21:36:29,421 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4298 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,421 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4298, Edges: 5704, Graphs: 4\n",
            "2025-05-27 21:36:29,422 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4298]) -> torch.Size([4298, 37])\n",
            "2025-05-27 21:36:29,422 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4298, 37]), Edge index shape: torch.Size([2, 5704])\n",
            "2025-05-27 21:36:29,423 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4298, 200])\n",
            "2025-05-27 21:36:29,423 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4298, 37]) -> torch.Size([4298, 200])\n",
            "2025-05-27 21:36:29,423 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4298, 200]), Edge index shape: torch.Size([2, 5704])\n",
            "2025-05-27 21:36:29,424 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4298, 200])\n",
            "2025-05-27 21:36:29,424 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4298, 200]) -> torch.Size([4298, 200])\n",
            "2025-05-27 21:36:29,424 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4298, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,426 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3440, 200]), Nodes kept: 3440/4298 (80.0%)\n",
            "2025-05-27 21:36:29,426 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4298, 200]) -> torch.Size([3440, 200])\n",
            "2025-05-27 21:36:29,426 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3440, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,427 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,427 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3440, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,427 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,427 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,427 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,427 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0303\n",
            "2025-05-27 21:36:29,432 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3093 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,432 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3093, Edges: 3675, Graphs: 4\n",
            "2025-05-27 21:36:29,432 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3093]) -> torch.Size([3093, 37])\n",
            "2025-05-27 21:36:29,432 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3093, 37]), Edge index shape: torch.Size([2, 3675])\n",
            "2025-05-27 21:36:29,433 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3093, 200])\n",
            "2025-05-27 21:36:29,433 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3093, 37]) -> torch.Size([3093, 200])\n",
            "2025-05-27 21:36:29,433 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3093, 200]), Edge index shape: torch.Size([2, 3675])\n",
            "2025-05-27 21:36:29,434 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3093, 200])\n",
            "2025-05-27 21:36:29,435 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3093, 200]) -> torch.Size([3093, 200])\n",
            "2025-05-27 21:36:29,435 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3093, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,436 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2475, 200]), Nodes kept: 2475/3093 (80.0%)\n",
            "2025-05-27 21:36:29,437 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3093, 200]) -> torch.Size([2475, 200])\n",
            "2025-05-27 21:36:29,437 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2475, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,437 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,437 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2475, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,437 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,437 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,437 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,438 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.3546\n",
            "2025-05-27 21:36:29,442 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3559 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,442 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3559, Edges: 4796, Graphs: 4\n",
            "2025-05-27 21:36:29,442 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3559]) -> torch.Size([3559, 37])\n",
            "2025-05-27 21:36:29,442 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3559, 37]), Edge index shape: torch.Size([2, 4796])\n",
            "2025-05-27 21:36:29,443 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,443 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3559, 37]) -> torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,443 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3559, 200]), Edge index shape: torch.Size([2, 4796])\n",
            "2025-05-27 21:36:29,444 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,444 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3559, 200]) -> torch.Size([3559, 200])\n",
            "2025-05-27 21:36:29,445 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3559, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,446 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2849, 200]), Nodes kept: 2849/3559 (80.1%)\n",
            "2025-05-27 21:36:29,446 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3559, 200]) -> torch.Size([2849, 200])\n",
            "2025-05-27 21:36:29,447 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2849, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,447 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,447 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2849, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,447 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,447 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,447 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,448 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0037\n",
            "2025-05-27 21:36:29,452 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4812 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,452 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4812, Edges: 6155, Graphs: 2\n",
            "2025-05-27 21:36:29,452 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4812]) -> torch.Size([4812, 37])\n",
            "2025-05-27 21:36:29,452 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4812, 37]), Edge index shape: torch.Size([2, 6155])\n",
            "2025-05-27 21:36:29,453 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4812, 200])\n",
            "2025-05-27 21:36:29,453 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4812, 37]) -> torch.Size([4812, 200])\n",
            "2025-05-27 21:36:29,453 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4812, 200]), Edge index shape: torch.Size([2, 6155])\n",
            "2025-05-27 21:36:29,454 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4812, 200])\n",
            "2025-05-27 21:36:29,454 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4812, 200]) -> torch.Size([4812, 200])\n",
            "2025-05-27 21:36:29,455 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4812, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,456 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3850, 200]), Nodes kept: 3850/4812 (80.0%)\n",
            "2025-05-27 21:36:29,457 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4812, 200]) -> torch.Size([3850, 200])\n",
            "2025-05-27 21:36:29,457 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3850, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,457 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,457 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3850, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,457 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,457 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,457 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,458 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0194, loss_train: 0.0780, time: 0.1s:  96% 193/200 [00:18<00:00, 10.37it/s]2025-05-27 21:36:29,461 - trainers.GraphTrainer - INFO - train:427 - Epoch 194 completed - Avg loss: 0.0780, Time: 0.1s\n",
            "2025-05-27 21:36:29,461 - trainers.GraphTrainer - INFO - train:427 - Epoch 194 completed - Avg loss: 0.0780, Time: 0.1s\n",
            "Epoch: 0194, loss_train: 0.0780, time: 0.1s:  98% 195/200 [00:18<00:00, 11.39it/s]2025-05-27 21:36:29,463 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5146 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,463 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5146, Edges: 6756, Graphs: 4\n",
            "2025-05-27 21:36:29,463 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5146]) -> torch.Size([5146, 37])\n",
            "2025-05-27 21:36:29,463 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5146, 37]), Edge index shape: torch.Size([2, 6756])\n",
            "2025-05-27 21:36:29,464 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5146, 200])\n",
            "2025-05-27 21:36:29,464 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5146, 37]) -> torch.Size([5146, 200])\n",
            "2025-05-27 21:36:29,465 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5146, 200]), Edge index shape: torch.Size([2, 6756])\n",
            "2025-05-27 21:36:29,465 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5146, 200])\n",
            "2025-05-27 21:36:29,466 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5146, 200]) -> torch.Size([5146, 200])\n",
            "2025-05-27 21:36:29,466 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5146, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,468 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4118, 200]), Nodes kept: 4118/5146 (80.0%)\n",
            "2025-05-27 21:36:29,468 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5146, 200]) -> torch.Size([4118, 200])\n",
            "2025-05-27 21:36:29,468 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4118, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,468 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,468 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4118, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,468 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,469 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,469 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,469 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0002\n",
            "2025-05-27 21:36:29,472 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 195, Batch 0/5, Loss: 0.0002\n",
            "2025-05-27 21:36:29,474 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3469 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,474 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3469, Edges: 4663, Graphs: 4\n",
            "2025-05-27 21:36:29,474 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3469]) -> torch.Size([3469, 37])\n",
            "2025-05-27 21:36:29,474 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3469, 37]), Edge index shape: torch.Size([2, 4663])\n",
            "2025-05-27 21:36:29,475 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,475 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3469, 37]) -> torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,475 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3469, 200]), Edge index shape: torch.Size([2, 4663])\n",
            "2025-05-27 21:36:29,476 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,476 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3469, 200]) -> torch.Size([3469, 200])\n",
            "2025-05-27 21:36:29,477 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3469, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,478 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2776, 200]), Nodes kept: 2776/3469 (80.0%)\n",
            "2025-05-27 21:36:29,478 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3469, 200]) -> torch.Size([2776, 200])\n",
            "2025-05-27 21:36:29,479 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2776, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,479 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,479 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2776, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,479 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,479 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,479 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,480 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0005\n",
            "2025-05-27 21:36:29,484 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4688 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,484 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4688, Edges: 5436, Graphs: 4\n",
            "2025-05-27 21:36:29,484 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4688]) -> torch.Size([4688, 37])\n",
            "2025-05-27 21:36:29,484 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4688, 37]), Edge index shape: torch.Size([2, 5436])\n",
            "2025-05-27 21:36:29,485 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4688, 200])\n",
            "2025-05-27 21:36:29,514 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4688, 37]) -> torch.Size([4688, 200])\n",
            "2025-05-27 21:36:29,515 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4688, 200]), Edge index shape: torch.Size([2, 5436])\n",
            "2025-05-27 21:36:29,516 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4688, 200])\n",
            "2025-05-27 21:36:29,516 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4688, 200]) -> torch.Size([4688, 200])\n",
            "2025-05-27 21:36:29,516 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4688, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,518 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3752, 200]), Nodes kept: 3752/4688 (80.0%)\n",
            "2025-05-27 21:36:29,518 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4688, 200]) -> torch.Size([3752, 200])\n",
            "2025-05-27 21:36:29,518 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3752, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,519 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,519 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3752, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,519 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,519 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,519 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,520 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1770\n",
            "2025-05-27 21:36:29,525 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3594 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,526 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3594, Edges: 4825, Graphs: 4\n",
            "2025-05-27 21:36:29,526 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3594]) -> torch.Size([3594, 37])\n",
            "2025-05-27 21:36:29,526 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3594, 37]), Edge index shape: torch.Size([2, 4825])\n",
            "2025-05-27 21:36:29,528 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3594, 200])\n",
            "2025-05-27 21:36:29,528 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3594, 37]) -> torch.Size([3594, 200])\n",
            "2025-05-27 21:36:29,528 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3594, 200]), Edge index shape: torch.Size([2, 4825])\n",
            "2025-05-27 21:36:29,529 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3594, 200])\n",
            "2025-05-27 21:36:29,530 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3594, 200]) -> torch.Size([3594, 200])\n",
            "2025-05-27 21:36:29,530 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3594, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,532 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2877, 200]), Nodes kept: 2877/3594 (80.1%)\n",
            "2025-05-27 21:36:29,532 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3594, 200]) -> torch.Size([2877, 200])\n",
            "2025-05-27 21:36:29,532 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2877, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,533 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,533 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2877, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,533 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,533 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,533 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,534 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0179\n",
            "2025-05-27 21:36:29,539 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4816 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,539 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4816, Edges: 6157, Graphs: 2\n",
            "2025-05-27 21:36:29,539 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4816]) -> torch.Size([4816, 37])\n",
            "2025-05-27 21:36:29,539 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4816, 37]), Edge index shape: torch.Size([2, 6157])\n",
            "2025-05-27 21:36:29,540 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4816, 200])\n",
            "2025-05-27 21:36:29,542 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4816, 37]) -> torch.Size([4816, 200])\n",
            "2025-05-27 21:36:29,542 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4816, 200]), Edge index shape: torch.Size([2, 6157])\n",
            "2025-05-27 21:36:29,543 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4816, 200])\n",
            "2025-05-27 21:36:29,543 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4816, 200]) -> torch.Size([4816, 200])\n",
            "2025-05-27 21:36:29,543 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4816, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,545 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3853, 200]), Nodes kept: 3853/4816 (80.0%)\n",
            "2025-05-27 21:36:29,545 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4816, 200]) -> torch.Size([3853, 200])\n",
            "2025-05-27 21:36:29,545 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3853, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,546 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,546 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3853, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,546 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,546 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,546 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,546 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "Epoch: 0195, loss_train: 0.0391, time: 0.1s:  98% 195/200 [00:18<00:00, 11.39it/s]2025-05-27 21:36:29,550 - trainers.GraphTrainer - INFO - train:427 - Epoch 195 completed - Avg loss: 0.0391, Time: 0.1s\n",
            "2025-05-27 21:36:29,550 - trainers.GraphTrainer - INFO - train:427 - Epoch 195 completed - Avg loss: 0.0391, Time: 0.1s\n",
            "2025-05-27 21:36:29,552 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4479 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,552 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4479, Edges: 5996, Graphs: 4\n",
            "2025-05-27 21:36:29,553 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4479]) -> torch.Size([4479, 37])\n",
            "2025-05-27 21:36:29,553 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4479, 37]), Edge index shape: torch.Size([2, 5996])\n",
            "2025-05-27 21:36:29,554 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4479, 200])\n",
            "2025-05-27 21:36:29,554 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4479, 37]) -> torch.Size([4479, 200])\n",
            "2025-05-27 21:36:29,554 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4479, 200]), Edge index shape: torch.Size([2, 5996])\n",
            "2025-05-27 21:36:29,555 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4479, 200])\n",
            "2025-05-27 21:36:29,556 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4479, 200]) -> torch.Size([4479, 200])\n",
            "2025-05-27 21:36:29,556 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4479, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,558 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3585, 200]), Nodes kept: 3585/4479 (80.0%)\n",
            "2025-05-27 21:36:29,558 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4479, 200]) -> torch.Size([3585, 200])\n",
            "2025-05-27 21:36:29,558 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3585, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,558 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,559 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3585, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,559 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,559 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,559 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,559 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0001\n",
            "2025-05-27 21:36:29,563 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 196, Batch 0/5, Loss: 0.0001\n",
            "2025-05-27 21:36:29,564 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4170 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,565 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4170, Edges: 5466, Graphs: 4\n",
            "2025-05-27 21:36:29,565 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4170]) -> torch.Size([4170, 37])\n",
            "2025-05-27 21:36:29,565 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4170, 37]), Edge index shape: torch.Size([2, 5466])\n",
            "2025-05-27 21:36:29,566 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4170, 200])\n",
            "2025-05-27 21:36:29,566 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4170, 37]) -> torch.Size([4170, 200])\n",
            "2025-05-27 21:36:29,566 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4170, 200]), Edge index shape: torch.Size([2, 5466])\n",
            "2025-05-27 21:36:29,568 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4170, 200])\n",
            "2025-05-27 21:36:29,568 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4170, 200]) -> torch.Size([4170, 200])\n",
            "2025-05-27 21:36:29,568 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4170, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,570 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3337, 200]), Nodes kept: 3337/4170 (80.0%)\n",
            "2025-05-27 21:36:29,570 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4170, 200]) -> torch.Size([3337, 200])\n",
            "2025-05-27 21:36:29,571 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3337, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,571 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,571 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3337, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,571 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,571 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,571 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,572 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0367\n",
            "2025-05-27 21:36:29,577 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5839 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,577 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5839, Edges: 7333, Graphs: 4\n",
            "2025-05-27 21:36:29,577 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5839]) -> torch.Size([5839, 37])\n",
            "2025-05-27 21:36:29,577 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5839, 37]), Edge index shape: torch.Size([2, 7333])\n",
            "2025-05-27 21:36:29,578 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5839, 200])\n",
            "2025-05-27 21:36:29,578 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5839, 37]) -> torch.Size([5839, 200])\n",
            "2025-05-27 21:36:29,579 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5839, 200]), Edge index shape: torch.Size([2, 7333])\n",
            "2025-05-27 21:36:29,580 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5839, 200])\n",
            "2025-05-27 21:36:29,580 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5839, 200]) -> torch.Size([5839, 200])\n",
            "2025-05-27 21:36:29,580 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5839, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,582 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4672, 200]), Nodes kept: 4672/5839 (80.0%)\n",
            "2025-05-27 21:36:29,582 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5839, 200]) -> torch.Size([4672, 200])\n",
            "2025-05-27 21:36:29,582 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4672, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,583 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,583 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4672, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,583 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,583 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,583 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,584 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0005\n",
            "2025-05-27 21:36:29,589 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4306 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,589 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4306, Edges: 5717, Graphs: 4\n",
            "2025-05-27 21:36:29,589 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4306]) -> torch.Size([4306, 37])\n",
            "2025-05-27 21:36:29,590 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4306, 37]), Edge index shape: torch.Size([2, 5717])\n",
            "2025-05-27 21:36:29,590 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4306, 200])\n",
            "2025-05-27 21:36:29,591 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4306, 37]) -> torch.Size([4306, 200])\n",
            "2025-05-27 21:36:29,591 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4306, 200]), Edge index shape: torch.Size([2, 5717])\n",
            "2025-05-27 21:36:29,592 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4306, 200])\n",
            "2025-05-27 21:36:29,592 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4306, 200]) -> torch.Size([4306, 200])\n",
            "2025-05-27 21:36:29,592 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4306, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,594 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3446, 200]), Nodes kept: 3446/4306 (80.0%)\n",
            "2025-05-27 21:36:29,594 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4306, 200]) -> torch.Size([3446, 200])\n",
            "2025-05-27 21:36:29,594 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3446, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,595 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,595 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3446, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,595 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,595 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,595 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,595 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0199\n",
            "2025-05-27 21:36:29,600 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 2919 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,601 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2919, Edges: 3325, Graphs: 2\n",
            "2025-05-27 21:36:29,615 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2919]) -> torch.Size([2919, 37])\n",
            "2025-05-27 21:36:29,615 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2919, 37]), Edge index shape: torch.Size([2, 3325])\n",
            "2025-05-27 21:36:29,616 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2919, 200])\n",
            "2025-05-27 21:36:29,617 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2919, 37]) -> torch.Size([2919, 200])\n",
            "2025-05-27 21:36:29,617 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2919, 200]), Edge index shape: torch.Size([2, 3325])\n",
            "2025-05-27 21:36:29,618 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2919, 200])\n",
            "2025-05-27 21:36:29,618 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2919, 200]) -> torch.Size([2919, 200])\n",
            "2025-05-27 21:36:29,618 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2919, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,620 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2336, 200]), Nodes kept: 2336/2919 (80.0%)\n",
            "2025-05-27 21:36:29,620 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2919, 200]) -> torch.Size([2336, 200])\n",
            "2025-05-27 21:36:29,620 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2336, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,620 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,620 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2336, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,620 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,620 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,621 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,621 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.3852\n",
            "Epoch: 0196, loss_train: 0.0885, time: 0.1s:  98% 195/200 [00:18<00:00, 11.39it/s]2025-05-27 21:36:29,624 - trainers.GraphTrainer - INFO - train:427 - Epoch 196 completed - Avg loss: 0.0885, Time: 0.1s\n",
            "2025-05-27 21:36:29,624 - trainers.GraphTrainer - INFO - train:427 - Epoch 196 completed - Avg loss: 0.0885, Time: 0.1s\n",
            "Epoch: 0196, loss_train: 0.0885, time: 0.1s:  98% 197/200 [00:18<00:00, 11.65it/s]2025-05-27 21:36:29,626 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4310 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,626 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4310, Edges: 5719, Graphs: 4\n",
            "2025-05-27 21:36:29,626 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4310]) -> torch.Size([4310, 37])\n",
            "2025-05-27 21:36:29,626 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4310, 37]), Edge index shape: torch.Size([2, 5719])\n",
            "2025-05-27 21:36:29,627 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4310, 200])\n",
            "2025-05-27 21:36:29,627 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4310, 37]) -> torch.Size([4310, 200])\n",
            "2025-05-27 21:36:29,627 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4310, 200]), Edge index shape: torch.Size([2, 5719])\n",
            "2025-05-27 21:36:29,628 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4310, 200])\n",
            "2025-05-27 21:36:29,628 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4310, 200]) -> torch.Size([4310, 200])\n",
            "2025-05-27 21:36:29,629 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4310, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,630 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3449, 200]), Nodes kept: 3449/4310 (80.0%)\n",
            "2025-05-27 21:36:29,631 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4310, 200]) -> torch.Size([3449, 200])\n",
            "2025-05-27 21:36:29,631 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3449, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,631 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,631 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3449, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,631 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,631 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,631 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,632 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0006\n",
            "2025-05-27 21:36:29,635 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 197, Batch 0/5, Loss: 0.0006\n",
            "2025-05-27 21:36:29,636 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5913 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,637 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5913, Edges: 7399, Graphs: 4\n",
            "2025-05-27 21:36:29,637 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5913]) -> torch.Size([5913, 37])\n",
            "2025-05-27 21:36:29,637 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5913, 37]), Edge index shape: torch.Size([2, 7399])\n",
            "2025-05-27 21:36:29,638 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5913, 200])\n",
            "2025-05-27 21:36:29,638 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5913, 37]) -> torch.Size([5913, 200])\n",
            "2025-05-27 21:36:29,638 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5913, 200]), Edge index shape: torch.Size([2, 7399])\n",
            "2025-05-27 21:36:29,639 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5913, 200])\n",
            "2025-05-27 21:36:29,639 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5913, 200]) -> torch.Size([5913, 200])\n",
            "2025-05-27 21:36:29,640 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5913, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,641 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4731, 200]), Nodes kept: 4731/5913 (80.0%)\n",
            "2025-05-27 21:36:29,641 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5913, 200]) -> torch.Size([4731, 200])\n",
            "2025-05-27 21:36:29,642 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4731, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,642 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,642 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4731, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,642 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,642 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,642 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,643 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0009\n",
            "2025-05-27 21:36:29,648 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 5686 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,648 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5686, Edges: 7235, Graphs: 4\n",
            "2025-05-27 21:36:29,648 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5686]) -> torch.Size([5686, 37])\n",
            "2025-05-27 21:36:29,648 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5686, 37]), Edge index shape: torch.Size([2, 7235])\n",
            "2025-05-27 21:36:29,649 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5686, 200])\n",
            "2025-05-27 21:36:29,649 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5686, 37]) -> torch.Size([5686, 200])\n",
            "2025-05-27 21:36:29,649 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5686, 200]), Edge index shape: torch.Size([2, 7235])\n",
            "2025-05-27 21:36:29,650 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5686, 200])\n",
            "2025-05-27 21:36:29,650 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5686, 200]) -> torch.Size([5686, 200])\n",
            "2025-05-27 21:36:29,651 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5686, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,653 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4550, 200]), Nodes kept: 4550/5686 (80.0%)\n",
            "2025-05-27 21:36:29,653 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5686, 200]) -> torch.Size([4550, 200])\n",
            "2025-05-27 21:36:29,653 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4550, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,653 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,653 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4550, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,653 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,653 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,654 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,654 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0000\n",
            "2025-05-27 21:36:29,659 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4790 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,659 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4790, Edges: 6214, Graphs: 4\n",
            "2025-05-27 21:36:29,659 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4790]) -> torch.Size([4790, 37])\n",
            "2025-05-27 21:36:29,659 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4790, 37]), Edge index shape: torch.Size([2, 6214])\n",
            "2025-05-27 21:36:29,660 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4790, 200])\n",
            "2025-05-27 21:36:29,660 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4790, 37]) -> torch.Size([4790, 200])\n",
            "2025-05-27 21:36:29,660 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4790, 200]), Edge index shape: torch.Size([2, 6214])\n",
            "2025-05-27 21:36:29,661 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4790, 200])\n",
            "2025-05-27 21:36:29,662 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4790, 200]) -> torch.Size([4790, 200])\n",
            "2025-05-27 21:36:29,662 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4790, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,664 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3834, 200]), Nodes kept: 3834/4790 (80.0%)\n",
            "2025-05-27 21:36:29,664 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4790, 200]) -> torch.Size([3834, 200])\n",
            "2025-05-27 21:36:29,664 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3834, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,664 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,664 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3834, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,664 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,664 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,665 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,665 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.2676\n",
            "2025-05-27 21:36:29,669 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1014 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,669 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1014, Edges: 1270, Graphs: 2\n",
            "2025-05-27 21:36:29,670 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1014]) -> torch.Size([1014, 37])\n",
            "2025-05-27 21:36:29,670 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1014, 37]), Edge index shape: torch.Size([2, 1270])\n",
            "2025-05-27 21:36:29,671 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1014, 200])\n",
            "2025-05-27 21:36:29,671 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1014, 37]) -> torch.Size([1014, 200])\n",
            "2025-05-27 21:36:29,671 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1014, 200]), Edge index shape: torch.Size([2, 1270])\n",
            "2025-05-27 21:36:29,672 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1014, 200])\n",
            "2025-05-27 21:36:29,672 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1014, 200]) -> torch.Size([1014, 200])\n",
            "2025-05-27 21:36:29,672 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1014, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,674 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([812, 200]), Nodes kept: 812/1014 (80.1%)\n",
            "2025-05-27 21:36:29,674 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1014, 200]) -> torch.Size([812, 200])\n",
            "2025-05-27 21:36:29,674 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([812, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,674 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,674 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([812, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,674 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,674 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,675 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,675 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0007\n",
            "Epoch: 0197, loss_train: 0.0539, time: 0.1s:  98% 197/200 [00:18<00:00, 11.65it/s]2025-05-27 21:36:29,677 - trainers.GraphTrainer - INFO - train:427 - Epoch 197 completed - Avg loss: 0.0539, Time: 0.1s\n",
            "2025-05-27 21:36:29,677 - trainers.GraphTrainer - INFO - train:427 - Epoch 197 completed - Avg loss: 0.0539, Time: 0.1s\n",
            "2025-05-27 21:36:29,679 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6313 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,679 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6313, Edges: 7972, Graphs: 4\n",
            "2025-05-27 21:36:29,680 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6313]) -> torch.Size([6313, 37])\n",
            "2025-05-27 21:36:29,680 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6313, 37]), Edge index shape: torch.Size([2, 7972])\n",
            "2025-05-27 21:36:29,680 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6313, 200])\n",
            "2025-05-27 21:36:29,681 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6313, 37]) -> torch.Size([6313, 200])\n",
            "2025-05-27 21:36:29,681 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6313, 200]), Edge index shape: torch.Size([2, 7972])\n",
            "2025-05-27 21:36:29,682 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6313, 200])\n",
            "2025-05-27 21:36:29,682 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6313, 200]) -> torch.Size([6313, 200])\n",
            "2025-05-27 21:36:29,682 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6313, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,684 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5052, 200]), Nodes kept: 5052/6313 (80.0%)\n",
            "2025-05-27 21:36:29,684 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6313, 200]) -> torch.Size([5052, 200])\n",
            "2025-05-27 21:36:29,716 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5052, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,716 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,717 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5052, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,717 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,717 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,717 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,717 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0955\n",
            "2025-05-27 21:36:29,722 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 198, Batch 0/5, Loss: 0.0955\n",
            "2025-05-27 21:36:29,724 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 3572 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,725 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3572, Edges: 4812, Graphs: 4\n",
            "2025-05-27 21:36:29,725 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3572]) -> torch.Size([3572, 37])\n",
            "2025-05-27 21:36:29,725 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3572, 37]), Edge index shape: torch.Size([2, 4812])\n",
            "2025-05-27 21:36:29,727 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3572, 200])\n",
            "2025-05-27 21:36:29,727 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3572, 37]) -> torch.Size([3572, 200])\n",
            "2025-05-27 21:36:29,727 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3572, 200]), Edge index shape: torch.Size([2, 4812])\n",
            "2025-05-27 21:36:29,729 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3572, 200])\n",
            "2025-05-27 21:36:29,729 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3572, 200]) -> torch.Size([3572, 200])\n",
            "2025-05-27 21:36:29,729 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3572, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,732 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2859, 200]), Nodes kept: 2859/3572 (80.0%)\n",
            "2025-05-27 21:36:29,732 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3572, 200]) -> torch.Size([2859, 200])\n",
            "2025-05-27 21:36:29,732 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2859, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,732 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,732 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2859, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,732 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,733 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,733 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,733 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0016\n",
            "2025-05-27 21:36:29,737 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6052 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,738 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6052, Edges: 8296, Graphs: 4\n",
            "2025-05-27 21:36:29,738 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6052]) -> torch.Size([6052, 37])\n",
            "2025-05-27 21:36:29,738 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6052, 37]), Edge index shape: torch.Size([2, 8296])\n",
            "2025-05-27 21:36:29,739 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6052, 200])\n",
            "2025-05-27 21:36:29,739 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6052, 37]) -> torch.Size([6052, 200])\n",
            "2025-05-27 21:36:29,739 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6052, 200]), Edge index shape: torch.Size([2, 8296])\n",
            "2025-05-27 21:36:29,740 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6052, 200])\n",
            "2025-05-27 21:36:29,740 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6052, 200]) -> torch.Size([6052, 200])\n",
            "2025-05-27 21:36:29,741 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6052, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,743 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4843, 200]), Nodes kept: 4843/6052 (80.0%)\n",
            "2025-05-27 21:36:29,743 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6052, 200]) -> torch.Size([4843, 200])\n",
            "2025-05-27 21:36:29,743 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4843, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,743 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,744 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4843, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,744 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,744 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,744 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,744 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0152\n",
            "2025-05-27 21:36:29,749 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 4147 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,749 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 4147, Edges: 4780, Graphs: 4\n",
            "2025-05-27 21:36:29,750 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([4147]) -> torch.Size([4147, 37])\n",
            "2025-05-27 21:36:29,750 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4147, 37]), Edge index shape: torch.Size([2, 4780])\n",
            "2025-05-27 21:36:29,751 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4147, 200])\n",
            "2025-05-27 21:36:29,751 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([4147, 37]) -> torch.Size([4147, 200])\n",
            "2025-05-27 21:36:29,751 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([4147, 200]), Edge index shape: torch.Size([2, 4780])\n",
            "2025-05-27 21:36:29,752 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([4147, 200])\n",
            "2025-05-27 21:36:29,752 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([4147, 200]) -> torch.Size([4147, 200])\n",
            "2025-05-27 21:36:29,752 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([4147, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,754 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3318, 200]), Nodes kept: 3318/4147 (80.0%)\n",
            "2025-05-27 21:36:29,754 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([4147, 200]) -> torch.Size([3318, 200])\n",
            "2025-05-27 21:36:29,754 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3318, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,755 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,755 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3318, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,755 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,755 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,755 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,755 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0006\n",
            "2025-05-27 21:36:29,759 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1629 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,760 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1629, Edges: 1977, Graphs: 2\n",
            "2025-05-27 21:36:29,760 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1629]) -> torch.Size([1629, 37])\n",
            "2025-05-27 21:36:29,760 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1629, 37]), Edge index shape: torch.Size([2, 1977])\n",
            "2025-05-27 21:36:29,761 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1629, 200])\n",
            "2025-05-27 21:36:29,761 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1629, 37]) -> torch.Size([1629, 200])\n",
            "2025-05-27 21:36:29,761 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1629, 200]), Edge index shape: torch.Size([2, 1977])\n",
            "2025-05-27 21:36:29,762 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1629, 200])\n",
            "2025-05-27 21:36:29,762 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1629, 200]) -> torch.Size([1629, 200])\n",
            "2025-05-27 21:36:29,762 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1629, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,764 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1304, 200]), Nodes kept: 1304/1629 (80.0%)\n",
            "2025-05-27 21:36:29,764 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1629, 200]) -> torch.Size([1304, 200])\n",
            "2025-05-27 21:36:29,764 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1304, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,764 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,765 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1304, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,765 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,765 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,765 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,765 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0121\n",
            "Epoch: 0198, loss_train: 0.0250, time: 0.1s:  98% 197/200 [00:18<00:00, 11.65it/s]2025-05-27 21:36:29,768 - trainers.GraphTrainer - INFO - train:427 - Epoch 198 completed - Avg loss: 0.0250, Time: 0.1s\n",
            "2025-05-27 21:36:29,768 - trainers.GraphTrainer - INFO - train:427 - Epoch 198 completed - Avg loss: 0.0250, Time: 0.1s\n",
            "Epoch: 0198, loss_train: 0.0250, time: 0.1s: 100% 199/200 [00:18<00:00, 12.25it/s]2025-05-27 21:36:29,770 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6700 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,770 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6700, Edges: 9062, Graphs: 4\n",
            "2025-05-27 21:36:29,770 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6700]) -> torch.Size([6700, 37])\n",
            "2025-05-27 21:36:29,770 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6700, 37]), Edge index shape: torch.Size([2, 9062])\n",
            "2025-05-27 21:36:29,771 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6700, 200])\n",
            "2025-05-27 21:36:29,771 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6700, 37]) -> torch.Size([6700, 200])\n",
            "2025-05-27 21:36:29,771 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6700, 200]), Edge index shape: torch.Size([2, 9062])\n",
            "2025-05-27 21:36:29,772 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6700, 200])\n",
            "2025-05-27 21:36:29,772 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6700, 200]) -> torch.Size([6700, 200])\n",
            "2025-05-27 21:36:29,773 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6700, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,775 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5361, 200]), Nodes kept: 5361/6700 (80.0%)\n",
            "2025-05-27 21:36:29,775 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6700, 200]) -> torch.Size([5361, 200])\n",
            "2025-05-27 21:36:29,775 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5361, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,775 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,775 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5361, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,775 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,775 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,776 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,776 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.1164\n",
            "2025-05-27 21:36:29,780 - trainers.GraphTrainer - DEBUG - train:421 - Epoch 199, Batch 0/5, Loss: 0.1164\n",
            "2025-05-27 21:36:29,781 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6172 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,782 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6172, Edges: 8483, Graphs: 4\n",
            "2025-05-27 21:36:29,782 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6172]) -> torch.Size([6172, 37])\n",
            "2025-05-27 21:36:29,782 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6172, 37]), Edge index shape: torch.Size([2, 8483])\n",
            "2025-05-27 21:36:29,783 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6172, 200])\n",
            "2025-05-27 21:36:29,783 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6172, 37]) -> torch.Size([6172, 200])\n",
            "2025-05-27 21:36:29,783 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6172, 200]), Edge index shape: torch.Size([2, 8483])\n",
            "2025-05-27 21:36:29,784 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6172, 200])\n",
            "2025-05-27 21:36:29,784 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6172, 200]) -> torch.Size([6172, 200])\n",
            "2025-05-27 21:36:29,784 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6172, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,786 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4939, 200]), Nodes kept: 4939/6172 (80.0%)\n",
            "2025-05-27 21:36:29,786 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6172, 200]) -> torch.Size([4939, 200])\n",
            "2025-05-27 21:36:29,787 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4939, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,787 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,787 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4939, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,787 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,787 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,787 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,787 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0023\n",
            "2025-05-27 21:36:29,792 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 1806 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,793 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1806, Edges: 2205, Graphs: 4\n",
            "2025-05-27 21:36:29,793 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1806]) -> torch.Size([1806, 37])\n",
            "2025-05-27 21:36:29,793 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1806, 37]), Edge index shape: torch.Size([2, 2205])\n",
            "2025-05-27 21:36:29,794 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1806, 200])\n",
            "2025-05-27 21:36:29,817 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1806, 37]) -> torch.Size([1806, 200])\n",
            "2025-05-27 21:36:29,817 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1806, 200]), Edge index shape: torch.Size([2, 2205])\n",
            "2025-05-27 21:36:29,818 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1806, 200])\n",
            "2025-05-27 21:36:29,818 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1806, 200]) -> torch.Size([1806, 200])\n",
            "2025-05-27 21:36:29,819 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1806, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,821 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1447, 200]), Nodes kept: 1447/1806 (80.1%)\n",
            "2025-05-27 21:36:29,821 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1806, 200]) -> torch.Size([1447, 200])\n",
            "2025-05-27 21:36:29,821 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1447, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,821 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,822 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1447, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,822 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,822 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,822 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,822 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0161\n",
            "2025-05-27 21:36:29,829 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 6133 nodes, 4 graphs\n",
            "2025-05-27 21:36:29,830 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6133, Edges: 6980, Graphs: 4\n",
            "2025-05-27 21:36:29,830 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6133]) -> torch.Size([6133, 37])\n",
            "2025-05-27 21:36:29,830 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6133, 37]), Edge index shape: torch.Size([2, 6980])\n",
            "2025-05-27 21:36:29,831 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6133, 200])\n",
            "2025-05-27 21:36:29,831 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6133, 37]) -> torch.Size([6133, 200])\n",
            "2025-05-27 21:36:29,831 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6133, 200]), Edge index shape: torch.Size([2, 6980])\n",
            "2025-05-27 21:36:29,832 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6133, 200])\n",
            "2025-05-27 21:36:29,833 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6133, 200]) -> torch.Size([6133, 200])\n",
            "2025-05-27 21:36:29,833 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6133, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,835 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4907, 200]), Nodes kept: 4907/6133 (80.0%)\n",
            "2025-05-27 21:36:29,835 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6133, 200]) -> torch.Size([4907, 200])\n",
            "2025-05-27 21:36:29,835 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4907, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,836 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,836 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4907, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,836 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,836 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,836 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,836 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0209\n",
            "2025-05-27 21:36:29,842 - trainers.GraphTrainer - DEBUG - train_epoch_tj:441 - Training epoch TJ - Batch size: 902 nodes, 2 graphs\n",
            "2025-05-27 21:36:29,842 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 902, Edges: 1107, Graphs: 2\n",
            "2025-05-27 21:36:29,842 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([902]) -> torch.Size([902, 37])\n",
            "2025-05-27 21:36:29,842 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([902, 37]), Edge index shape: torch.Size([2, 1107])\n",
            "2025-05-27 21:36:29,843 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([902, 200])\n",
            "2025-05-27 21:36:29,844 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([902, 37]) -> torch.Size([902, 200])\n",
            "2025-05-27 21:36:29,844 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([902, 200]), Edge index shape: torch.Size([2, 1107])\n",
            "2025-05-27 21:36:29,845 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([902, 200])\n",
            "2025-05-27 21:36:29,845 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([902, 200]) -> torch.Size([902, 200])\n",
            "2025-05-27 21:36:29,845 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([902, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,847 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([722, 200]), Nodes kept: 722/902 (80.0%)\n",
            "2025-05-27 21:36:29,847 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([902, 200]) -> torch.Size([722, 200])\n",
            "2025-05-27 21:36:29,848 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([722, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,848 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,848 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([722, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,848 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,848 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,848 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,849 - trainers.GraphTrainer - DEBUG - train_epoch_tj:450 - TJ training loss: 0.0006\n",
            "Epoch: 0199, loss_train: 0.0313, time: 0.1s: 100% 199/200 [00:19<00:00, 12.25it/s]2025-05-27 21:36:29,852 - trainers.GraphTrainer - INFO - train:427 - Epoch 199 completed - Avg loss: 0.0313, Time: 0.1s\n",
            "2025-05-27 21:36:29,852 - trainers.GraphTrainer - INFO - train:427 - Epoch 199 completed - Avg loss: 0.0313, Time: 0.1s\n",
            "Epoch: 0199, loss_train: 0.0313, time: 0.1s: 100% 200/200 [00:19<00:00, 10.49it/s]\n",
            "2025-05-27 21:36:29,852 - trainers.GraphTrainer - INFO - train:433 - Training completed! Total time: 19.1s\n",
            "2025-05-27 21:36:29,852 - trainers.GraphTrainer - INFO - train:433 - Training completed! Total time: 19.1s\n",
            "2025-05-27 21:36:29,852 - main - INFO - <module>:378 - Training completed successfully in 19.07s\n",
            "2025-05-27 21:36:29,853 - main - INFO - <module>:385 - ==================================================\n",
            "2025-05-27 21:36:29,853 - main - INFO - <module>:386 - PHASE 5: EVALUATION AND VISUALIZATION\n",
            "2025-05-27 21:36:29,853 - main - INFO - <module>:387 - ==================================================\n",
            "2025-05-27 21:36:29,853 - main - INFO - <module>:390 - Performing final evaluation...\n",
            "2025-05-27 21:36:29,853 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 200...\n",
            "2025-05-27 21:36:29,853 - trainers.GraphTrainer - INFO - evaluate:524 - Evaluating at epoch 200...\n",
            "2025-05-27 21:36:29,853 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,853 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,855 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,855 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3829, Edges: 4445, Graphs: 4\n",
            "2025-05-27 21:36:29,855 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3829]) -> torch.Size([3829, 37])\n",
            "2025-05-27 21:36:29,855 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3829, 37]), Edge index shape: torch.Size([2, 4445])\n",
            "2025-05-27 21:36:29,856 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3829, 200])\n",
            "2025-05-27 21:36:29,856 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3829, 37]) -> torch.Size([3829, 200])\n",
            "2025-05-27 21:36:29,856 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3829, 200]), Edge index shape: torch.Size([2, 4445])\n",
            "2025-05-27 21:36:29,857 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3829, 200])\n",
            "2025-05-27 21:36:29,858 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3829, 200]) -> torch.Size([3829, 200])\n",
            "2025-05-27 21:36:29,858 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3829, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,860 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([3064, 200]), Nodes kept: 3064/3829 (80.0%)\n",
            "2025-05-27 21:36:29,860 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3829, 200]) -> torch.Size([3064, 200])\n",
            "2025-05-27 21:36:29,860 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([3064, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,860 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,860 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([3064, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,860 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,861 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,861 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,861 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0351\n",
            "2025-05-27 21:36:29,862 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:29,863 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,863 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 5159, Edges: 6519, Graphs: 4\n",
            "2025-05-27 21:36:29,864 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([5159]) -> torch.Size([5159, 37])\n",
            "2025-05-27 21:36:29,864 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5159, 37]), Edge index shape: torch.Size([2, 6519])\n",
            "2025-05-27 21:36:29,865 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5159, 200])\n",
            "2025-05-27 21:36:29,865 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([5159, 37]) -> torch.Size([5159, 200])\n",
            "2025-05-27 21:36:29,865 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([5159, 200]), Edge index shape: torch.Size([2, 6519])\n",
            "2025-05-27 21:36:29,866 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([5159, 200])\n",
            "2025-05-27 21:36:29,866 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([5159, 200]) -> torch.Size([5159, 200])\n",
            "2025-05-27 21:36:29,866 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([5159, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,868 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([4128, 200]), Nodes kept: 4128/5159 (80.0%)\n",
            "2025-05-27 21:36:29,869 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([5159, 200]) -> torch.Size([4128, 200])\n",
            "2025-05-27 21:36:29,869 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([4128, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,869 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,869 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([4128, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,869 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,869 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,869 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,870 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0051\n",
            "2025-05-27 21:36:29,872 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,872 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 6679, Edges: 9033, Graphs: 4\n",
            "2025-05-27 21:36:29,872 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([6679]) -> torch.Size([6679, 37])\n",
            "2025-05-27 21:36:29,872 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6679, 37]), Edge index shape: torch.Size([2, 9033])\n",
            "2025-05-27 21:36:29,873 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6679, 200])\n",
            "2025-05-27 21:36:29,874 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([6679, 37]) -> torch.Size([6679, 200])\n",
            "2025-05-27 21:36:29,874 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([6679, 200]), Edge index shape: torch.Size([2, 9033])\n",
            "2025-05-27 21:36:29,875 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([6679, 200])\n",
            "2025-05-27 21:36:29,875 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([6679, 200]) -> torch.Size([6679, 200])\n",
            "2025-05-27 21:36:29,875 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([6679, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,877 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([5345, 200]), Nodes kept: 5345/6679 (80.0%)\n",
            "2025-05-27 21:36:29,877 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([6679, 200]) -> torch.Size([5345, 200])\n",
            "2025-05-27 21:36:29,877 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([5345, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,878 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,878 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([5345, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,878 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,878 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,878 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,878 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.2816\n",
            "2025-05-27 21:36:29,881 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,881 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2532, Edges: 3046, Graphs: 4\n",
            "2025-05-27 21:36:29,881 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2532]) -> torch.Size([2532, 37])\n",
            "2025-05-27 21:36:29,881 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2532, 37]), Edge index shape: torch.Size([2, 3046])\n",
            "2025-05-27 21:36:29,882 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2532, 200])\n",
            "2025-05-27 21:36:29,882 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2532, 37]) -> torch.Size([2532, 200])\n",
            "2025-05-27 21:36:29,882 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2532, 200]), Edge index shape: torch.Size([2, 3046])\n",
            "2025-05-27 21:36:29,884 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2532, 200])\n",
            "2025-05-27 21:36:29,884 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2532, 200]) -> torch.Size([2532, 200])\n",
            "2025-05-27 21:36:29,884 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2532, 200]), Batch size: 4\n",
            "2025-05-27 21:36:29,886 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2027, 200]), Nodes kept: 2027/2532 (80.1%)\n",
            "2025-05-27 21:36:29,886 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2532, 200]) -> torch.Size([2027, 200])\n",
            "2025-05-27 21:36:29,886 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2027, 200]), Batch graphs: 4\n",
            "2025-05-27 21:36:29,886 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,886 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2027, 200]) -> torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,887 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,887 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([4, 200])\n",
            "2025-05-27 21:36:29,887 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([4, 2])\n",
            "2025-05-27 21:36:29,887 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0201\n",
            "2025-05-27 21:36:29,889 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,889 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 3514, Edges: 4794, Graphs: 2\n",
            "2025-05-27 21:36:29,889 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([3514]) -> torch.Size([3514, 37])\n",
            "2025-05-27 21:36:29,890 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3514, 37]), Edge index shape: torch.Size([2, 4794])\n",
            "2025-05-27 21:36:29,891 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3514, 200])\n",
            "2025-05-27 21:36:29,924 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([3514, 37]) -> torch.Size([3514, 200])\n",
            "2025-05-27 21:36:29,924 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([3514, 200]), Edge index shape: torch.Size([2, 4794])\n",
            "2025-05-27 21:36:29,925 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([3514, 200])\n",
            "2025-05-27 21:36:29,925 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([3514, 200]) -> torch.Size([3514, 200])\n",
            "2025-05-27 21:36:29,926 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([3514, 200]), Batch size: 2\n",
            "2025-05-27 21:36:29,928 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2812, 200]), Nodes kept: 2812/3514 (80.0%)\n",
            "2025-05-27 21:36:29,928 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([3514, 200]) -> torch.Size([2812, 200])\n",
            "2025-05-27 21:36:29,928 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2812, 200]), Batch graphs: 2\n",
            "2025-05-27 21:36:29,928 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,928 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2812, 200]) -> torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,928 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,928 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([2, 200])\n",
            "2025-05-27 21:36:29,929 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([2, 2])\n",
            "2025-05-27 21:36:29,929 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:29,930 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0684, Predictions: 18\n",
            "2025-05-27 21:36:29,930 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 0.0684, Predictions: 18\n",
            "2025-05-27 21:36:29,930 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,930 - trainers.GraphTrainer - INFO - inference:477 - Running inference on 5 batches...\n",
            "2025-05-27 21:36:29,931 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,931 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 782, Edges: 972, Graphs: 1\n",
            "2025-05-27 21:36:29,932 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([782]) -> torch.Size([782, 37])\n",
            "2025-05-27 21:36:29,932 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 37]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:29,933 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,933 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([782, 37]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,933 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 200]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:29,934 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,934 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([782, 200]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:29,934 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([782, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,936 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([626, 200]), Nodes kept: 626/782 (80.1%)\n",
            "2025-05-27 21:36:29,936 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([782, 200]) -> torch.Size([626, 200])\n",
            "2025-05-27 21:36:29,936 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([626, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,936 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,936 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([626, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,936 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,936 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,937 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,937 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:29,937 - trainers.GraphTrainer - DEBUG - inference:506 - Inference batch 0/5\n",
            "2025-05-27 21:36:29,938 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,938 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1830, Edges: 2170, Graphs: 1\n",
            "2025-05-27 21:36:29,939 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1830]) -> torch.Size([1830, 37])\n",
            "2025-05-27 21:36:29,939 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 37]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:29,940 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,940 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1830, 37]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,940 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 200]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:29,941 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,941 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1830, 200]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:29,941 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1830, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,943 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1464, 200]), Nodes kept: 1464/1830 (80.0%)\n",
            "2025-05-27 21:36:29,943 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1830, 200]) -> torch.Size([1464, 200])\n",
            "2025-05-27 21:36:29,943 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1464, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,943 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,943 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1464, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,943 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,944 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,944 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,944 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 5.5640\n",
            "2025-05-27 21:36:29,945 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,945 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 833, Edges: 1034, Graphs: 1\n",
            "2025-05-27 21:36:29,946 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([833]) -> torch.Size([833, 37])\n",
            "2025-05-27 21:36:29,946 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 37]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:29,947 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,947 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([833, 37]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,947 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 200]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:29,948 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,948 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([833, 200]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:29,948 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([833, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,950 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([667, 200]), Nodes kept: 667/833 (80.1%)\n",
            "2025-05-27 21:36:29,950 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([833, 200]) -> torch.Size([667, 200])\n",
            "2025-05-27 21:36:29,950 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([667, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,950 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,950 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([667, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,950 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,950 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,951 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,951 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.0000\n",
            "2025-05-27 21:36:29,952 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,952 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 717, Edges: 838, Graphs: 1\n",
            "2025-05-27 21:36:29,953 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([717]) -> torch.Size([717, 37])\n",
            "2025-05-27 21:36:29,953 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 37]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:29,954 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,954 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([717, 37]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,954 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 200]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:29,955 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,955 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([717, 200]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:29,955 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([717, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,957 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([574, 200]), Nodes kept: 574/717 (80.1%)\n",
            "2025-05-27 21:36:29,957 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([717, 200]) -> torch.Size([574, 200])\n",
            "2025-05-27 21:36:29,957 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([574, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,957 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,957 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([574, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,957 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,957 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,958 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,958 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 0.5382\n",
            "2025-05-27 21:36:29,959 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:459 - Running inference epoch TJ...\n",
            "2025-05-27 21:36:29,959 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2541, Edges: 3576, Graphs: 1\n",
            "2025-05-27 21:36:29,960 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2541]) -> torch.Size([2541, 37])\n",
            "2025-05-27 21:36:29,960 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 37]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:29,961 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,962 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2541, 37]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,962 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 200]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:29,962 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,963 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2541, 200]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:29,963 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2541, 200]), Batch size: 1\n",
            "2025-05-27 21:36:29,964 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2033, 200]), Nodes kept: 2033/2541 (80.0%)\n",
            "2025-05-27 21:36:29,965 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2541, 200]) -> torch.Size([2033, 200])\n",
            "2025-05-27 21:36:29,965 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2033, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:29,965 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,965 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2033, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,965 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,965 - models.GRAPH2VEC - DEBUG - mlp:370 - MLP forward pass - Input shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:29,965 - models.GRAPH2VEC - DEBUG - mlp:374 - MLP completed - Output shape: torch.Size([1, 2])\n",
            "2025-05-27 21:36:29,966 - trainers.GraphTrainer - DEBUG - inference_epoch_tj:468 - TJ inference loss: 10.2180\n",
            "2025-05-27 21:36:29,966 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 3.2641, Predictions: 5\n",
            "2025-05-27 21:36:29,966 - trainers.GraphTrainer - INFO - inference:515 - Inference completed - Avg loss: 3.2641, Predictions: 5\n",
            "\n",
            "Mini Test for Epochs 200:\n",
            "2025-05-27 21:36:29,967 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for train...\n",
            "train loss: 0.0684, train accuracy: 0.9444, train f1 score: 0.9565, train confusion_matrix: [[ 6  1], [ 0 11]], train precision: 0.9167, train recall: 1.0000\n",
            "2025-05-27 21:36:29,973 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0684, train accuracy: 0.9444, train f1 score: 0.9565, train confusion_matrix: [[ 6  1], [ 0 11]], train precision: 0.9167, train recall: 1.0000\n",
            "2025-05-27 21:36:29,973 - trainers.GraphTrainer - INFO - metric_print:209 - train loss: 0.0684, train accuracy: 0.9444, train f1 score: 0.9565, train confusion_matrix: [[ 6  1], [ 0 11]], train precision: 0.9167, train recall: 1.0000\n",
            "2025-05-27 21:36:29,973 - trainers.GraphTrainer - DEBUG - metric_calc:168 - Calculating metrics for test ...\n",
            "test  loss: 3.2641, test  accuracy: 0.6000, test  f1 score: 0.7500, test  confusion_matrix: [[0 2], [0 3]], test  precision: 0.6000, test  recall: 1.0000\n",
            "2025-05-27 21:36:29,979 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 3.2641, test  accuracy: 0.6000, test  f1 score: 0.7500, test  confusion_matrix: [[0 2], [0 3]], test  precision: 0.6000, test  recall: 1.0000\n",
            "2025-05-27 21:36:29,979 - trainers.GraphTrainer - INFO - metric_print:209 - test  loss: 3.2641, test  accuracy: 0.6000, test  f1 score: 0.7500, test  confusion_matrix: [[0 2], [0 3]], test  precision: 0.6000, test  recall: 1.0000\n",
            "best  loss: 0.7701, best  accuracy: 0.6000, best  f1 score: 0.7500, best  confusion_matrix: [[0 2], [0 3]], best  precision: 0.6000, best  recall: 1.0000\n",
            "2025-05-27 21:36:29,979 - trainers.GraphTrainer - INFO - metric_print:209 - best  loss: 0.7701, best  accuracy: 0.6000, best  f1 score: 0.7500, best  confusion_matrix: [[0 2], [0 3]], best  precision: 0.6000, best  recall: 1.0000\n",
            "2025-05-27 21:36:29,979 - trainers.GraphTrainer - INFO - metric_print:209 - best  loss: 0.7701, best  accuracy: 0.6000, best  f1 score: 0.7500, best  confusion_matrix: [[0 2], [0 3]], best  precision: 0.6000, best  recall: 1.0000\n",
            "2025-05-27 21:36:29,979 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.1s\n",
            "2025-05-27 21:36:29,979 - trainers.GraphTrainer - INFO - evaluate:551 - Evaluation completed in 0.1s\n",
            "2025-05-27 21:36:30,027 - main - INFO - <module>:396 - Generating embeddings for visualization...\n",
            "2025-05-27 21:36:30,027 - trainers.GraphTrainer - INFO - visualize_embeddings:112 - Generating embeddings for visualization...\n",
            "2025-05-27 21:36:30,027 - trainers.GraphTrainer - INFO - visualize_embeddings:112 - Generating embeddings for visualization...\n",
            "2025-05-27 21:36:30,027 - trainers.GraphTrainer - INFO - get_embeddings:141 - Extracting embeddings from model...\n",
            "2025-05-27 21:36:30,027 - trainers.GraphTrainer - INFO - get_embeddings:141 - Extracting embeddings from model...\n",
            "2025-05-27 21:36:30,029 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 1830, Edges: 2170, Graphs: 1\n",
            "2025-05-27 21:36:30,029 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([1830]) -> torch.Size([1830, 37])\n",
            "2025-05-27 21:36:30,029 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 37]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:30,031 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:30,031 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([1830, 37]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:30,031 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([1830, 200]), Edge index shape: torch.Size([2, 2170])\n",
            "2025-05-27 21:36:30,032 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([1830, 200])\n",
            "2025-05-27 21:36:30,032 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([1830, 200]) -> torch.Size([1830, 200])\n",
            "2025-05-27 21:36:30,033 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([1830, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,035 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1464, 200]), Nodes kept: 1464/1830 (80.0%)\n",
            "2025-05-27 21:36:30,035 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([1830, 200]) -> torch.Size([1464, 200])\n",
            "2025-05-27 21:36:30,036 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1464, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,036 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,036 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1464, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,036 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,036 - trainers.GraphTrainer - DEBUG - get_embeddings:157 - Processed 1/23 batches for embeddings\n",
            "2025-05-27 21:36:30,038 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2636, Edges: 3694, Graphs: 1\n",
            "2025-05-27 21:36:30,038 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2636]) -> torch.Size([2636, 37])\n",
            "2025-05-27 21:36:30,038 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2636, 37]), Edge index shape: torch.Size([2, 3694])\n",
            "2025-05-27 21:36:30,039 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,040 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2636, 37]) -> torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,040 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2636, 200]), Edge index shape: torch.Size([2, 3694])\n",
            "2025-05-27 21:36:30,041 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,041 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2636, 200]) -> torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,041 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2636, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,043 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2109, 200]), Nodes kept: 2109/2636 (80.0%)\n",
            "2025-05-27 21:36:30,043 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2636, 200]) -> torch.Size([2109, 200])\n",
            "2025-05-27 21:36:30,043 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2109, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,044 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,044 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2109, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,044 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,045 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2411, Edges: 2716, Graphs: 1\n",
            "2025-05-27 21:36:30,045 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2411]) -> torch.Size([2411, 37])\n",
            "2025-05-27 21:36:30,045 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2411, 37]), Edge index shape: torch.Size([2, 2716])\n",
            "2025-05-27 21:36:30,048 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2411, 200])\n",
            "2025-05-27 21:36:30,048 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2411, 37]) -> torch.Size([2411, 200])\n",
            "2025-05-27 21:36:30,048 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2411, 200]), Edge index shape: torch.Size([2, 2716])\n",
            "2025-05-27 21:36:30,049 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2411, 200])\n",
            "2025-05-27 21:36:30,049 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2411, 200]) -> torch.Size([2411, 200])\n",
            "2025-05-27 21:36:30,049 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2411, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,051 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1929, 200]), Nodes kept: 1929/2411 (80.0%)\n",
            "2025-05-27 21:36:30,051 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2411, 200]) -> torch.Size([1929, 200])\n",
            "2025-05-27 21:36:30,052 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1929, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,052 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,052 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1929, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,052 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,053 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2636, Edges: 3694, Graphs: 1\n",
            "2025-05-27 21:36:30,053 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2636]) -> torch.Size([2636, 37])\n",
            "2025-05-27 21:36:30,054 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2636, 37]), Edge index shape: torch.Size([2, 3694])\n",
            "2025-05-27 21:36:30,054 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,055 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2636, 37]) -> torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,055 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2636, 200]), Edge index shape: torch.Size([2, 3694])\n",
            "2025-05-27 21:36:30,056 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,056 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2636, 200]) -> torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,056 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2636, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,058 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2109, 200]), Nodes kept: 2109/2636 (80.0%)\n",
            "2025-05-27 21:36:30,058 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2636, 200]) -> torch.Size([2109, 200])\n",
            "2025-05-27 21:36:30,058 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2109, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,059 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,059 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2109, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,059 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,060 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 71, Edges: 63, Graphs: 1\n",
            "2025-05-27 21:36:30,060 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([71]) -> torch.Size([71, 37])\n",
            "2025-05-27 21:36:30,060 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([71, 37]), Edge index shape: torch.Size([2, 63])\n",
            "2025-05-27 21:36:30,061 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([71, 200])\n",
            "2025-05-27 21:36:30,061 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([71, 37]) -> torch.Size([71, 200])\n",
            "2025-05-27 21:36:30,061 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([71, 200]), Edge index shape: torch.Size([2, 63])\n",
            "2025-05-27 21:36:30,062 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([71, 200])\n",
            "2025-05-27 21:36:30,063 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([71, 200]) -> torch.Size([71, 200])\n",
            "2025-05-27 21:36:30,063 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([71, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,065 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([57, 200]), Nodes kept: 57/71 (80.3%)\n",
            "2025-05-27 21:36:30,066 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([71, 200]) -> torch.Size([57, 200])\n",
            "2025-05-27 21:36:30,066 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([57, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,066 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,066 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([57, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,066 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,067 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 782, Edges: 972, Graphs: 1\n",
            "2025-05-27 21:36:30,068 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([782]) -> torch.Size([782, 37])\n",
            "2025-05-27 21:36:30,068 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 37]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:30,069 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:30,069 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([782, 37]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:30,069 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([782, 200]), Edge index shape: torch.Size([2, 972])\n",
            "2025-05-27 21:36:30,070 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([782, 200])\n",
            "2025-05-27 21:36:30,070 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([782, 200]) -> torch.Size([782, 200])\n",
            "2025-05-27 21:36:30,070 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([782, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,072 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([626, 200]), Nodes kept: 626/782 (80.1%)\n",
            "2025-05-27 21:36:30,072 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([782, 200]) -> torch.Size([626, 200])\n",
            "2025-05-27 21:36:30,072 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([626, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,073 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,073 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([626, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,073 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,074 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 833, Edges: 1034, Graphs: 1\n",
            "2025-05-27 21:36:30,074 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([833]) -> torch.Size([833, 37])\n",
            "2025-05-27 21:36:30,074 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 37]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:30,075 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,075 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([833, 37]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,076 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 200]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:30,076 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,077 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([833, 200]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,077 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([833, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,079 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([667, 200]), Nodes kept: 667/833 (80.1%)\n",
            "2025-05-27 21:36:30,079 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([833, 200]) -> torch.Size([667, 200])\n",
            "2025-05-27 21:36:30,079 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([667, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,079 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,079 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([667, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,079 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,081 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 833, Edges: 1034, Graphs: 1\n",
            "2025-05-27 21:36:30,081 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([833]) -> torch.Size([833, 37])\n",
            "2025-05-27 21:36:30,081 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 37]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:30,082 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,082 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([833, 37]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,082 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([833, 200]), Edge index shape: torch.Size([2, 1034])\n",
            "2025-05-27 21:36:30,083 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,083 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([833, 200]) -> torch.Size([833, 200])\n",
            "2025-05-27 21:36:30,083 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([833, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,085 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([667, 200]), Nodes kept: 667/833 (80.1%)\n",
            "2025-05-27 21:36:30,085 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([833, 200]) -> torch.Size([667, 200])\n",
            "2025-05-27 21:36:30,085 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([667, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,125 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,125 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([667, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,126 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,127 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 32, Edges: 32, Graphs: 1\n",
            "2025-05-27 21:36:30,127 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([32]) -> torch.Size([32, 37])\n",
            "2025-05-27 21:36:30,127 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([32, 37]), Edge index shape: torch.Size([2, 32])\n",
            "2025-05-27 21:36:30,128 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([32, 200])\n",
            "2025-05-27 21:36:30,128 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([32, 37]) -> torch.Size([32, 200])\n",
            "2025-05-27 21:36:30,128 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([32, 200]), Edge index shape: torch.Size([2, 32])\n",
            "2025-05-27 21:36:30,129 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([32, 200])\n",
            "2025-05-27 21:36:30,129 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([32, 200]) -> torch.Size([32, 200])\n",
            "2025-05-27 21:36:30,129 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([32, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,131 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([26, 200]), Nodes kept: 26/32 (81.2%)\n",
            "2025-05-27 21:36:30,131 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([32, 200]) -> torch.Size([26, 200])\n",
            "2025-05-27 21:36:30,131 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([26, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,132 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,132 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([26, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,132 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,133 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 41, Edges: 46, Graphs: 1\n",
            "2025-05-27 21:36:30,133 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([41]) -> torch.Size([41, 37])\n",
            "2025-05-27 21:36:30,133 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([41, 37]), Edge index shape: torch.Size([2, 46])\n",
            "2025-05-27 21:36:30,134 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([41, 200])\n",
            "2025-05-27 21:36:30,134 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([41, 37]) -> torch.Size([41, 200])\n",
            "2025-05-27 21:36:30,134 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([41, 200]), Edge index shape: torch.Size([2, 46])\n",
            "2025-05-27 21:36:30,135 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([41, 200])\n",
            "2025-05-27 21:36:30,135 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([41, 200]) -> torch.Size([41, 200])\n",
            "2025-05-27 21:36:30,135 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([41, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,137 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([33, 200]), Nodes kept: 33/41 (80.5%)\n",
            "2025-05-27 21:36:30,137 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([41, 200]) -> torch.Size([33, 200])\n",
            "2025-05-27 21:36:30,137 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([33, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,137 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,138 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([33, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,138 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,139 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 717, Edges: 838, Graphs: 1\n",
            "2025-05-27 21:36:30,139 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([717]) -> torch.Size([717, 37])\n",
            "2025-05-27 21:36:30,139 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 37]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:30,140 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:30,140 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([717, 37]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:30,140 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([717, 200]), Edge index shape: torch.Size([2, 838])\n",
            "2025-05-27 21:36:30,141 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([717, 200])\n",
            "2025-05-27 21:36:30,141 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([717, 200]) -> torch.Size([717, 200])\n",
            "2025-05-27 21:36:30,141 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([717, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,143 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([574, 200]), Nodes kept: 574/717 (80.1%)\n",
            "2025-05-27 21:36:30,143 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([717, 200]) -> torch.Size([574, 200])\n",
            "2025-05-27 21:36:30,143 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([574, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,143 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,143 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([574, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,143 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,144 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 795, Edges: 926, Graphs: 1\n",
            "2025-05-27 21:36:30,145 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([795]) -> torch.Size([795, 37])\n",
            "2025-05-27 21:36:30,145 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([795, 37]), Edge index shape: torch.Size([2, 926])\n",
            "2025-05-27 21:36:30,146 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([795, 200])\n",
            "2025-05-27 21:36:30,146 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([795, 37]) -> torch.Size([795, 200])\n",
            "2025-05-27 21:36:30,146 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([795, 200]), Edge index shape: torch.Size([2, 926])\n",
            "2025-05-27 21:36:30,147 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([795, 200])\n",
            "2025-05-27 21:36:30,147 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([795, 200]) -> torch.Size([795, 200])\n",
            "2025-05-27 21:36:30,147 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([795, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,149 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([636, 200]), Nodes kept: 636/795 (80.0%)\n",
            "2025-05-27 21:36:30,149 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([795, 200]) -> torch.Size([636, 200])\n",
            "2025-05-27 21:36:30,149 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([636, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,149 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,149 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([636, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,149 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,150 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 882, Edges: 1102, Graphs: 1\n",
            "2025-05-27 21:36:30,151 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([882]) -> torch.Size([882, 37])\n",
            "2025-05-27 21:36:30,151 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([882, 37]), Edge index shape: torch.Size([2, 1102])\n",
            "2025-05-27 21:36:30,151 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([882, 200])\n",
            "2025-05-27 21:36:30,152 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([882, 37]) -> torch.Size([882, 200])\n",
            "2025-05-27 21:36:30,152 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([882, 200]), Edge index shape: torch.Size([2, 1102])\n",
            "2025-05-27 21:36:30,153 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([882, 200])\n",
            "2025-05-27 21:36:30,153 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([882, 200]) -> torch.Size([882, 200])\n",
            "2025-05-27 21:36:30,153 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([882, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,155 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([706, 200]), Nodes kept: 706/882 (80.0%)\n",
            "2025-05-27 21:36:30,155 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([882, 200]) -> torch.Size([706, 200])\n",
            "2025-05-27 21:36:30,155 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([706, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,155 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,155 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([706, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,155 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,156 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2541, Edges: 3576, Graphs: 1\n",
            "2025-05-27 21:36:30,156 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2541]) -> torch.Size([2541, 37])\n",
            "2025-05-27 21:36:30,157 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 37]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:30,157 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:30,158 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2541, 37]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:30,158 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2541, 200]), Edge index shape: torch.Size([2, 3576])\n",
            "2025-05-27 21:36:30,158 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2541, 200])\n",
            "2025-05-27 21:36:30,159 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2541, 200]) -> torch.Size([2541, 200])\n",
            "2025-05-27 21:36:30,159 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2541, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,160 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2033, 200]), Nodes kept: 2033/2541 (80.0%)\n",
            "2025-05-27 21:36:30,160 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2541, 200]) -> torch.Size([2033, 200])\n",
            "2025-05-27 21:36:30,161 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2033, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,161 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,161 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2033, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,161 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,162 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 870, Edges: 1075, Graphs: 1\n",
            "2025-05-27 21:36:30,162 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([870]) -> torch.Size([870, 37])\n",
            "2025-05-27 21:36:30,162 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([870, 37]), Edge index shape: torch.Size([2, 1075])\n",
            "2025-05-27 21:36:30,163 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([870, 200])\n",
            "2025-05-27 21:36:30,163 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([870, 37]) -> torch.Size([870, 200])\n",
            "2025-05-27 21:36:30,163 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([870, 200]), Edge index shape: torch.Size([2, 1075])\n",
            "2025-05-27 21:36:30,164 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([870, 200])\n",
            "2025-05-27 21:36:30,165 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([870, 200]) -> torch.Size([870, 200])\n",
            "2025-05-27 21:36:30,165 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([870, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,167 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([696, 200]), Nodes kept: 696/870 (80.0%)\n",
            "2025-05-27 21:36:30,167 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([870, 200]) -> torch.Size([696, 200])\n",
            "2025-05-27 21:36:30,167 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([696, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,167 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,168 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([696, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,168 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,169 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 739, Edges: 862, Graphs: 1\n",
            "2025-05-27 21:36:30,169 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([739]) -> torch.Size([739, 37])\n",
            "2025-05-27 21:36:30,169 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([739, 37]), Edge index shape: torch.Size([2, 862])\n",
            "2025-05-27 21:36:30,170 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([739, 200])\n",
            "2025-05-27 21:36:30,170 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([739, 37]) -> torch.Size([739, 200])\n",
            "2025-05-27 21:36:30,171 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([739, 200]), Edge index shape: torch.Size([2, 862])\n",
            "2025-05-27 21:36:30,171 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([739, 200])\n",
            "2025-05-27 21:36:30,172 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([739, 200]) -> torch.Size([739, 200])\n",
            "2025-05-27 21:36:30,172 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([739, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,173 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([592, 200]), Nodes kept: 592/739 (80.1%)\n",
            "2025-05-27 21:36:30,173 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([739, 200]) -> torch.Size([592, 200])\n",
            "2025-05-27 21:36:30,174 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([592, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,174 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,174 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([592, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,174 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,227 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 668, Edges: 783, Graphs: 1\n",
            "2025-05-27 21:36:30,227 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([668]) -> torch.Size([668, 37])\n",
            "2025-05-27 21:36:30,227 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([668, 37]), Edge index shape: torch.Size([2, 783])\n",
            "2025-05-27 21:36:30,228 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([668, 200])\n",
            "2025-05-27 21:36:30,228 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([668, 37]) -> torch.Size([668, 200])\n",
            "2025-05-27 21:36:30,228 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([668, 200]), Edge index shape: torch.Size([2, 783])\n",
            "2025-05-27 21:36:30,229 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([668, 200])\n",
            "2025-05-27 21:36:30,229 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([668, 200]) -> torch.Size([668, 200])\n",
            "2025-05-27 21:36:30,230 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([668, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,231 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([535, 200]), Nodes kept: 535/668 (80.1%)\n",
            "2025-05-27 21:36:30,232 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([668, 200]) -> torch.Size([535, 200])\n",
            "2025-05-27 21:36:30,232 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([535, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,232 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,232 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([535, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,232 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,234 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2632, Edges: 3692, Graphs: 1\n",
            "2025-05-27 21:36:30,234 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2632]) -> torch.Size([2632, 37])\n",
            "2025-05-27 21:36:30,234 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2632, 37]), Edge index shape: torch.Size([2, 3692])\n",
            "2025-05-27 21:36:30,236 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2632, 200])\n",
            "2025-05-27 21:36:30,236 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2632, 37]) -> torch.Size([2632, 200])\n",
            "2025-05-27 21:36:30,236 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2632, 200]), Edge index shape: torch.Size([2, 3692])\n",
            "2025-05-27 21:36:30,237 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2632, 200])\n",
            "2025-05-27 21:36:30,237 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2632, 200]) -> torch.Size([2632, 200])\n",
            "2025-05-27 21:36:30,237 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2632, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,240 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2106, 200]), Nodes kept: 2106/2632 (80.0%)\n",
            "2025-05-27 21:36:30,240 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2632, 200]) -> torch.Size([2106, 200])\n",
            "2025-05-27 21:36:30,240 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2106, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,240 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,240 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2106, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,240 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,242 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 747, Edges: 875, Graphs: 1\n",
            "2025-05-27 21:36:30,242 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([747]) -> torch.Size([747, 37])\n",
            "2025-05-27 21:36:30,242 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([747, 37]), Edge index shape: torch.Size([2, 875])\n",
            "2025-05-27 21:36:30,243 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([747, 200])\n",
            "2025-05-27 21:36:30,243 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([747, 37]) -> torch.Size([747, 200])\n",
            "2025-05-27 21:36:30,243 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([747, 200]), Edge index shape: torch.Size([2, 875])\n",
            "2025-05-27 21:36:30,244 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([747, 200])\n",
            "2025-05-27 21:36:30,245 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([747, 200]) -> torch.Size([747, 200])\n",
            "2025-05-27 21:36:30,245 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([747, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,247 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([598, 200]), Nodes kept: 598/747 (80.1%)\n",
            "2025-05-27 21:36:30,247 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([747, 200]) -> torch.Size([598, 200])\n",
            "2025-05-27 21:36:30,247 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([598, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,248 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,248 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([598, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,248 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,249 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2180, Edges: 2463, Graphs: 1\n",
            "2025-05-27 21:36:30,249 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2180]) -> torch.Size([2180, 37])\n",
            "2025-05-27 21:36:30,249 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2180, 37]), Edge index shape: torch.Size([2, 2463])\n",
            "2025-05-27 21:36:30,251 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2180, 200])\n",
            "2025-05-27 21:36:30,251 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2180, 37]) -> torch.Size([2180, 200])\n",
            "2025-05-27 21:36:30,251 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2180, 200]), Edge index shape: torch.Size([2, 2463])\n",
            "2025-05-27 21:36:30,252 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2180, 200])\n",
            "2025-05-27 21:36:30,252 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2180, 200]) -> torch.Size([2180, 200])\n",
            "2025-05-27 21:36:30,252 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2180, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,254 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([1744, 200]), Nodes kept: 1744/2180 (80.0%)\n",
            "2025-05-27 21:36:30,254 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2180, 200]) -> torch.Size([1744, 200])\n",
            "2025-05-27 21:36:30,255 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([1744, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,255 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,255 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([1744, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,255 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,256 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 2636, Edges: 3694, Graphs: 1\n",
            "2025-05-27 21:36:30,257 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([2636]) -> torch.Size([2636, 37])\n",
            "2025-05-27 21:36:30,257 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2636, 37]), Edge index shape: torch.Size([2, 3694])\n",
            "2025-05-27 21:36:30,258 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,258 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([2636, 37]) -> torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,258 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([2636, 200]), Edge index shape: torch.Size([2, 3694])\n",
            "2025-05-27 21:36:30,259 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,259 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([2636, 200]) -> torch.Size([2636, 200])\n",
            "2025-05-27 21:36:30,259 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([2636, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,261 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([2109, 200]), Nodes kept: 2109/2636 (80.0%)\n",
            "2025-05-27 21:36:30,261 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([2636, 200]) -> torch.Size([2109, 200])\n",
            "2025-05-27 21:36:30,262 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([2109, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,262 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,262 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([2109, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,262 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,263 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 144, Edges: 195, Graphs: 1\n",
            "2025-05-27 21:36:30,263 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([144]) -> torch.Size([144, 37])\n",
            "2025-05-27 21:36:30,263 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([144, 37]), Edge index shape: torch.Size([2, 195])\n",
            "2025-05-27 21:36:30,264 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([144, 200])\n",
            "2025-05-27 21:36:30,264 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([144, 37]) -> torch.Size([144, 200])\n",
            "2025-05-27 21:36:30,265 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([144, 200]), Edge index shape: torch.Size([2, 195])\n",
            "2025-05-27 21:36:30,265 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([144, 200])\n",
            "2025-05-27 21:36:30,266 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([144, 200]) -> torch.Size([144, 200])\n",
            "2025-05-27 21:36:30,266 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([144, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,267 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([116, 200]), Nodes kept: 116/144 (80.6%)\n",
            "2025-05-27 21:36:30,268 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([144, 200]) -> torch.Size([116, 200])\n",
            "2025-05-27 21:36:30,268 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([116, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,268 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,268 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([116, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,268 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,269 - models.GRAPH2VEC - DEBUG - embed_graph:312 - Graph embedding - Input nodes: 760, Edges: 891, Graphs: 1\n",
            "2025-05-27 21:36:30,269 - models.GRAPH2VEC - DEBUG - embed_graph:320 - One-hot encoding: torch.Size([760]) -> torch.Size([760, 37])\n",
            "2025-05-27 21:36:30,269 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([760, 37]), Edge index shape: torch.Size([2, 891])\n",
            "2025-05-27 21:36:30,270 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([760, 200])\n",
            "2025-05-27 21:36:30,270 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 0: torch.Size([760, 37]) -> torch.Size([760, 200])\n",
            "2025-05-27 21:36:30,271 - models.GRAPH_CONV - DEBUG - forward:75 - Forward pass - Input shape: torch.Size([760, 200]), Edge index shape: torch.Size([2, 891])\n",
            "2025-05-27 21:36:30,271 - models.GRAPH_CONV - DEBUG - forward:79 - Forward pass completed - Output shape: torch.Size([760, 200])\n",
            "2025-05-27 21:36:30,272 - models.GRAPH2VEC - DEBUG - embed_graph:326 - Conv layer 1: torch.Size([760, 200]) -> torch.Size([760, 200])\n",
            "2025-05-27 21:36:30,272 - models.GRAPH_POOL - DEBUG - forward:107 - Pooling forward pass - Input shape: torch.Size([760, 200]), Batch size: 1\n",
            "2025-05-27 21:36:30,273 - models.GRAPH_POOL - DEBUG - forward:112 - Pooling completed - Output shape: torch.Size([608, 200]), Nodes kept: 608/760 (80.0%)\n",
            "2025-05-27 21:36:30,273 - models.GRAPH2VEC - DEBUG - embed_graph:332 - Pooling: torch.Size([760, 200]) -> torch.Size([608, 200])\n",
            "2025-05-27 21:36:30,274 - models.GRAPH_READOUT - DEBUG - forward:134 - Readout forward pass - Input shape: torch.Size([608, 200]), Batch graphs: 1\n",
            "2025-05-27 21:36:30,274 - models.GRAPH_READOUT - DEBUG - forward:144 - Readout completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,274 - models.GRAPH2VEC - DEBUG - embed_graph:337 - Readout: torch.Size([608, 200]) -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,274 - models.GRAPH2VEC - DEBUG - embed_graph:341 - Graph embedding completed - Output shape: torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,274 - trainers.GraphTrainer - INFO - get_embeddings:159 - Extracted 23 embeddings from 23 graphs\n",
            "2025-05-27 21:36:30,274 - trainers.GraphTrainer - INFO - get_embeddings:159 - Extracted 23 embeddings from 23 graphs\n",
            "2025-05-27 21:36:30,274 - trainers.GraphTrainer - INFO - visualize_embeddings:120 - Generated 23 embeddings\n",
            "2025-05-27 21:36:30,274 - trainers.GraphTrainer - INFO - visualize_embeddings:120 - Generated 23 embeddings\n",
            "2025-05-27 21:36:30,274 - trainers.GraphTrainer - INFO - visualize_embeddings:121 - Saving visualization data to .\n",
            "2025-05-27 21:36:30,274 - trainers.GraphTrainer - INFO - visualize_embeddings:121 - Saving visualization data to .\n",
            "2025-05-27 21:36:30,275 - trainers.GraphTrainer - DEBUG - visualize_embeddings:131 - Embedding 0: xtea -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,275 - trainers.GraphTrainer - DEBUG - visualize_embeddings:131 - Embedding 1: PIC16F84-T300 -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,275 - trainers.GraphTrainer - DEBUG - visualize_embeddings:131 - Embedding 2: RC6 -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,276 - trainers.GraphTrainer - DEBUG - visualize_embeddings:131 - Embedding 3: PIC16F84-T400 -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,276 - trainers.GraphTrainer - DEBUG - visualize_embeddings:131 - Embedding 4: det_1011 -> torch.Size([1, 200])\n",
            "2025-05-27 21:36:30,278 - trainers.GraphTrainer - INFO - visualize_embeddings:133 - Embedding visualization files saved successfully\n",
            "2025-05-27 21:36:30,278 - trainers.GraphTrainer - INFO - visualize_embeddings:133 - Embedding visualization files saved successfully\n",
            "2025-05-27 21:36:30,278 - main - INFO - <module>:400 - Visualization files generated successfully\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:407 - ==================================================\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:408 - EXECUTION SUMMARY\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:409 - ==================================================\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:412 - FINAL RESULTS:\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:413 - Best Test Loss: 0.7701\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:416 - Best Test acc: 0.6000\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:416 - Best Test f1: 0.7500\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:418 - Best Test conf_mtx: [[0 2], [0 3]]\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:416 - Best Test precision: 0.6000\n",
            "2025-05-27 21:36:30,279 - main - INFO - <module>:416 - Best Test recall: 1.0000\n",
            "2025-05-27 21:36:30,326 - main - INFO - <module>:420 - Total graphs processed: 23\n",
            "2025-05-27 21:36:30,326 - main - INFO - <module>:421 - Training graphs: 18\n",
            "2025-05-27 21:36:30,326 - main - INFO - <module>:422 - Test graphs: 5\n",
            "2025-05-27 21:36:30,326 - main - INFO - <module>:423 - Model saved to: /content\n",
            "2025-05-27 21:36:30,326 - main - INFO - <module>:424 - Visualizations saved to: ./visualize_embeddings/\n",
            "\n",
            "✅ EXECUTION COMPLETED SUCCESSFULLY!\n",
            "📊 Best Test Accuracy: 0.6000\n",
            "📊 Best Test F1 Score: 0.7500\n",
            "💾 Model saved to: /content\n",
            "2025-05-27 21:36:30,326 - main - INFO - <module>:446 - ================================================================================\n",
            "2025-05-27 21:36:30,327 - main - INFO - <module>:447 - HW2VEC EXECUTION COMPLETED\n",
            "2025-05-27 21:36:30,327 - main - INFO - <module>:448 - Detailed logs available at: hw2vec_logs/hw2vec_main_20250527_213602.log\n",
            "2025-05-27 21:36:30,327 - main - INFO - <module>:449 - ================================================================================\n",
            "\n",
            "📋 EXECUTION SUMMARY\n",
            "📁 Log file: hw2vec_logs/hw2vec_main_20250527_213602.log\n",
            "📊 Check logs for detailed performance metrics\n",
            "🔍 Visualization files in: ./visualize_embeddings/\n"
          ]
        }
      ]
    }
  ]
}